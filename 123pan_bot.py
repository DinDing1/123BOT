import warnings
warnings.filterwarnings("ignore", message="python-telegram-bot is using upstream urllib3.*")
warnings.filterwarnings("ignore", message=".*pkg_resources is deprecated.*", category=UserWarning)
import os
import re
import json
import time
import logging
import requests
import sqlite3
import threading
import concurrent.futures
from contextlib import closing
from datetime import datetime, timedelta, timezone
from telegram import Update, BotCommand, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import (
    Updater, 
    MessageHandler, 
    Filters, 
    CallbackContext, 
    CommandHandler,
    CallbackQueryHandler
)
from functools import wraps
import urllib3
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from urllib.parse import urlparse, parse_qs
from p115client import P115Client
from p115 import P115Client, P115ShareFileSystem, P115FileSystem
from p115client.tool.iterdir import iter_files, get_id_to_path
from p115client.tool.download import iter_url_batches

# ç¦ç”¨SSLè­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

######################ç‰ˆæœ¬ä¿¡æ¯###########
def get_version():
    """ä» VERSION æ–‡ä»¶ä¸­è¯»å–ç‰ˆæœ¬å·"""
    version_file = "/app/VERSION"
    if os.path.exists(version_file):
        with open(version_file, "r", encoding="utf-8") as f:
            return f.read().strip()
    return "æœªçŸ¥ç‰ˆæœ¬"

VERSION = get_version()
#######################################

# é…ç½®æ—¥å¿—
logging.basicConfig(
    format='%(asctime)s - %(levelname)s - %(message)s',
    level=logging.INFO,
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# å¿½ç•¥ç¬¬ä¸‰æ–¹åº“çš„è­¦å‘Š
logging.getLogger("telegram").setLevel(logging.WARNING)
logging.getLogger("apscheduler").setLevel(logging.WARNING)
logging.getLogger("urllib3").setLevel(logging.WARNING)
logging.getLogger("p115client").setLevel(logging.WARNING)
logging.getLogger("requests").setLevel(logging.ERROR)
# ====================== é…ç½®åŒºåŸŸ ======================
# æ•°æ®åº“æ–‡ä»¶è·¯å¾„
DB_PATH = os.getenv("DB_PATH", "bot123.db")

# 123äº‘ç›˜APIé…ç½®
PAN_HOST = "https://www.123pan.com"
API_PATHS = {
    "TOKEN": "/api/v1/access_token",
    "USER_INFO": "/api/v1/user/info",
    "LIST_FILES_V2": "/api/v2/file/list",
    "UPLOAD_REQUEST": "/b/api/file/upload_request",
    "CLEAR_TRASH": "/api/file/trash_delete_all",
    "GET_SHARE": "/b/api/share/get",
    "OFFLINE_DOWNLOAD": "/api/v1/offline/download",
    "DIRECTORY_CREATE": "/upload/v1/file/mkdir"
}

# å¼€æ”¾å¹³å°åœ°å€
OPEN_API_HOST = "https://open-api.123pan.com"

# ç§’ä¼ é“¾æ¥å‰ç¼€
LEGACY_FOLDER_LINK_PREFIX_V1 = "123FSLinkV1$"
LEGACY_FOLDER_LINK_PREFIX_V2 = "123FSLinkV2$"
COMMON_PATH_LINK_PREFIX_V1 = "123FLCPV1$"
COMMON_PATH_LINK_PREFIX_V2 = "123FLCPV2$"
COMMON_PATH_DELIMITER = "%"

# Base62å­—ç¬¦é›†
BASE62_CHARS = "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ"

# ç¯å¢ƒå˜é‡é…ç½®
DEFAULT_SAVE_DIR = os.getenv("DEFAULT_SAVE_DIR", "").strip()
EXPORT_BASE_DIRS = [d.strip() for d in os.getenv("EXPORT_BASE_DIR", "").split(';') if d.strip()]
SEARCH_MAX_DEPTH = int(os.getenv("SEARCH_MAX_DEPTH", ""))
DAILY_EXPORT_LIMIT = int(os.getenv("DAILY_EXPORT_LIMIT", "3")) #å¯¼å‡ºæ¬¡æ•°
BANNED_EXPORT_NAMES = [name.strip().lower() for name in os.getenv("BANNED_EXPORT_NAMES", "ç”µè§†å‰§;ç”µå½±").split(';') if name.strip()]

# APIé€Ÿç‡æ§åˆ¶é…ç½®
API_RATE_LIMIT = float(os.getenv("API_RATE_LIMIT", "2.0"))
TRANSFER_RATE_LIMIT = float(os.getenv("TRANSFER_RATE_LIMIT", "3"))

# å…è®¸çš„æ–‡ä»¶ç±»å‹é…ç½®
ALLOWED_VIDEO_EXTENSIONS = [ext.strip().lower() for ext in os.getenv("ALLOWED_VIDEO_EXT", ".mp4,.mkv,.avi,.mov,.flv,.wmv,.webm,.ts,.m2ts,.iso,.mp3,.flac,.wav").split(',') if ext.strip()]
ALLOWED_SUB_EXTENSIONS = [ext.strip().lower() for ext in os.getenv("ALLOWED_SUB_EXT", ".srt,.ass,.ssa,.sub,.idx,.vtt,.sup").split(',') if ext.strip()]

# 115ç½‘ç›˜é…ç½®
DEFAULT_SOURCE_PATH = os.getenv("DEFAULT_SOURCE_PATH", "æˆ‘çš„æ¥æ”¶")
P115_COOKIE = os.getenv("P115_COOKIE", "")
MOBILE_UA = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"
SHARE_LINK_PATTERN = re.compile(
    r'(https?://(?:115\.com|115cdn\.com)/s/\w+)(?:\?password=\w{4})?[^\s]*',
    re.IGNORECASE
)
MAX_SUBMIT_RETRIES = 5  # 115ä»»åŠ¡æäº¤æœ€å¤§é‡è¯•æ¬¡æ•°
RETRY_DELAY = 10       # 115é‡è¯•å»¶è¿Ÿæ—¶é—´(ç§’)
# =====================================================

def init_db():
    """åˆå§‹åŒ–æ•°æ®åº“"""
    try:
        with closing(sqlite3.connect(DB_PATH)) as conn:
            c = conn.cursor()
            # åˆ›å»ºæ‰€æœ‰è¡¨
            tables = [
                '''CREATE TABLE IF NOT EXISTS token_cache (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    access_token TEXT NOT NULL,
                    client_id TEXT NOT NULL,
                    client_secret TEXT NOT NULL,
                    expired_at TIMESTAMP NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )''',
                '''CREATE TABLE IF NOT EXISTS directory_cache (
                    file_id INTEGER PRIMARY KEY,
                    filename TEXT NOT NULL,
                    parent_id INTEGER NOT NULL,
                    full_path TEXT NOT NULL,
                    base_dir_id INTEGER NOT NULL,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )''',
                '''CREATE TABLE IF NOT EXISTS user_privileges (
                    user_id INTEGER PRIMARY KEY,
                    privilege_level TEXT NOT NULL DEFAULT 'user',
                    export_count INTEGER NOT NULL DEFAULT 0,
                    last_export_date TIMESTAMP,
                    join_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )''',
                '''CREATE TABLE IF NOT EXISTS export_history (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_id INTEGER NOT NULL,
                    export_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    folder_count INTEGER NOT NULL
                )'''
            ]
            
            for table in tables:
                c.execute(table)
            
            # åˆ›å»ºç´¢å¼•
            indexes = [
                "CREATE INDEX IF NOT EXISTS idx_filename ON directory_cache (filename)",
                "CREATE INDEX IF NOT EXISTS idx_full_path ON directory_cache (full_path)",
                "CREATE INDEX IF NOT EXISTS idx_base_dir ON directory_cache (base_dir_id)"
            ]
            
            for index in indexes:
                c.execute(index)
                
            conn.commit()
    except Exception as e:
        logger.error(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")

init_db()

# ====================== å·¥å…·å‡½æ•° ======================
def format_size(size_bytes):
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    if size_bytes >= 1024 ** 4:
        return f"{size_bytes / (1024 ** 4):.2f} TB"
    elif size_bytes >= 1024 ** 3:
        return f"{size_bytes / (1024 ** 3):.2f} GB"
    elif size_bytes >= 1024 ** 2:
        return f"{size_bytes / (1024 ** 2):.2f} MB"
    elif size_bytes >= 1024:
        return f"{size_bytes / 1024:.2f} KB"
    else:
        return f"{size_bytes} bytes"

def generate_usage_bar(percent, length=20):
    """ç”Ÿæˆä½¿ç”¨ç‡è¿›åº¦æ¡"""
    filled = int(round(length * percent / 100))
    empty = length - filled
    return "[" + "â–ˆ" * filled + "â–‘" * empty + "]"

def format_duration(seconds):
    """æ ¼å¼åŒ–æ—¶é—´é—´éš”"""
    hours, remainder = divmod(seconds, 3600)
    minutes, seconds = divmod(remainder, 60)
    return f"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d}"

# =====================================================

class TokenManager:
    """ç®¡ç†API tokençš„è·å–å’Œç¼“å­˜"""
    def __init__(self, client_id, client_secret):
        self.client_id = client_id
        self.client_secret = client_secret
        self.session = self._create_session()
        self.access_token = None
        self.token_expiry = None
        self.start_time = datetime.now()
        
        if not self.load_token_from_cache():
            self.get_new_token()
    
    def _create_session(self):
        """åˆ›å»ºå¸¦é‡è¯•æœºåˆ¶çš„Session"""
        session = requests.Session()
        retry_strategy = Retry(
            total=5,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504],
            allowed_methods=["GET", "POST"]
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("https://", adapter)
        session.mount("http://", adapter)
        session.verify = False
        return session
    
    def load_token_from_cache(self):
        """ä»æ•°æ®åº“åŠ è½½ç¼“å­˜çš„Token"""
        try:
            with closing(sqlite3.connect(DB_PATH)) as conn:
                c = conn.cursor()
                c.execute("SELECT access_token, client_id, client_secret, expired_at FROM token_cache ORDER BY id DESC LIMIT 1")
                row = c.fetchone()
                
                if row:
                    token, cached_id, cached_secret, expired_at_str = row
                    expired_at = datetime.fromisoformat(expired_at_str).astimezone(timezone.utc)
                    now = datetime.now(timezone.utc)
                    
                    if (expired_at > now + timedelta(minutes=5) and \
                       self.client_id == cached_id and \
                       self.client_secret == cached_secret):
                        self.access_token = token
                        self.token_expiry = expired_at
                        logger.info("ä½¿ç”¨ç¼“å­˜Token")
                    
                        return True
        except Exception as e:
            logger.error(f"åŠ è½½Tokenç¼“å­˜å¤±è´¥: {e}")
        return False
    
    def save_token_to_cache(self, access_token, expired_at):
        """ä¿å­˜Tokenåˆ°æ•°æ®åº“"""
        try:
            with closing(sqlite3.connect(DB_PATH)) as conn:
                c = conn.cursor()
                c.execute("DELETE FROM token_cache")
                c.execute('''INSERT INTO token_cache 
                           (access_token, client_id, client_secret, expired_at)
                           VALUES (?,?,?,?)''',
                           (access_token, self.client_id, self.client_secret, expired_at.isoformat()))
                conn.commit()
                return True
        except Exception as e:
            logger.error(f"ä¿å­˜Tokenåˆ°ç¼“å­˜å¤±è´¥: {e}")
            return False
    
    def get_new_token(self):
        """è·å–æ–°token"""
        try:
            logger.info("æ­£åœ¨è·å–æ–°Token...")
            url = f"{OPEN_API_HOST}{API_PATHS['TOKEN']}"
            payload = {
                "clientID": self.client_id,
                "clientSecret": self.client_secret
            }
            
            headers = {
                "Content-Type": "application/json",
                "Platform": "open_platform"
            }
            
            response = self.session.post(url, json=payload, headers=headers, timeout=20)
            
            if response.status_code != 200:
                logger.error(f"è®¤è¯å¤±è´¥: HTTP {response.status_code}")
                return False
            
            data = response.json()
            if data.get("code") != 0:
                logger.error(f"APIé”™è¯¯: {data.get('code')} - {data.get('message')}")
                return False
            
            self.access_token = data["data"]["accessToken"]
            expired_at_str = data["data"]["expiredAt"]
            
            # ç»Ÿä¸€å¤„ç†æ—¶é—´æ ¼å¼
            if expired_at_str.endswith('Z'):
                expired_at_str = expired_at_str[:-1] + "+00:00"
            
            self.token_expiry = datetime.fromisoformat(expired_at_str).astimezone(timezone.utc)
            
            if self.save_token_to_cache(self.access_token, self.token_expiry):
                logger.info(f"æ›´æ–°TokenæˆåŠŸï¼Œæœ‰æ•ˆæœŸè‡³: {self.token_expiry} (UTC)")
                return True
            return False
        except Exception as e:
            logger.error(f"è·å–Tokenå¤±è´¥: {e}")
            return False
    
    def ensure_token_valid(self):
        """ç¡®ä¿tokenæœ‰æ•ˆ"""
        current_time = datetime.now(timezone.utc)
        if not self.access_token or not self.token_expiry or current_time >= self.token_expiry - timedelta(minutes=5):
            logger.info("Tokenæ— æ•ˆæˆ–å³å°†è¿‡æœŸï¼Œåˆ·æ–°ä¸­...")
            return self.get_new_token()
        return True
    
    def get_auth_header(self):
        """è·å–è®¤è¯å¤´"""
        if not self.ensure_token_valid():
            raise Exception("æ— æ³•è·å–æœ‰æ•ˆçš„Token")
        return {
            "Authorization": f"Bearer {self.access_token}",
            "Platform": "open_platform",
            "Content-Type": "application/json"
        }
        
def is_allowed_file(filename):
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºå…è®¸çš„ç±»å‹"""
    ext = os.path.splitext(filename)[1].lower()
    return ext in ALLOWED_VIDEO_EXTENSIONS or ext in ALLOWED_SUB_EXTENSIONS


class Pan115Transfer:
    """115ç½‘ç›˜è½¬å­˜è¿ç§»ç±»"""
    def __init__(self, pan_client, access_token):
        self.pan_client = pan_client
        self.access_token = access_token
        self.created_dirs = {}
        self.target_root_id = self.create_123_directory(DEFAULT_SAVE_DIR)
        self.transfer_stats = {
            "total_files": 0,
            "filtered_files": 0,
            "submitted_files": 0,
            "success_files": 0,
            "failed_files": 0,
            "start_time": time.time(),
            "total_size": 0,
            "filtered_size": 0
        }
        
        # åˆå§‹åŒ–115å®¢æˆ·ç«¯
        self.client_115 = self.init_115_client()
        self.default_source_dir_id = self.find_115_directory_id(DEFAULT_SOURCE_PATH)
    
    def init_115_client(self):
        """åˆå§‹åŒ–115ç½‘ç›˜å®¢æˆ·ç«¯"""
        logger.info("åˆå§‹åŒ–115ç½‘ç›˜å®¢æˆ·ç«¯...")
        if not P115_COOKIE:
            raise ValueError("æœªè®¾ç½®P115_COOKIEç¯å¢ƒå˜é‡")

        client = P115Client(cookies=P115_COOKIE)
        try:
            user_info = client.user_info(headers={"User-Agent": MOBILE_UA})
            logger.info(f"115ç™»å½•æˆåŠŸ!")
            return client
        except Exception as e:
            logger.error(f"115ç™»å½•å¤±è´¥: {str(e)}")
            raise
    
    def find_115_directory_id(self, path):
        """æŸ¥æ‰¾115ç›®å½•ID"""
        if not path or path == "/":
            return 0
            
        try:
            dir_id = get_id_to_path(
                client=self.client_115,
                path=path,
                parent_id=0,
                ensure_file=False,
                app='web',
            )
            return dir_id
        except Exception as e:
            logger.error(f"è·å–ç›®å½•IDå¤±è´¥: {path} - {str(e)}")
            return None
    
    def extract_share_info(self, text):
        """ä»æ–‡æœ¬ä¸­æå–115åˆ†äº«é“¾æ¥å’Œå¯†ç """
        matches = re.finditer(SHARE_LINK_PATTERN, text)
        share_links = []
        
        for match in matches:
            url = match.group(0)
            parsed = urlparse(url)
            password = parse_qs(parsed.query).get('password', [''])[0]
            
            if password and len(password) == 4:
                share_links.append((url, password))
            else:
                share_links.append((url, ''))
        
        return share_links
    
    def save_share_to_115(self, text, target_path=DEFAULT_SOURCE_PATH):
        """å°†åˆ†äº«é“¾æ¥ä¸­çš„æ–‡ä»¶ä¿å­˜åˆ°115ç½‘ç›˜çš„ä¸­è½¬ç«™"""
        target_dir_id = self.find_115_directory_id(target_path)
        if target_dir_id is None:
            logger.error(f"ç›®æ ‡ç›®å½•ä¸å­˜åœ¨: {target_path}")
            return False
        
        share_links = self.extract_share_info(text)
        if not share_links:
            logger.error("æ— æ³•è§£æåˆ†äº«é“¾æ¥")
            return False
        
        results = []
        for url, password in share_links:
            logger.info(f"å¤„ç†åˆ†äº«é“¾æ¥: {url}")
            if password:
                logger.info(f"ä½¿ç”¨æå–ç : {password}")
            
            try:
                parsed = urlparse(url)
                path_parts = parsed.path.split('/')
                if len(path_parts) < 3 or path_parts[1] != 's':
                    logger.error(f"âŒ æ— æ•ˆçš„åˆ†äº«é“¾æ¥æ ¼å¼: {url}")
                    results.append(False)
                    continue
                
                share_code = path_parts[2]
                
                share_fs = P115ShareFileSystem(
                    client=self.client_115, 
                    share_code=share_code,
                    receive_code=password,
                )
                
                resp = share_fs.receive(0, target_dir_id)
                
                if resp.get("state") is True:
                    logger.info("âœ… åˆ†äº«å†…å®¹è½¬å­˜æˆåŠŸ!")
                    results.append(True)
                else:
                    error_msg = resp.get("error", "æœªçŸ¥é”™è¯¯")
                    logger.error(f"âŒ è½¬å­˜å¤±è´¥: {error_msg}")
                    results.append(False)
                    
            except Exception as e:
                logger.error(f"âŒ ä¿å­˜åˆ†äº«æ–‡ä»¶å¤±è´¥: {str(e)}")
                results.append(False)
        
        return all(results)
    
    def scan_115_directory(self, path):
        """æ‰«æ115ç›®å½•è·å–æ–‡ä»¶åˆ—è¡¨"""
        logger.info(f"æ‰«æç›®å½•: {path}...")
        files = []
        dir_id = self.find_115_directory_id(path)
        if dir_id is None:
            logger.error(f"ç›®å½•IDæœªæ‰¾åˆ°: {path}")
            return []
            
        try:
            for item in iter_files(
                client=self.client_115,
                cid=dir_id,
                type=99,  # ä»…æ–‡ä»¶
                cur=0,    # é€’å½’å­ç›®å½•
                with_path=True,
                escape=False,
            ):
                try:
                    if "name" not in item or "path" not in item:
                        continue
                    
                    # è®°å½•æ‰«æåˆ°çš„æ–‡ä»¶
                    self.transfer_stats["total_files"] += 1
                    self.transfer_stats["total_size"] += item.get("size", 0)
                    
                    # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
                    file_ext = os.path.splitext(item["name"])[1].lower()
                    if file_ext not in ALLOWED_VIDEO_EXTENSIONS + ALLOWED_SUB_EXTENSIONS:
                        self.transfer_stats["filtered_files"] += 1
                        self.transfer_stats["filtered_size"] += item.get("size", 0)
                        continue
                        
                    # è§„èŒƒåŒ–è·¯å¾„æ¯”è¾ƒ
                    norm_path = os.path.normpath(path)
                    item_path = os.path.normpath(item["path"].lstrip('/'))
                    
                    # å¤„ç†ç›¸å¯¹è·¯å¾„
                    if item_path == norm_path:
                        rel_path = ""
                    elif item_path.startswith(norm_path + os.sep):
                        rel_path = item_path[len(norm_path)+1:]
                    else:
                        rel_path = item_path
                    
                    parent_id = item.get("cid", dir_id)
                    
                    files.append({
                        "name": item["name"],
                        "path": os.path.dirname(rel_path) if rel_path else "",
                        "size": item["size"],
                        "pickcode": item["pickcode"],
                        "url": None,
                        "parent_id": parent_id
                    })
                except Exception:
                    continue
        except Exception as e:
            logger.error(f"æ‰«æç›®å½•å¤±è´¥: {str(e)}")
            return files
            
        # æ‰¹é‡è·å–ä¸‹è½½é“¾æ¥
        pickcodes = [f["pickcode"] for f in files]
        url_map = {}
        
        logger.info(f"è·å– {len(pickcodes)} ä¸ªæ–‡ä»¶çš„ä¸‹è½½é“¾æ¥...")
        try:
            for url_info in iter_url_batches(
                client=self.client_115,
                pickcodes=pickcodes,
                user_agent=MOBILE_UA,
                batch_size=50,
                headers={"User-Agent": MOBILE_UA}
            ):
                if url_info.url:
                    url_map[url_info.pickcode] = url_info.url
        except Exception as e:
            logger.error(f"è·å–ä¸‹è½½é“¾æ¥å¤±è´¥: {str(e)}")
            
        # åˆå¹¶ä¸‹è½½é“¾æ¥
        for file in files:
            file["url"] = url_map.get(file["pickcode"])
            
        valid_files = [f for f in files if f["url"]]
        logger.info(f"æ‰¾åˆ° {len(valid_files)} ä¸ªæœ‰æ•ˆæ–‡ä»¶")
        return valid_files
    
    def create_123_directory(self, full_path):
        """åˆ›å»º123äº‘ç›˜ç›®å½•ï¼ˆå·²å­˜åœ¨æ—¶ç›´æ¥ä½¿ç”¨ï¼‰"""
        if not full_path:
            return 0
            
        if full_path in self.created_dirs:
            return self.created_dirs[full_path]
            
        parts = [p for p in full_path.split('/') if p]
        current_id = 0
        
        for i, part in enumerate(parts):
            current_path = '/'.join(parts[:i+1])
            
            if current_path in self.created_dirs:
                current_id = self.created_dirs[current_path]
                continue
                
            # æ£€æŸ¥ç›®å½•æ˜¯å¦å·²å­˜åœ¨
            existing_id = self.get_123_directory_id(current_id, part)
            if existing_id:
                self.created_dirs[current_path] = existing_id
                current_id = existing_id
                continue
                
            headers = {
                "Authorization": f"Bearer {self.access_token}",
                "Platform": "open_platform",
                "Content-Type": "application/json"
            }
            
            try:
                response = requests.post(
                    f"{OPEN_API_HOST}{API_PATHS['DIRECTORY_CREATE']}",
                    headers=headers,
                    json={"name": part, "parentID": current_id}
                )
                data = response.json()
                
                if data.get("code") == 0:
                    new_id = data["data"]["dirID"]
                    self.created_dirs[current_path] = new_id
                    current_id = new_id
                else:
                    # ç­‰å¾…åé‡è¯•è·å–ç›®å½•ID
                    time.sleep(1)
                    existing_id = self.get_123_directory_id(current_id, part)
                    if existing_id:
                        self.created_dirs[current_path] = existing_id
                        current_id = existing_id
                    else:
                        # æœ€ç»ˆå°è¯•åˆ›å»º
                        response = requests.post(
                            f"{OPEN_API_HOST}{API_PATHS['DIRECTORY_CREATE']}",
                            headers=headers,
                            json={"name": part, "parentID": current_id}
                        )
                        data = response.json()
                        
                        if data.get("code") == 0:
                            new_id = data["data"]["dirID"]
                            self.created_dirs[current_path] = new_id
                            current_id = new_id
                        else:
                            existing_id = self.get_123_directory_id(current_id, part)
                            if existing_id:
                                self.created_dirs[current_path] = existing_id
                                current_id = existing_id
                            else:
                                raise Exception(f"åˆ›å»ºç›®å½•å¤±è´¥: {data.get('message', 'æœªçŸ¥é”™è¯¯')}")
            except Exception as e:
                existing_id = self.get_123_directory_id(current_id, part)
                if existing_id:
                    self.created_dirs[current_path] = existing_id
                    current_id = existing_id
                else:
                    logger.error(f"åˆ›å»ºç›®å½•å¤±è´¥: {str(e)}")
                    raise
                
        return current_id

    def get_123_directory_id(self, parent_id, dir_name):
        """æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨"""
        headers = {
            "Authorization": f"Bearer {self.access_token}",
            "Platform": "open_platform"
        }
        
        try:
            response = requests.get(
                f"{OPEN_API_HOST}{API_PATHS['LIST_FILES_V2']}",
                headers=headers,
                params={"parentFileId": parent_id, "limit": 100}
            )
            data = response.json()
            
            if data.get("code") == 0:
                for item in data["data"]["fileList"]:
                    if item["type"] == 1 and item["filename"] == dir_name:
                        return item["fileId"]
            return None
        except Exception as e:
            logger.error(f"è·å–ç›®å½•åˆ—è¡¨å¤±è´¥: {str(e)}")
            return None

    def submit_to_123pan(self, file_url, file_name, dir_id):
        """æäº¤ä¸‹è½½ä»»åŠ¡åˆ°123äº‘ç›˜ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
        headers = {
            "Authorization": f"Bearer {self.access_token}",
            "Platform": "open_platform",
            "Content-Type": "application/json"
        }
        
        payload = {"url": file_url, "dirID": dir_id, "fileName": file_name}
        
        for attempt in range(MAX_SUBMIT_RETRIES):
            try:
                response = requests.post(
                    f"{OPEN_API_HOST}{API_PATHS['OFFLINE_DOWNLOAD']}",
                    headers=headers,
                    json=payload
                )
                data = response.json()
                
                if data.get("code") == 0:
                    task_id = data["data"]["taskID"]
                    return task_id
                else:
                    error_msg = data.get("message", "æœªçŸ¥é”™è¯¯")
                    # å¦‚æœæ˜¯é¢‘ç‡é™åˆ¶é”™è¯¯ï¼Œç­‰å¾…åé‡è¯•
                    if "é¢‘ç¹" in error_msg or "ç¨å" in error_msg:
                        time.sleep(RETRY_DELAY)
                    else:
                        return None
            except Exception:
                time.sleep(RETRY_DELAY)
        
        return None
    def clear_115_directory(self, path=DEFAULT_SOURCE_PATH):
        """æ¸…ç©ºç›®å½•ï¼ˆåˆ é™¤ç›®å½•ä¸‹çš„æ‰€æœ‰å†…å®¹ä½†ä¸åˆ é™¤ç›®å½•æœ¬èº«ï¼‰"""
        print(f"æ¸…ç©ºç›®å½•: {path}...")
        dir_id = self.find_115_directory_id(path)
        if not dir_id:
            print(f"ç›®å½•IDæœªæ‰¾åˆ°: {path}")
            return False
        
        try:
            # åˆ›å»ºæ–‡ä»¶ç³»ç»Ÿå¯¹è±¡
            fs = P115FileSystem(self.client_115)
            
            # åˆ‡æ¢åˆ°ç›®æ ‡ç›®å½•
            fs.chdir(dir_id)
            
            # è·å–ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶å’Œå­ç›®å½•
            items = fs.listdir_attr()
            
            # æ”¶é›†æ‰€æœ‰è¦åˆ é™¤çš„ID
            ids_to_delete = []
            for item in items:
                # åªå¤„ç†å½“å‰ç›®å½•ä¸‹çš„ç›´æ¥å­é¡¹
                if item['parent_id'] == dir_id:
                    ids_to_delete.append(item['id'])
            
            if not ids_to_delete:
                print(f"ç›®å½• {path} å·²ç»æ˜¯ç©ºçš„")
                return True
            
            # æ‰¹é‡åˆ é™¤
            result = self.client_115.fs_delete(ids_to_delete)
            if result.get("state"):
                print(f"âœ… ç›®å½•å†…å®¹åˆ é™¤æˆåŠŸ! å·²ç§»åŠ¨åˆ°å›æ”¶ç«™: {path}")
                return True
            else:
                error_msg = result.get("error", "æœªçŸ¥é”™è¯¯")
                print(f"âŒ ç›®å½•å†…å®¹åˆ é™¤å¤±è´¥: {error_msg}")
                return False
        except Exception as e:
            print(f"æ¸…ç©ºç›®å½•å¼‚å¸¸: {str(e)}")
            return False

    def get_transfer_report(self):
        """ç”Ÿæˆè¿ç§»ç»Ÿè®¡æŠ¥å‘Š"""
        elapsed = time.time() - self.transfer_stats["start_time"]
        
        report = (
            "ğŸ“Š è¿ç§»ç»Ÿè®¡æŠ¥å‘Š\n"
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
            f"ğŸ“‚ æ‰«ææ–‡ä»¶æ€»æ•°: {self.transfer_stats['total_files']} (å¤§å°: {format_size(self.transfer_stats['total_size'])})\n"
            f"ğŸš« è¿‡æ»¤æ–‡ä»¶æ•°: {self.transfer_stats['filtered_files']} (å¤§å°: {format_size(self.transfer_stats['filtered_size'])})\n"
            f"ğŸ“¤ æäº¤è¿ç§»æ–‡ä»¶æ•°: {self.transfer_stats['submitted_files']} (å¤§å°: {format_size(self.transfer_stats['total_size'] - self.transfer_stats['filtered_size'])})\n"
            f"âœ… æˆåŠŸæäº¤æ–‡ä»¶æ•°: {self.transfer_stats['success_files']}\n"
            f"âŒ æäº¤å¤±è´¥æ–‡ä»¶æ•°: {self.transfer_stats['failed_files']}\n"
            f"â±ï¸ æ€»è€—æ—¶: {format_duration(elapsed)}\n"
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        )
        
        return report

    def transfer_files(self, source_path):
        """æ‰§è¡Œè¿ç§»ï¼ˆä¸å†ç›‘æ§è¿›åº¦ï¼‰"""
        # é‡ç½®ç»Ÿè®¡ä¿¡æ¯
        self.transfer_stats = {
            "total_files": 0,
            "filtered_files": 0,
            "submitted_files": 0,
            "success_files": 0,
            "failed_files": 0,
            "start_time": time.time(),
            "total_size": 0,
            "filtered_size": 0
        }
        
        files = self.scan_115_directory(source_path)
        if not files:
            logger.warning(f"æ²¡æœ‰å¯è¿ç§»çš„æ–‡ä»¶: {source_path}")
            return False, "æ²¡æœ‰å¯è¿ç§»çš„æ–‡ä»¶"
            
        logger.info(f"å‡†å¤‡è¿ç§» {len(files)} ä¸ªæ–‡ä»¶...")
        self.transfer_stats["submitted_files"] = len(files)
        
        # é¢„å¤„ç†ç›®å½• - æå‰åˆ›å»ºæ‰€æœ‰éœ€è¦çš„ç›®å½•
        dir_id_map = {}
        for file in files:
            dir_path = file["path"]
            full_dir_path = f"{DEFAULT_SAVE_DIR}/{dir_path}" if dir_path else DEFAULT_SAVE_DIR
            
            if full_dir_path not in dir_id_map:
                try:
                    dir_id = self.create_123_directory(full_dir_path)
                    dir_id_map[full_dir_path] = dir_id
                except Exception as e:
                    logger.error(f"ç›®å½•åˆ›å»ºå¤±è´¥: {str(e)}")
                    parent_path = os.path.dirname(full_dir_path)
                    if parent_path in dir_id_map:
                        dir_id = dir_id_map[parent_path]
                        dir_id_map[full_dir_path] = dir_id
                    else:
                        dir_id_map[full_dir_path] = 0
        
        # æ‰¹é‡æäº¤ä»»åŠ¡
        success_count = 0
        failed_files = []
        
        for file in files:
            dir_path = file["path"]
            full_dir_path = f"{DEFAULT_SAVE_DIR}/{dir_path}" if dir_path else DEFAULT_SAVE_DIR
            dir_id = dir_id_map.get(full_dir_path, 0)
            
            task_id = self.submit_to_123pan(
                file["url"],
                file["name"],
                dir_id
            )
            
            if task_id:
                success_count += 1
            else:
                failed_files.append(file["name"])
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self.transfer_stats["success_files"] = success_count
        self.transfer_stats["failed_files"] = len(failed_files)
        
        logger.info(f"æˆåŠŸæäº¤ä»»åŠ¡: {success_count}/{len(files)}")
        if failed_files:
            logger.warning(f"æäº¤å¤±è´¥çš„æ–‡ä»¶: {', '.join(failed_files[:3])}{'...' if len(failed_files) > 3 else ''}")
        
        # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        report = self.get_transfer_report()
        return True, report

class Pan123Client:
    def __init__(self, client_id, client_secret):
        self.token_manager = TokenManager(client_id, client_secret)
        self.session = self._create_session()
        self.last_api_call = 0
        self.api_rate_limit = API_RATE_LIMIT
        self.share_root_folder = ""
        
        # åˆå§‹åŒ–ç›®å½•ID
        self.default_save_dir_id = 0
        self.export_base_dir_ids = []
        self.export_base_dir_map = {0: "æ ¹ç›®å½•"}
        
        # APIé€Ÿç‡æ§åˆ¶
        self.rate_limit_lock = threading.Lock()
        
        if DEFAULT_SAVE_DIR:
            self.default_save_dir_id = self.get_or_create_directory(DEFAULT_SAVE_DIR)
            logger.info(f"é»˜è®¤ä¿å­˜ç›®å½•å·²è®¾ç½®: '{DEFAULT_SAVE_DIR}' (ID: {self.default_save_dir_id})")
        
        for base_dir in EXPORT_BASE_DIRS:
            base_dir_id = self.get_or_create_directory(base_dir)
            self.export_base_dir_ids.append(base_dir_id)
            self.export_base_dir_map[base_dir_id] = base_dir
            logger.info(f"å¯¼å‡ºåŸºç›®å½•å·²è®¾ç½®: '{base_dir}' (ID: {base_dir_id})")
        
        self.search_max_depth = SEARCH_MAX_DEPTH
        logger.info(f"æœç´¢æœ€å¤§æ·±åº¦å·²è®¾ç½®: {self.search_max_depth} å±‚")
        
        # åˆå§‹åŒ–ç›®å½•ç¼“å­˜
        self.directory_cache = {}
        self.load_directory_cache()
        logger.info(f"å·²åŠ è½½ {len(self.directory_cache)} ä¸ªç›®å½•ç¼“å­˜")
    
    def _create_session(self):
        """åˆ›å»ºå¸¦é‡è¯•æœºåˆ¶çš„Session"""
        session = requests.Session()
        session.trust_env = False
        retry_strategy = Retry(
            total=5,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504],
            allowed_methods=["GET", "POST"]
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("https://", adapter)
        session.mount("http://", adapter)
        session.verify = False
        return session
    
    def get_or_create_directory(self, path):
        """è·å–æˆ–åˆ›å»ºç›®å½•è·¯å¾„"""
        parent_id = 0
        parts = path.strip('/').split('/')
        
        for part in parts:
            if not part:
                continue
                
            folder_info = self.search_folder(part, parent_id)
            if folder_info:
                parent_id = folder_info["fileId"]
                logger.debug(f"æ‰¾åˆ°ç›®å½•: '{part}' (ID: {parent_id})")
            else:
                logger.info(f"åˆ›å»ºç›®å½•: '{part}' (çˆ¶ID: {parent_id})")
                folder = self.create_folder(parent_id, part)
                if folder:
                    parent_id = folder["FileId"]
                    logger.info(f"å·²åˆ›å»ºç›®å½•: '{part}' (ID: {parent_id})")
        
        return parent_id
    
    def search_folder(self, folder_name, parent_id=0):
        """åœ¨æŒ‡å®šçˆ¶ç›®å½•ä¸‹æœç´¢æ–‡ä»¶å¤¹"""
        try:
            url = f"{OPEN_API_HOST}{API_PATHS['LIST_FILES_V2']}"
            params = {
                "parentFileId": parent_id,
                "trashed": 0,
                "limit": 100,
                "lastFileId": 0
            }
            headers = self.token_manager.get_auth_header()
            
            response = self._call_api("GET", url, params=params, headers=headers, timeout=30)
            if not response or response.status_code != 200:
                return None
                
            data = response.json()
            if data.get("code") != 0:
                return None
                
            for item in data["data"].get("fileList", []):
                if item["type"] == 1 and item["filename"] == folder_name:
                    return {
                        "fileId": item["fileId"],
                        "filename": item["filename"]
                    }
        except Exception as e:
            logger.error(f"æœç´¢ç›®å½•å‡ºé”™: {e}")
        return None

    def _call_api(self, method, url, **kwargs):
        """æ§åˆ¶APIè°ƒç”¨é¢‘ç‡ï¼Œæ·»åŠ æœ€å¤§é‡è¯•æ¬¡æ•°é™åˆ¶"""
        retry_count = 0
        max_retries = 5
        
        while retry_count < max_retries:
            try:
                with self.rate_limit_lock:
                    elapsed = time.time() - self.last_api_call
                    required_delay = 1.0 / self.api_rate_limit
                    if elapsed < required_delay:
                        time.sleep(required_delay - elapsed)
                    response = self.session.request(method, url, **kwargs)
                    self.last_api_call = time.time()
                
                if response.status_code == 429:
                    retry_after = response.headers.get('Retry-After')
                    wait_time = float(retry_after) if retry_after else 5.0
                    logger.warning(f"APIé™æµï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                    retry_count += 1
                    continue
                
                try:
                    data = response.json()
                    if data.get("code") == 429 or "æ“ä½œé¢‘ç¹" in data.get("message", ""):
                        logger.warning("APIé™æµï¼ˆå†…å®¹æ£€æµ‹ï¼‰ï¼Œç­‰å¾…5ç§’åé‡è¯•...")
                        time.sleep(5.0)
                        retry_count += 1
                        continue
                except:
                    pass
                
                return response
                
            except (requests.exceptions.SSLError, 
                    requests.exceptions.ConnectionError,
                    requests.exceptions.ChunkedEncodingError,
                    requests.exceptions.HTTPError) as e:
                retry_count += 1
                logger.error(f"ç½‘ç»œè¿æ¥é”™è¯¯: {e}ï¼Œé‡è¯• {retry_count}/{max_retries}")
                time.sleep(2 ** retry_count)
            except Exception as e:
                logger.error(f"APIè°ƒç”¨å‡ºé”™: {e}")
                retry_count += 1
                time.sleep(2 ** retry_count)
        
        logger.error(f"APIè°ƒç”¨å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° {max_retries}")
        return None
    
    def _get_auth_headers(self):
        """è·å–è®¤è¯å¤´"""
        auth_header = self.token_manager.get_auth_header()
        return {
            **auth_header,
            "platform": "web",
            "App-Version": "3",
            "Origin": PAN_HOST,
            "Referer": f"{PAN_HOST}/",
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36"
        }
    
    def get_user_info(self):
        """è·å–ç”¨æˆ·ä¿¡æ¯"""
        try:
            if not self.token_manager.ensure_token_valid():
                return None
                
            url = f"{OPEN_API_HOST}{API_PATHS['USER_INFO']}"
            headers = self.token_manager.get_auth_header()
            response = self._call_api("GET", url, headers=headers, timeout=30)
            if not response or response.status_code != 200:
                return None
                
            data = response.json()
            if data.get("code") != 0:
                return None
                
            return data.get("data")
        except Exception as e:
            logger.error(f"è·å–ç”¨æˆ·ä¿¡æ¯å‡ºé”™: {e}")
            return None
    
    def create_folder(self, parent_id, folder_name, retry_count=3):
        """åˆ›å»ºæ–‡ä»¶å¤¹"""
        for attempt in range(retry_count):
            try:
                url = f"{PAN_HOST}{API_PATHS['UPLOAD_REQUEST']}"
                payload = {
                    "driveId": 0,
                    "etag": "",
                    "fileName": folder_name,
                    "parentFileId": int(parent_id),
                    "size": 0,
                    "type": 1,
                    "NotReuse": True,
                    "RequestSource": None,
                    "duplicate": 1,
                    "event": "newCreateFolder",
                    "operateType": 1
                }
                headers = self._get_auth_headers()
                response = self.session.post(url, json=payload, headers=headers, timeout=20, verify=False)
                data = response.json()
                
                if data.get("code") == 0 and data["data"].get("Info", {}).get("FileId"):
                    folder_id = data["data"]["Info"]["FileId"]
                    logger.info(f"æ–‡ä»¶å¤¹åˆ›å»ºæˆåŠŸ: '{folder_name}' (ID: {folder_id})")
                    return data["data"]["Info"]
                else:
                    error_msg = data.get("message", "æœªçŸ¥é”™è¯¯")
                    logger.error(f"åˆ›å»ºæ–‡ä»¶å¤¹å¤±è´¥: {error_msg}")
            except Exception as e:
                logger.error(f"åˆ›å»ºæ–‡ä»¶å¤¹è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            time.sleep(1)
        return None
    
    def rapid_upload(self, etag, size, file_name, parent_id, max_retries=8):
        """ç§’ä¼ æ–‡ä»¶"""
        original_etag = etag
        
        if len(etag) != 32 or not all(c in '0123456789abcdef' for c in etag.lower()):
            etag = FastLinkProcessor.optimized_etag_to_hex(etag, True)
        
        base_delay = 2.0
        max_delay = 180.0
        
        for attempt in range(max_retries):
            try:
                delay = min(max_delay, base_delay * (2 ** attempt))
                if attempt > 0:
                    time.sleep(delay)
                
                url = f"{PAN_HOST}{API_PATHS['UPLOAD_REQUEST']}"
                payload = {
                    "driveId": 0,
                    "etag": etag,
                    "fileName": file_name,
                    "parentFileId": int(parent_id),
                    "size": int(size),
                    "type": 0,
                    "NotReuse": False,
                    "RequestSource": None,
                    "duplicate": 1,
                    "event": "rapidUpload",
                    "operateType": 1
                }
                headers = self._get_auth_headers()
                response = self._call_api("POST", url, json=payload, headers=headers, timeout=30)
                
                if not response:
                    continue
                
                try:
                    data = response.json()
                except json.JSONDecodeError:
                    continue
                
                if data.get("code") == 0 and data["data"].get("Info", {}).get("FileId"):
                    file_id = data["data"]["Info"]["FileId"]
                    logger.info(f"æ–‡ä»¶ç§’ä¼ æˆåŠŸ: '{file_name}' (ID: {file_id})")
                    return data["data"]["Info"]
                else:
                    error_msg = data.get("message", "æœªçŸ¥é”™è¯¯")
                    logger.error(f"æ–‡ä»¶ç§’ä¼ å¤±è´¥: {error_msg}")
                    if "etag" in error_msg.lower() and etag != original_etag:
                        etag = original_etag
                        continue
                    if "æ“ä½œé¢‘ç¹" in error_msg or "é™æµ" in error_msg or "é¢‘ç¹" in error_msg:
                        with self.rate_limit_lock:
                            self.api_rate_limit = max(0.8, self.api_rate_limit * 0.9)
                        logger.warning(f"è§¦å‘é™æµï¼Œé™ä½å…¨å±€é€Ÿç‡è‡³ {self.api_rate_limit:.2f} è¯·æ±‚/ç§’")
                        continue
            except Exception as e:
                logger.error(f"ç§’ä¼ è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        logger.error(f"ç§’ä¼ å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° {max_retries}")
        return None
    
    def load_directory_cache(self):
        """ä»æ•°æ®åº“åŠ è½½ç›®å½•ç¼“å­˜"""
        try:
            with closing(sqlite3.connect(DB_PATH)) as conn:
                conn.row_factory = sqlite3.Row
                c = conn.cursor()
                
                if not self.export_base_dir_ids:
                    c.execute("SELECT * FROM directory_cache")
                else:
                    placeholders = ','.join(['?'] * len(self.export_base_dir_ids))
                    c.execute(f"SELECT * FROM directory_cache WHERE base_dir_id IN ({placeholders})", 
                              self.export_base_dir_ids)
                
                rows = c.fetchall()
                for row in rows:
                    file_id = row["file_id"]
                    self.directory_cache[file_id] = dict(row)
                logger.info(f"å·²åŠ è½½ {len(rows)} ä¸ªç›®å½•ç¼“å­˜")
        except Exception as e:
            logger.error(f"åŠ è½½ç›®å½•ç¼“å­˜å¤±è´¥: {e}")
    
    def update_directory_cache(self, file_id, filename, parent_id, full_path, base_dir_id):
        """æ›´æ–°ç›®å½•ç¼“å­˜"""
        try:
            if file_id in self.directory_cache:
                existing = self.directory_cache[file_id]
                if (existing["filename"] == filename and 
                    existing["parent_id"] == parent_id and 
                    existing["full_path"] == full_path and
                    existing["base_dir_id"] == base_dir_id):
                    return False
            
            cache_entry = {
                "file_id": file_id,
                "filename": filename,
                "parent_id": parent_id,
                "full_path": full_path,
                "base_dir_id": base_dir_id
            }
            self.directory_cache[file_id] = cache_entry
            
            with closing(sqlite3.connect(DB_PATH)) as conn:
                c = conn.cursor()
                c.execute('''INSERT OR REPLACE INTO directory_cache 
                            (file_id, filename, parent_id, full_path, base_dir_id) 
                            VALUES (?,?,?,?,?)''',
                          (file_id, filename, parent_id, full_path, base_dir_id))
                conn.commit()
            logger.info(f"æ›´æ–°ç›®å½•ç¼“å­˜: {filename} (ID: {file_id}, è·¯å¾„: {full_path})")
            return True
        except Exception as e:
            logger.error(f"æ›´æ–°ç›®å½•ç¼“å­˜å¤±è´¥: {e}")
            return False
    
    def full_sync_directory_cache(self):
        """å…¨é‡åŒæ­¥ç›®å½•ç¼“å­˜"""
        logger.info("å¼€å§‹å…¨é‡åŒæ­¥ç›®å½•ç¼“å­˜...")
        try:
            with closing(sqlite3.connect(DB_PATH)) as conn:
                c = conn.cursor()
                c.execute("DELETE FROM directory_cache")
                c.execute("DELETE FROM sqlite_sequence WHERE name='directory_cache'")
                conn.commit()
                logger.info("å·²æ¸…ç©ºæ—§ç¼“å­˜æ•°æ®è¡¨")

            self.directory_cache = {}
            update_count = 0
            
            for base_dir_id in self.export_base_dir_ids:
                base_dir_path = self.export_base_dir_map.get(base_dir_id, f"åŸºç›®å½•({base_dir_id})")
                update_count += self.sync_directory(base_dir_id, base_dir_path, base_dir_id)
            
            logger.info(f"å…¨é‡åŒæ­¥å®Œæˆï¼Œæ›´æ–° {update_count} ä¸ªç›®å½•")
            return update_count
        except Exception as e:
            logger.error(f"å…¨é‡åŒæ­¥å¤±è´¥: {e}")
            return 0
    
    def sync_directory(self, directory_id, current_path, base_dir_id, current_depth=0):
        """åŒæ­¥æŒ‡å®šç›®å½•åŠå…¶å­ç›®å½•"""
        last_file_id = 0
        update_count = 0
        
        while True:
            url = f"{OPEN_API_HOST}{API_PATHS['LIST_FILES_V2']}"
            params = {
                "parentFileId": directory_id,
                "trashed": 0,
                "limit": 100,
                "lastFileId": last_file_id
            }
            headers = self.token_manager.get_auth_header()
            
            try:
                response = self._call_api("GET", url, params=params, headers=headers, timeout=30)
                if not response or response.status_code != 200:
                    break
                
                data = response.json()
                if data.get("code") != 0:
                    break
                
                for item in data["data"].get("fileList", []):
                    if item.get("trashed", 1) != 0:
                        continue
                    
                    item_path = f"{current_path}/{item['filename']}" if current_path else item['filename']
                    
                    if item["type"] == 1:
                        updated = self.update_directory_cache(
                            item["fileId"],
                            item["filename"],
                            directory_id,
                            item_path,
                            base_dir_id
                        )
                        if updated:
                            update_count += 1
                        
                        if current_depth < self.search_max_depth:
                            update_count += self.sync_directory(
                                item["fileId"],
                                item_path,
                                base_dir_id,
                                current_depth + 1
                            )
                
                last_file_id = data["data"].get("lastFileId", -1)
                if last_file_id == -1:
                    break
            except Exception as e:
                logger.error(f"åŒæ­¥ç›®å½•å‡ºé”™: {e}")
                break
        
        return update_count
    
    def get_directory_files(self, directory_id=0, base_path="", current_path=""):
        """è·å–ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶"""
        all_files = []
        
        if not self.token_manager.ensure_token_valid():
            return []
        
        last_file_id = 0
        while True:
            url = f"{OPEN_API_HOST}{API_PATHS['LIST_FILES_V2']}"
            params = {
                "parentFileId": directory_id,
                "trashed": 0,
                "limit": 100,
                "lastFileId": last_file_id
            }
            headers = self.token_manager.get_auth_header()
            
            try:
                response = self._call_api("GET", url, params=params, headers=headers, timeout=30)
                if not response or response.status_code != 200:
                    return all_files
                
                data = response.json()
                if data.get("code") != 0:
                    return all_files
                
                for item in data["data"].get("fileList", []):
                    if item.get("trashed", 1) != 0:
                        continue
                    
                    if current_path:
                        file_path = f"{current_path}/{item['filename']}"
                    else:
                        file_path = item['filename']
                    
                    if item["type"] == 0:
                        if not is_allowed_file(item['filename']):
                            continue
                        all_files.append({
                            "path": file_path,
                            "etag": item["etag"],
                            "size": item["size"]
                        })
                    elif item["type"] == 1:
                        if current_path:
                            sub_path = f"{current_path}/{item['filename']}"
                        else:
                            sub_path = item['filename']
                        time.sleep(0.5)
                        sub_files = self.get_directory_files(item["fileId"], base_path, sub_path)
                        all_files.extend(sub_files)
                
                last_file_id = data["data"].get("lastFileId", -1)
                if last_file_id == -1:
                    break
            except Exception as e:
                logger.error(f"è·å–ç›®å½•åˆ—è¡¨å‡ºé”™: {e}")
                return all_files
        
        return all_files

    def clear_trash(self):
        """æ¸…ç©ºå›æ”¶ç«™"""
        try:
            url = f"{PAN_HOST}{API_PATHS['CLEAR_TRASH']}"
            headers = self._get_auth_headers()
            payload = {"event": "recycleClear"}
            response = self._call_api("POST", url, json=payload, headers=headers, timeout=30)
            if not response or response.status_code != 200:
                return False
            data = response.json()
            if data.get("code") == 7301 or data.get("code") == 0:
                logger.info("å›æ”¶ç«™å·²æ¸…ç©º")
                return True
            return False
        except Exception as e:
            logger.error(f"æ¸…ç©ºå›æ”¶ç«™å‡ºé”™: {e}")
            return False
   
    def extract_share_info(self, share_url):
        """ä»åˆ†äº«é“¾æ¥æå–åˆ†äº«Keyå’Œå¯†ç ï¼ˆä½¿ç”¨æ”¹è¿›çš„æ­£åˆ™ï¼‰"""
        pattern = r'(https?://(?:[a-zA-Z0-9-]+\.)*123[a-zA-Z0-9-]*\.[a-z]{2,6}+/s/)([a-zA-Z0-9\-_]+)(?:[\s\S]*?(?:æå–ç |å¯†ç |code)[\s:ï¼š=]*(\w{4}))?'
        match = re.search(pattern, share_url)
        if not match:
            raise ValueError("æ— æ•ˆçš„åˆ†äº«é“¾æ¥æ ¼å¼")
        
        share_key = match.group(2)
        password = match.group(3) or ""
        
        return share_key, password

    def save_share_files(self, share_url, save_dir_id):
        """ä¿å­˜åˆ†äº«é“¾æ¥ä¸­çš„æ–‡ä»¶åˆ°æŒ‡å®šç›®å½•ï¼Œä¿ç•™åŸå§‹ç›®å½•ç»“æ„"""
        try:
            # æå–åˆ†äº«ä¿¡æ¯
            share_key, password = self.extract_share_info(share_url)
            
            # é€’å½’è·å–æ‰€æœ‰æ–‡ä»¶
            files = self._get_share_files_recursive(share_key, password, "0", "")
            if not files:
                logger.warning("åˆ†äº«ä¸­æ²¡æœ‰æ–‡ä»¶")
                return 0, 0, [], 0
                
            # ç”¨äºå­˜å‚¨ç›®å½•æ˜ å°„ï¼šè·¯å¾„ -> äº‘ç›˜ç›®å½•ID
            dir_map = {"": save_dir_id}  # æ ¹ç›®å½•æ˜ å°„
            success_count = 0
            failure_count = 0
            results = []
            total_size = 0  # ç»Ÿè®¡æ€»å¤§å°
            
            # é¦–å…ˆåˆ›å»ºæ‰€æœ‰éœ€è¦çš„ç›®å½•
            all_dirs = {os.path.dirname(f["path"]) for f in files}
            for dir_path in sorted(all_dirs):
                if not dir_path or dir_path in dir_map:
                    continue
                    
                # åˆ›å»ºç›®å½•è·¯å¾„
                parent_id = save_dir_id
                parts = dir_path.split('/')
                current_path = ""
                
                for part in parts:
                    if not part:
                        continue
                        
                    current_path = f"{current_path}/{part}" if current_path else part
                    if current_path in dir_map:
                        parent_id = dir_map[current_path]
                        continue
                        
                    # åˆ›å»ºç›®å½•
                    folder = self.create_folder(parent_id, part)
                    if folder:
                        dir_map[current_path] = folder["FileId"]
                        parent_id = folder["FileId"]
                    else:
                        break
            
            # è½¬å­˜æ–‡ä»¶
            for file_info in files:
                file_path = file_info["path"]
                file_name = os.path.basename(file_path)
                dir_path = os.path.dirname(file_path)
                parent_id = dir_map.get(dir_path, save_dir_id)
                
                # åªè½¬å­˜å…è®¸çš„æ–‡ä»¶ç±»å‹
                if not is_allowed_file(file_name):
                    continue
                
                total_size += file_info["size"]
                
                try:
                    result = self.rapid_upload(
                        file_info["etag"], 
                        file_info["size"], 
                        file_name, 
                        parent_id
                    )
                    
                    if result:
                        success_count += 1
                        results.append({
                            "success": True,
                            "file_name": file_path,
                            "size": file_info["size"]
                        })
                    else:
                        failure_count += 1
                        results.append({
                            "success": False,
                            "file_name": file_path,
                            "size": file_info["size"],
                            "error": "ç§’ä¼ å¤±è´¥"
                        })
                except Exception as e:
                    failure_count += 1
                    results.append({
                        "success": False,
                        "file_name": file_path,
                        "size": file_info["size"],
                        "error": str(e)
                    })
            
            return success_count, failure_count, results, total_size
        except Exception as e:
            logger.error(f"ä¿å­˜åˆ†äº«æ–‡ä»¶å¤±è´¥: {e}")
            return 0, 0, [], 0
    
    def _get_share_files_recursive(self, share_key, password, fid, current_path):
        """é€’å½’è·å–åˆ†äº«ä¸­çš„æ‰€æœ‰æ–‡ä»¶"""
        files = []
        items = self._get_share_files(share_key, password, fid)
        
        for item in items:
            if item["Type"] == 0:  # æ–‡ä»¶
                file_path = f"{current_path}/{item['FileName']}" if current_path else item['FileName']
                files.append({
                    "path": file_path,
                    "name": item["FileName"],
                    "size": item["Size"],
                    "etag": item["Etag"]
                })
            elif item["Type"] == 1:  # ç›®å½•
                sub_path = f"{current_path}/{item['FileName']}" if current_path else item['FileName']
                sub_files = self._get_share_files_recursive(
                    share_key, 
                    password, 
                    item["FileId"], 
                    sub_path
                )
                files.extend(sub_files)
        
        return files
    
    def _get_share_files(self, share_key, password, fid="0"):
        """è·å–åˆ†äº«ä¸­çš„æ–‡ä»¶å’Œç›®å½•åˆ—è¡¨ï¼ˆéé€’å½’ï¼‰"""
        items = []
        next_marker = "0"
        page = 1
        
        while next_marker != "-1":
            params = {
                "shareKey": share_key,
                "SharePwd": password,
                "parentFileId": fid,
                "limit": 100,
                "next": next_marker,
                "orderBy": "file_name",
                "orderDirection": "asc",
                "Page": page
            }
            
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36",
                "Referer": f"{PAN_HOST}/s/{share_key}",
                "Origin": PAN_HOST
            }
            
            try:
                response = self._call_api("GET", f"{PAN_HOST}{API_PATHS['GET_SHARE']}", 
                                         params=params, headers=headers, timeout=30)
                if not response or response.status_code != 200:
                    break
                
                data = response.json()
                if data.get("code") != 0:
                    logger.warning(f"è·å–åˆ†äº«æ–‡ä»¶å¤±è´¥: {data.get('message', 'æœªçŸ¥é”™è¯¯')}")
                    break
                
                # æ·»åŠ å½“å‰é¡µçš„é¡¹ç›®
                for item in data["data"]["InfoList"]:
                    item["Type"] = item.get("Type", 0)
                    items.append(item)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é¡µ
                next_marker = data["data"].get("Next", "-1")
                page += 1
                
            except Exception as e:
                logger.error(f"è·å–åˆ†äº«æ–‡ä»¶æ—¶å‡ºé”™: {e}")
                break
        
        return items

class FastLinkProcessor:
    @staticmethod
    def parse_share_link(share_link):
        """è§£æç§’ä¼ é“¾æ¥"""
        common_base_path = ""
        is_common_path_format = False
        is_v2_etag_format = False
        
        # ä½¿ç”¨å‰ç¼€æ˜ å°„ç®€åŒ–å¤„ç†
        prefix_map = {
            COMMON_PATH_LINK_PREFIX_V2: (True, True),
            COMMON_PATH_LINK_PREFIX_V1: (True, False),
            LEGACY_FOLDER_LINK_PREFIX_V2: (False, True),
            LEGACY_FOLDER_LINK_PREFIX_V1: (False, False)
        }
        
        for prefix, (is_common, is_v2) in prefix_map.items():
            if share_link.startswith(prefix):
                share_link = share_link[len(prefix):]
                is_common_path_format = is_common
                is_v2_etag_format = is_v2
                break
        
        if is_common_path_format:
            delimiter_pos = share_link.find(COMMON_PATH_DELIMITER)
            if delimiter_pos > -1:
                common_base_path = share_link[:delimiter_pos]
                share_link = share_link[delimiter_pos + 1:]
        
        files = []
        for s_link in share_link.split('$'):
            if not s_link:
                continue
            parts = s_link.split('#')
            if len(parts) < 3:
                continue
            
            etag = parts[0]
            size = parts[1]
            file_path = '#'.join(parts[2:])
            
            if is_common_path_format and common_base_path:
                file_path = common_base_path + file_path
            
            files.append({
                "etag": etag,
                "size": int(size),
                "file_name": file_path,
                "is_v2_etag": is_v2_etag_format
            })
        
        return files
    
    @staticmethod
    def optimized_etag_to_hex(optimized_etag, is_v2_etag):
        """å°†ä¼˜åŒ–åçš„ETagè½¬æ¢ä¸ºåå…­è¿›åˆ¶æ ¼å¼"""
        if not is_v2_etag:
            return optimized_etag
        
        try:
            # å¦‚æœå·²ç»æ˜¯åå…­è¿›åˆ¶æ ¼å¼ï¼Œç›´æ¥è¿”å›
            if len(optimized_etag) == 32 and all(c in '0123456789abcdefABCDEF' for c in optimized_etag):
                return optimized_etag.lower()
            
            num = 0
            for char in optimized_etag:
                if char not in BASE62_CHARS:
                    return optimized_etag
                num = num * 62 + BASE62_CHARS.index(char)
            
            hex_str = hex(num)[2:].lower()
            # å¤„ç†é•¿åº¦
            if len(hex_str) > 32:
                hex_str = hex_str[-32:]
            elif len(hex_str) < 32:
                hex_str = hex_str.zfill(32)
            
            return hex_str
        except Exception as e:
            logger.error(f"ETagè½¬æ¢å¤±è´¥: {e}")
            return optimized_etag

class TelegramBotHandler:
    def __init__(self, token, pan_client, allowed_user_ids):
        self.token = token
        self.pan_client = pan_client
        self.allowed_user_ids = allowed_user_ids
        self.updater = Updater(token, use_context=True)
        self.dispatcher = self.updater.dispatcher
        self.start_time = pan_client.token_manager.start_time
        
        # æ³¨å†Œå¤„ç†ç¨‹åº
        self.dispatcher.add_handler(CommandHandler("start", self.start_command))
        self.dispatcher.add_handler(CommandHandler("export", self.export_command))
        self.dispatcher.add_handler(CommandHandler("sync_full", self.sync_full_command))
        self.dispatcher.add_handler(CommandHandler("clear_trash", self.clear_trash_command))
        self.dispatcher.add_handler(CommandHandler("add", self.add_command))
        self.dispatcher.add_handler(CommandHandler("delete", self.delete_command))
        self.dispatcher.add_handler(CommandHandler("info", self.info_command))
        self.dispatcher.add_handler(CommandHandler("refresh_token", self.refresh_token_command))
        self.dispatcher.add_handler(CommandHandler("transport", self.transport_command))  # æ–°å¢è¿ç§»å‘½ä»¤
        self.dispatcher.add_handler(CommandHandler("clear", self.clear_command))  # æ–°å¢æ¸…ç©ºä¸­è½¬ç«™å‘½ä»¤
        self.dispatcher.add_handler(MessageHandler(Filters.text & ~Filters.command, self.handle_text))
        self.dispatcher.add_handler(MessageHandler(Filters.document, self.handle_document))
        self.dispatcher.add_handler(CallbackQueryHandler(self.button_callback))
        
        # è®¾ç½®èœå•å‘½ä»¤
        self.set_menu_commands()
    
    def set_menu_commands(self):
        """è®¾ç½®Telegram Botèœå•å‘½ä»¤"""
        commands = [
            BotCommand("start", "ä¸ªäººä¿¡æ¯"),
            BotCommand("export", "å¯¼å‡ºç§’ä¼ æ–‡ä»¶"),
            BotCommand("sync_full", "å…¨é‡åŒæ­¥"),
            BotCommand("info", "ç”¨æˆ·ä¿¡æ¯"),
            BotCommand("add", "æ·»åŠ ç”¨æˆ·"),
            BotCommand("delete", "åˆ é™¤ç”¨æˆ·"),            
            BotCommand("clear_trash", "æ¸…ç©º123å›æ”¶ç«™"),
            BotCommand("clear", "æ¸…ç©º115ä¸­è½¬ç«™"),
            BotCommand("transport", "è¿ç§»115æ–‡ä»¶"),  # æ–°å¢å‘½ä»¤
            BotCommand("refresh_token", "å¼ºåˆ¶åˆ·æ–°Token"),
        ]
        
        try:
            self.updater.bot.set_my_commands(commands)
        except Exception as e:
            logger.error(f"è®¾ç½®èœå•å‘½ä»¤å¤±è´¥: {e}")
    
    def start(self):
        """å¯åŠ¨æœºå™¨äºº"""
        try:
            # å¯åŠ¨è½®è¯¢å¹¶æ¸…é™¤å†å²æ¶ˆæ¯
            self.updater.start_polling(drop_pending_updates=True)
            logger.info("ğŸ¤– æœºå™¨äººå·²å¯åŠ¨ï¼Œç­‰å¾…æ¶ˆæ¯...")
            self.updater.idle()
        except Exception as e:
            logger.error(f"å¯åŠ¨æœºå™¨äººå¤±è´¥: {e}")
    
    # ç®¡ç†å‘˜æƒé™æ£€æŸ¥è£…é¥°å™¨
    def admin_required(func):
        @wraps(func)
        def wrapper(self, update: Update, context: CallbackContext, *args, **kwargs):
            user_id = update.message.from_user.id
            if user_id not in self.allowed_user_ids:
                return
            return func(self, update, context, *args, **kwargs)
        return wrapper
    
    def auto_delete_message(self, context, chat_id, message_id, delay=3):
        """è‡ªåŠ¨åˆ é™¤æ¶ˆæ¯ï¼ˆæ”¯æŒç¾¤èŠå’Œç§èŠï¼‰"""
        def delete():
            try:
                context.bot.delete_message(chat_id=chat_id, message_id=message_id)
            except Exception:
                pass
        threading.Timer(delay, delete).start()
    
    def send_auto_delete_message(self, update, context, text, delay=3, chat_id=None, parse_mode=None):
        """å‘é€è‡ªåŠ¨åˆ é™¤çš„æ¶ˆæ¯"""
        if chat_id is None:
            if update and update.message:
                chat_id = update.message.chat_id
            elif update and update.callback_query and update.callback_query.message:
                chat_id = update.callback_query.message.chat_id
            elif context and hasattr(context, '_chat_id'):
                chat_id = context._chat_id
            else:
                return None
        
        message = context.bot.send_message(chat_id=chat_id, text=text, parse_mode=parse_mode)
        self.auto_delete_message(context, chat_id, message.message_id, delay)
        return message  # è¿”å›æ¶ˆæ¯å¯¹è±¡
    
    @admin_required
    def start_command(self, update: Update, context: CallbackContext):
        """å¤„ç†/startå‘½ä»¤ - ä¼˜åŒ–ç‰ˆç”¨æˆ·ä¿¡æ¯è¾“å‡º"""
        try:
            user_info = self.pan_client.get_user_info()
            if not user_info:
                self.send_auto_delete_message(update, context, "âŒ æ— æ³•è·å–ç”¨æˆ·ä¿¡æ¯")
                return
            
            # è®¡ç®—è¿è¡Œæ—¶é—´
            uptime = datetime.now() - self.start_time
            days = uptime.days
            hours, remainder = divmod(uptime.seconds, 3600)
            minutes, seconds = divmod(remainder, 60)
            
            # æ ¼å¼åŒ–æ‰‹æœºå·ç å’ŒUID
            phone = user_info.get("passport", "")
            if phone and len(phone) > 7:
                phone = phone[:3] + "*" * 4 + phone[-4:]
            
            uid = str(user_info.get("uid", ""))
            if uid and len(uid) > 6:
                uid = uid[:3] + "*" * (len(uid) - 6) + uid[-3:]
            
            # æ ¼å¼åŒ–å­˜å‚¨ç©ºé—´
            space_permanent = format_size(user_info.get("spacePermanent", 0))
            space_used = format_size(user_info.get("spaceUsed", 0))
            direct_traffic = format_size(user_info.get("directTraffic", 0))
            
            # è®¡ç®—å­˜å‚¨ç©ºé—´ä½¿ç”¨ç‡
            if user_info.get("spacePermanent", 0) > 0:
                usage_percent = (user_info.get("spaceUsed", 0) / user_info.get("spacePermanent", 1)) * 100
                usage_bar = generate_usage_bar(usage_percent)
            else:
                usage_percent = 0
                usage_bar = ""
            
            # æ„å»ºç”¨æˆ·ä¿¡æ¯æ¶ˆæ¯
            message = (
                f"ğŸš€ <b>123äº‘ç›˜ç”¨æˆ·ä¿¡æ¯</b> | {'ğŸ‘‘ <b>å°Šäº«è´¦æˆ·</b>' if user_info.get('vip', False) else 'ğŸ”’ <b>æ™®é€šè´¦æˆ·</b>'}\n"
                f"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
                f"ğŸ‘¤ <b>æ˜µç§°:</b> {user_info.get('nickname', 'æœªçŸ¥')}\n"
                f"ğŸ†” <b>è´¦æˆ·ID:</b> {uid}\n"
                f"ğŸ“± <b>æ‰‹æœºå·ç :</b> {phone}\n\n"
                f"ğŸ’¾ <b>å­˜å‚¨ç©ºé—´</b> ({usage_percent:.1f}%)\n"
                f"â”œ æ°¸ä¹…: {space_permanent}\n"
                f"â”œ å·²ç”¨: {space_used}\n"
                f"â”” {usage_bar}\n\n"
                f"ğŸ“¡ <b>æµé‡ä¿¡æ¯</b>\n"
                f"â”” ç›´é“¾: {direct_traffic}\n"
                f"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n"
                f"âš™ï¸ <b>å½“å‰é…ç½®:</b>\n"
                f"â”œ ä¿å­˜ç›®å½•: <code>{DEFAULT_SAVE_DIR or 'æ ¹ç›®å½•'}</code>\n"
                f"â”œ å¯¼å‡ºç›®å½•: <code>{', '.join(EXPORT_BASE_DIRS) if EXPORT_BASE_DIRS else 'æ ¹ç›®å½•'}</code>\n"
                f"â”œ æœç´¢æ·±åº¦: <code>{SEARCH_MAX_DEPTH}å±‚</code>\n"
                f"â”” æ•°æ®ç¼“å­˜: <code>{len(self.pan_client.directory_cache)}</code>\n\n"
                f"ğŸ¤– <b>æœºå™¨äººæ§åˆ¶ä¸­å¿ƒ</b>\n"
                f"â–«ï¸ /export - å¯¼å‡ºæ–‡ä»¶\n"
                f"â–«ï¸ /sync_full - å…¨é‡åŒæ­¥\n"
                f"â–«ï¸ /info - æŸ¥è¯¢ç”¨æˆ·ä¿¡æ¯\n"
                f"â–«ï¸ /add - æ·»åŠ ç”¨æˆ·\n"    
                f"â–«ï¸ /delete - åˆ é™¤ç”¨æˆ·\n"                                             
                f"â–«ï¸ /clear_trash - æ¸…ç©º123å›æ”¶ç«™\n"
                f"â–«ï¸ /clear - æ¸…ç©º115ä¸­è½¬ç«™\n"      # æ–°å¢å‘½ä»¤
                f"â–«ï¸ /transport - è¿ç§»115æ–‡ä»¶\n\n"  # æ–°å¢å‘½ä»¤
                f"ğŸ“¦ <b>Version:</b> <code>{VERSION}</code>\n"
                f"â±ï¸ <b>å·²è¿è¡Œ:</b> {days}å¤©{hours}å°æ—¶{minutes}åˆ†{seconds}ç§’"
            )

            update.message.reply_text(
                message, 
                parse_mode="HTML",
                disable_web_page_preview=True
            )
        except Exception as e:
            logger.error(f"å¤„ç†/startå‘½ä»¤å‡ºé”™: {e}")
            self.send_auto_delete_message(update, context, "âŒ è·å–ç”¨æˆ·ä¿¡æ¯å¤±è´¥")

    def search_database_by_name(self, name_pattern):
        """åœ¨æ•°æ®åº“ä¸­è¿›è¡Œæ¨¡ç³Šæœç´¢"""
        try:
            with closing(sqlite3.connect(DB_PATH)) as conn:
                conn.row_factory = sqlite3.Row
                c = conn.cursor()
                c.execute("SELECT * FROM directory_cache WHERE filename LIKE ? ORDER BY filename", (f'%{name_pattern}%',))
                rows = c.fetchall()
                return [dict(row) for row in rows]
        except Exception as e:
            logger.error(f"æ•°æ®åº“æœç´¢å¤±è´¥: {e}")
            return []
    
    def get_user_privilege(self, user_id):
        """è·å–ç”¨æˆ·æƒé™ä¿¡æ¯"""
        try:
            with closing(sqlite3.connect(DB_PATH)) as conn:
                conn.row_factory = sqlite3.Row
                c = conn.cursor()
                c.execute("SELECT * FROM user_privileges WHERE user_id = ?", (user_id,))
                row = c.fetchone()
                if row:
                    return dict(row)
        except Exception as e:
            logger.error(f"æŸ¥è¯¢ç”¨æˆ·æƒé™å¤±è´¥: {e}")
        return None
    
    def update_user_export_count(self, user_id, folder_count):
        """æ›´æ–°ç”¨æˆ·å¯¼å‡ºæ¬¡æ•°"""
        try:
            with closing(sqlite3.connect(DB_PATH)) as conn:
                c = conn.cursor()
                today = datetime.now().strftime("%Y-%m-%d")
                
                # è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯
                user_info = self.get_user_privilege(user_id)
                if user_info:
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡ç½®
                    last_export_date = user_info.get("last_export_date")
                    if last_export_date and last_export_date != today:
                        # é‡ç½®æ¬¡æ•°
                        c.execute("UPDATE user_privileges SET export_count = 0, last_export_date = ? WHERE user_id = ?", 
                                  (today, user_id))
                    
                    # å¢åŠ å¯¼å‡ºæ¬¡æ•°
                    c.execute("UPDATE user_privileges SET export_count = export_count + ?, last_export_date = ? WHERE user_id = ?", 
                              (folder_count, today, user_id))
                else:
                    # æ–°ç”¨æˆ·
                    c.execute("INSERT INTO user_privileges (user_id, privilege_level, export_count, last_export_date) VALUES (?, ?, ?, ?)",
                              (user_id, "user", folder_count, today))
                
                # è®°å½•å¯¼å‡ºå†å²
                c.execute("INSERT INTO export_history (user_id, folder_count) VALUES (?, ?)",
                          (user_id, folder_count))
                
                conn.commit()
            return True
        except Exception as e:
            logger.error(f"æ›´æ–°ç”¨æˆ·å¯¼å‡ºæ¬¡æ•°å¤±è´¥: {e}")
            return False

    def export_command(self, update: Update, context: CallbackContext):
        """å¤„ç†/exportå‘½ä»¤"""
        user_id = update.message.from_user.id
        search_query = " ".join(context.args) if context.args else ""
        chat_type = update.message.chat.type
        in_group = chat_type in ['group', 'supergroup']

        # å¦‚æœæ˜¯ç¾¤èŠï¼Œå…ˆåˆ é™¤ç”¨æˆ·æ¶ˆæ¯
        if in_group:
            try:
                update.message.delete()
            except Exception:
                pass

        if not search_query:
            self.send_auto_delete_message(update, context, "âŒ è¯·æŒ‡å®šæ–‡ä»¶å¤¹åç§°ï¼æ ¼å¼: /export <æ–‡ä»¶å¤¹åç§°>")
            return
         
        # æ£€æŸ¥ç”¨æˆ·æƒé™
        user_info = self.get_user_privilege(user_id)
        is_admin = user_id in self.allowed_user_ids
        is_svip = user_info and user_info.get("privilege_level") == "svip"  # æ–°å¢SVIPæ£€æŸ¥

        # éç®¡ç†å‘˜ä¸”éSVIPç”¨æˆ·æ£€æŸ¥æƒé™
        if not is_admin and not is_svip:  # ä¿®æ”¹æ£€æŸ¥æ¡ä»¶
            if not user_info:
                self.send_auto_delete_message(update, context, "âŒ æ‚¨æ²¡æœ‰ä½¿ç”¨å¯¼å‡ºåŠŸèƒ½çš„æƒé™ï¼Œè¯·è”ç³»ç®¡ç†å‘˜")
                return
            if search_query.lower() in BANNED_EXPORT_NAMES:
                self.send_auto_delete_message(update, context, f"âŒ ç¦æ­¢å¯¼å‡ºåç§°ä¸º '{search_query}' çš„æ–‡ä»¶å¤¹")
                return
     
            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶
            today = datetime.now().strftime("%Y-%m-%d")
            last_export_date = user_info.get("last_export_date", "")
            export_count = user_info.get("export_count", 0)
            
            # å¦‚æœæ˜¯æ–°çš„ä¸€å¤©ï¼Œé‡ç½®æ¬¡æ•°
            if last_export_date != today:
                export_count = 0
            
            if export_count >= DAILY_EXPORT_LIMIT:
                self.send_auto_delete_message(update, context, f"âŒ æ‚¨ä»Šæ—¥çš„å¯¼å‡ºæ¬¡æ•°å·²è¾¾ä¸Šé™ï¼ˆ{DAILY_EXPORT_LIMIT}æ¬¡ï¼‰ï¼Œè¯·æ˜å¤©å†è¯•æˆ–è”ç³»ç®¡ç†å‘˜å‡çº§æƒé™")
                return
        
        if in_group:
            # å‘é€æç¤ºæ¶ˆæ¯å¹¶ä¿å­˜æ¶ˆæ¯IDä»¥ä¾¿æ’¤å›
            msg = self.send_auto_delete_message(
              update, context,
              f"ğŸ” æ­£åœ¨æœç´¢æ–‡ä»¶å¤¹: '{search_query}'...\nç»“æœå°†é€šè¿‡ç§èŠå‘é€ç»™æ‚¨",
              delay=5
            )
            context.user_data['group_temp_msg_id'] = msg.message_id
            context.user_data['group_chat_id'] = update.message.chat_id  # ä¿å­˜ç¾¤èŠID
        else:
            self.send_auto_delete_message(update, context, f"ğŸ” æ­£åœ¨æœç´¢æ–‡ä»¶å¤¹: '{search_query}'...")

        try:
            results = self.search_database_by_name(search_query)
            if not results:
                self.send_auto_delete_message(update, context, f"âŒ æœªæ‰¾åˆ°åŒ…å« '{search_query}' çš„æ–‡ä»¶å¤¹")
                return
            
            context.user_data['export_search_results'] = results
            context.user_data['export_selected_indices'] = set()
            
            keyboard = []
            max_buttons = 40
            for i, result in enumerate(results[:max_buttons]):
                filename = result["filename"]
                display_name = filename if len(filename) <= 50 else f"{filename[:47]}..."
                keyboard.append([
                    InlineKeyboardButton(f"{i+1}. {display_name}", callback_data=f"export_toggle_{i}")
                ])
            
            action_buttons = [
                InlineKeyboardButton("âœ… å…¨é€‰", callback_data="export_select_all"),
                InlineKeyboardButton("ğŸ”„ åé€‰", callback_data="export_deselect_all"),
                InlineKeyboardButton("ğŸš€ å¯¼å‡º", callback_data="export_confirm"),
                InlineKeyboardButton("âŒ é€€å‡º", callback_data="export_cancel")
            ]
            
            keyboard.append(action_buttons[:2])
            keyboard.append(action_buttons[2:])
            reply_markup = InlineKeyboardMarkup(keyboard)

            if in_group:
                message = context.bot.send_message(
                    chat_id=update.message.chat_id,
                    text=f"âœ… æ‰¾åˆ° {len(results)} ä¸ªåŒ¹é…é¡¹\nè¯·é€‰æ‹©è¦å¯¼å‡ºçš„æ–‡ä»¶å¤¹:",
                    reply_markup=reply_markup
                )
            else:
                message = update.message.reply_text(
                    f"âœ… æ‰¾åˆ° {len(results)} ä¸ªåŒ¹é…é¡¹\nè¯·é€‰æ‹©è¦å¯¼å‡ºçš„æ–‡ä»¶å¤¹:",
                    reply_markup=reply_markup
                )
            
            context.user_data['export_message_id'] = message.message_id
            
            job_context = {
                "chat_id": update.message.chat_id,
                "user_data": context.user_data
            }
            context.job_queue.run_once(
                self.export_timeout, 
                60, 
                context=job_context,
                name=f"export_timeout_{message.message_id}"
            )
        except Exception as e:
            logger.error(f"æœç´¢æ–‡ä»¶å¤¹å¤±è´¥: {e}")
            self.send_auto_delete_message(update, context, f"âŒ æœç´¢å¤±è´¥: {e}")

    def export_choice_callback(self, update: Update, context: CallbackContext):
        """å¤„ç†å¯¼å‡ºé€‰æ‹©çš„å›è°ƒ"""
        query = update.callback_query
        query.answer()
        data = query.data
        
        results = context.user_data.get('export_search_results', [])
        selected_indices = context.user_data.get('export_selected_indices', set())
        
        if not results:
            query.edit_message_text("âŒ é€‰æ‹©è¶…æ—¶ï¼Œè¯·é‡æ–°æœç´¢")
            return
        
        if data.startswith("export_toggle_"):
            try:
                index = int(data.split("_")[2])
                if index in selected_indices:
                    selected_indices.remove(index)
                else:
                    selected_indices.add(index)
            except (ValueError, IndexError):
                pass
        elif data == "export_select_all":
            selected_indices = set(range(len(results)))
        elif data == "export_deselect_all":
            selected_indices = set()
        elif data == "export_confirm":
            self.process_export_selection(update, context, selected_indices)
            return
        elif data == "export_cancel":
            query.edit_message_text("âŒ å¯¼å‡ºæ“ä½œå·²å–æ¶ˆ")
            self.cleanup_export_context(context.user_data)
            return
        
        context.user_data['export_selected_indices'] = selected_indices
        self.update_export_message(update, context, results, selected_indices)
    
    def update_export_message(self, update: Update, context: CallbackContext, results, selected_indices):
        """æ›´æ–°å¯¼å‡ºé€‰æ‹©æ¶ˆæ¯"""
        query = update.callback_query
        selected_count = len(selected_indices)
        
        keyboard = []
        max_buttons = 40
        for i, result in enumerate(results[:max_buttons]):
            filename = result["filename"]
            display_name = filename if len(filename) <= 50 else f"{filename[:47]}..."
            prefix = "âœ… " if i in selected_indices else "â¬œ "
            keyboard.append([
                InlineKeyboardButton(f"{prefix}{i+1}. {display_name}", callback_data=f"export_toggle_{i}")
            ])
        
        action_buttons = [
            InlineKeyboardButton("âœ… å…¨é€‰", callback_data="export_select_all"),
            InlineKeyboardButton("ğŸ”„ åé€‰", callback_data="export_deselect_all"),
            InlineKeyboardButton(f"ğŸš€ å¯¼å‡º({selected_count})", callback_data="export_confirm"),
            InlineKeyboardButton("âŒ å–æ¶ˆ", callback_data="export_cancel")
        ]
        
        keyboard.append(action_buttons[:2])
        keyboard.append(action_buttons[2:])
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        query.edit_message_text(
            text=f"âœ… æ‰¾åˆ° {len(results)} ä¸ªåŒ¹é…é¡¹\nå·²é€‰æ‹© {selected_count} ä¸ªæ–‡ä»¶å¤¹:",
            reply_markup=reply_markup
        )
    
    def export_timeout(self, context: CallbackContext):
        """å¯¼å‡ºé€‰æ‹©è¶…æ—¶å¤„ç†"""
        job = context.job
        if not job or not job.context:
            return
        
        job_context = job.context
        chat_id = job_context.get("chat_id")
        user_data = job_context.get("user_data", {})

        if not chat_id:
            return
        
        if 'export_message_id' in user_data:
            message_id = user_data['export_message_id']
            try:
                self.updater.bot.edit_message_text(chat_id=chat_id, message_id=message_id, text="â±ï¸ æ“ä½œè¶…æ—¶ï¼Œå¯¼å‡ºå·²è‡ªåŠ¨å–æ¶ˆ")
            except Exception:
                pass
        
        self.cleanup_export_context(user_data)
    
    def cleanup_export_context(self, user_data: dict):
        """æ¸…ç†å¯¼å‡ºç›¸å…³çš„ä¸Šä¸‹æ–‡æ•°æ®"""
        keys_to_remove = ['export_search_results', 'export_selected_indices', 'export_message_id', 'group_temp_msg_id']
        for key in keys_to_remove:
            if key in user_data:
                del user_data[key]
    
    def process_export_selection(self, update: Update, context: CallbackContext, selected_indices):
        """å¤„ç†é€‰æ‹©çš„å¯¼å‡ºä»»åŠ¡"""
        query = update.callback_query
        results = context.user_data.get('export_search_results', [])
        if not results or not selected_indices:
            query.edit_message_text("âŒ è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæ–‡ä»¶å¤¹")
            return
            
        user_id = query.from_user.id
        folder_count = len(selected_indices)
        
        # æ£€æŸ¥ç”¨æˆ·æƒé™
        user_info = self.get_user_privilege(user_id)
        is_admin = user_id in self.allowed_user_ids
        is_svip = user_info and user_info.get("privilege_level") == "svip"  # æ–°å¢SVIPæ£€æŸ¥
        
        # æ™®é€šç”¨æˆ·æ£€æŸ¥å¯¼å‡ºé™åˆ¶
        if not is_admin and not is_svip:  # æ™®é€šç”¨æˆ·
            today = datetime.now().strftime("%Y-%m-%d")
            last_export_date = user_info.get("last_export_date", "")
            export_count = user_info.get("export_count", 0)
            
            # å¦‚æœæ˜¯æ–°çš„ä¸€å¤©ï¼Œé‡ç½®æ¬¡æ•°
            if last_export_date != today:
                export_count = 0
            
            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶
            if export_count + folder_count > DAILY_EXPORT_LIMIT:
                query.edit_message_text(f"âŒ æ‚¨ä»Šæ—¥çš„å¯¼å‡ºæ¬¡æ•°å·²è¾¾ä¸Šé™ï¼ˆ{DAILY_EXPORT_LIMIT}æ¬¡ï¼‰ï¼Œå·²ä½¿ç”¨: {export_count}æ¬¡ï¼Œæœ¬æ¬¡è¯·æ±‚: {folder_count}æ¬¡")
                return
            
        # åˆ¤æ–­æ˜¯å¦ç¾¤èŠç¯å¢ƒ
        in_group = 'group_temp_msg_id' in context.user_data

        # å‘é€ä¸´æ—¶æ¶ˆæ¯
        if in_group:
            # æ’¤å›ä¹‹å‰çš„ä¸´æ—¶æ¶ˆæ¯
            try:
                context.bot.delete_message(
                    chat_id=context.user_data['group_chat_id'],
                    message_id=context.user_data['group_temp_msg_id']
                )
            except Exception:
                pass
        
        # å‘é€æ–°æç¤º
        if in_group:
            query.edit_message_text(f"â³ å¼€å§‹å¯¼å‡º {folder_count} ä¸ªæ–‡ä»¶å¤¹åˆ°ç§èŠ...")
            self.auto_delete_message(context, query.message.chat_id, query.message.message_id, 3)
        else:
            query.edit_message_text(f"â³ å¼€å§‹å¯¼å‡º {folder_count} ä¸ªæ–‡ä»¶å¤¹...")
            self.auto_delete_message(context, query.message.chat_id, query.message.message_id, 3)
         
        if 'export_message_id' in context.user_data:
            message_id = context.user_data['export_message_id']
            job_name = f"export_timeout_{message_id}"
            for job in context.job_queue.get_jobs_by_name(job_name):
                job.schedule_removal()
        
        total = folder_count
        progress_messages = []
        
        for i, idx in enumerate(selected_indices):
            selected_folder = results[idx]
            folder_id = selected_folder["file_id"]
            folder_name = selected_folder["filename"]
            folder_path = selected_folder["full_path"]
            
            files = self.pan_client.get_directory_files(folder_id, folder_name)
            if not files:
                logger.warning(f"æ–‡ä»¶å¤¹ä¸ºç©º: {folder_name}")
                continue
                
            # æ¸…ç†æ–‡ä»¶å¤¹åç§°ï¼ˆç§»é™¤éæ³•å­—ç¬¦ï¼‰
            clean_folder_name = re.sub(r'[\\/*?:"<>|]', "", folder_name)
            # åœ¨æ–‡ä»¶å¤¹åç§°åæ·»åŠ æ–œæ 
            common_path = f"{clean_folder_name}/"
            # æ–‡ä»¶åä¿æŒåŸå§‹æ ¼å¼ï¼ˆä¸å¸¦æ–œæ ï¼‰
            file_name = f"{clean_folder_name}.json"
            
            # æ¯å¤„ç†3ä¸ªæ–‡ä»¶å¤¹æ›´æ–°ä¸€æ¬¡è¿›åº¦
            if i % 3 == 0:
                try:
                    msg = context.bot.send_message(
                        chat_id=query.message.chat_id,
                        text=f"â³ æ­£åœ¨å¤„ç†æ–‡ä»¶å¤¹ [{i+1}/{total}]:\nâ”œ åç§°: {folder_name}\nâ”” è·¯å¾„: {folder_path}"
                    )
                    progress_messages.append(msg.message_id)
                except Exception:
                    pass
            
            # è®¡ç®—æ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯
            total_size = sum(file_info["size"] for file_info in files)
            file_count = len(files)
            
            json_data = {
                "usesBase62EtagsInExport": False,
                "commonPath": common_path,
                "totalFilesCount": file_count,
                "totalSize": total_size,
                "formattedTotalSize": format_size(total_size),
                "files": [
                    {"path": file_info["path"], "etag": file_info["etag"], "size": file_info["size"]}
                    for file_info in files
                ]
            }
            
            with open(file_name, "w", encoding="utf-8") as f:
                json.dump(json_data, f, ensure_ascii=False, indent=2)
            
            user_info = self.pan_client.get_user_info()
            nickname = user_info.get("nickname", "æœªçŸ¥ç”¨æˆ·") if user_info else "æœªçŸ¥ç”¨æˆ·"

            # è®¡ç®—å¹³å‡å¤§å°
            avg_size = total_size / file_count if file_count > 0 else 0
            
            caption = (             
                f"âœ¨ åˆ†äº«è€…ï¼š{nickname}\n"
                f"ğŸ“ æ–‡ä»¶å: {clean_folder_name}\n"
                f"ğŸ“ æ–‡ä»¶æ•°: {file_count}\n"
                f"ğŸ’¾ æ€»å¤§å°ï¼š{format_size(total_size)}\n"
                f"ğŸ“Š å¹³å‡å¤§å°ï¼š{format_size(avg_size)}\n\n"
                f"â¤ï¸ 123å› æ‚¨åˆ†äº«æ›´å®Œç¾ï¼"
            )

            # åœ¨å‘é€æ–‡ä»¶å¤„ä¿®æ”¹ä¸ºç§èŠå‘é€
            if in_group:
                # é€šè¿‡ç§èŠå‘é€æ–‡ä»¶
                try:
                    with open(file_name, "rb") as f:
                        context.bot.send_document(
                            chat_id=user_id,  # ç›´æ¥å‘é€ç»™ç”¨æˆ·IDï¼ˆç§èŠï¼‰
                            document=f,
                            filename=file_name,
                            caption=caption
                        )
                except Exception as e:
                    logger.error(f"ç§èŠå‘é€å¤±è´¥: {e}")
                    # åœ¨ç¾¤èŠä¸­æç¤ºç”¨æˆ·
                    context.bot.send_message(
                        chat_id=context.user_data['group_chat_id'],
                        text=f"âŒ æ— æ³•å‘é€ç§èŠæ¶ˆæ¯ï¼Œè¯·å…ˆç§èŠæˆ‘ @{context.bot.username} å¹¶ç‚¹å‡»'å¼€å§‹'"
                    )
            else:
                # ç§èŠç¯å¢ƒæ­£å¸¸å‘é€
                with open(file_name, "rb") as f:
                    context.bot.send_document(
                    chat_id=query.message.chat_id,
                    document=f,
                    filename=file_name,
                    caption=caption
                )               
            
            os.remove(file_name)
        
        # æ›´æ–°ç”¨æˆ·å¯¼å‡ºæ¬¡æ•°
        self.update_user_export_count(user_id, folder_count)
        
        # å¯¼å‡ºå®Œæˆååˆ é™¤æ‰€æœ‰è¿›åº¦æ¶ˆæ¯
        chat_id = query.message.chat_id
        for msg_id in progress_messages:
            try:
                context.bot.delete_message(chat_id=chat_id, message_id=msg_id)
            except Exception:
                pass
        
        self.cleanup_export_context(context.user_data)
 
    @admin_required
    def handle_document(self, update: Update, context: CallbackContext):
        """å¤„ç†æ–‡æ¡£æ¶ˆæ¯"""
        document = update.message.document
        file_name = document.file_name
        
        if document.mime_type != "application/json" and not file_name.endswith(".json"):
            self.send_auto_delete_message(update, context, "âŒ è¯·å‘é€JSONæ ¼å¼çš„æ–‡ä»¶ï¼")
            return
        
        self.send_auto_delete_message(update, context, "ğŸ“¥ æ”¶åˆ°JSONæ–‡ä»¶ï¼Œå¼€å§‹ä¸‹è½½å¹¶è§£æ...")
        
        file = context.bot.get_file(document.file_id)
        file_path = f"temp_{document.file_id}.json"
        file.download(file_path)
        
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                json_data = json.load(f)
            os.remove(file_path)
            self.process_json_file(update, context, json_data)
        except Exception as e:
            logger.error(f"å¤„ç†JSONæ–‡ä»¶å‡ºé”™: {e}")
            self.send_auto_delete_message(update, context, f"âŒ å¤„ç†JSONæ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    @admin_required
    def process_fast_link(self, update: Update, context: CallbackContext, share_link):
        """å¤„ç†ç§’ä¼ é“¾æ¥è½¬å­˜"""
        try:
            files = FastLinkProcessor.parse_share_link(share_link)
            if not files:
                logger.warning("æ— æ³•è§£æç§’ä¼ é“¾æ¥æˆ–é“¾æ¥ä¸­æ— æœ‰æ•ˆæ–‡ä»¶ä¿¡æ¯")
                self.send_auto_delete_message(update, context, "âŒ æ— æ³•è§£æç§’ä¼ é“¾æ¥")
                return
            
            self.send_auto_delete_message(update, context, f"âœ… è§£ææˆåŠŸï¼æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶ï¼Œå¼€å§‹è½¬å­˜...")
            results, filtered_count, elapsed_time, original_total_count, original_total_size = self.transfer_files(update, context, files)
            self.send_transfer_results(update, context, results, filtered_count, elapsed_time, original_total_count, original_total_size)
        except Exception as e:
            logger.error(f"å¤„ç†ç§’ä¼ é“¾æ¥å‡ºé”™: {e}")
            self.send_auto_delete_message(update, context, f"âŒ å¤„ç†ç§’ä¼ é“¾æ¥æ—¶å‡ºé”™: {e}")
    
    @admin_required
    def process_json_file(self, update: Update, context: CallbackContext, json_data):
        """å¤„ç†JSONæ–‡ä»¶è½¬å­˜"""
        try:
            if not isinstance(json_data, dict) or not json_data.get("files"):
                logger.warning("JSONæ ¼å¼æ— æ•ˆï¼Œç¼ºå°‘fileså­—æ®µ")
                self.send_auto_delete_message(update, context, "âŒ JSONæ ¼å¼æ— æ•ˆ")
                return
            
            common_path = json_data.get("commonPath", "").strip()
            if common_path.endswith('/'):
                common_path = common_path[:-1]
            
            files = []
            for file_info in json_data["files"]:
                file_path = file_info.get("path", "")
                if common_path:
                    file_path = f"{common_path}/{file_path}"
                if not is_allowed_file(file_path):
                    continue
                files.append({
                    "etag": file_info.get("etag", ""),
                    "size": int(file_info.get("size", 0)),
                    "file_name": file_path,
                    "is_v2_etag": json_data.get("usesBase62EtagsInExport", False)
                })
            
            self.send_auto_delete_message(update, context, f"âœ… è§£ææˆåŠŸï¼æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶ï¼Œå¼€å§‹è½¬å­˜...")
            results, filtered_count, elapsed_time, original_total_count, original_total_size = self.transfer_files(update, context, files)
            self.send_transfer_results(update, context, results, filtered_count, elapsed_time, original_total_count, original_total_size)
        except Exception as e:
            logger.error(f"å¤„ç†JSONæ–‡ä»¶å‡ºé”™: {e}")
            self.send_auto_delete_message(update, context, f"âŒ å¤„ç†JSONæ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    def transfer_files(self, update: Update, context: CallbackContext, files):
        """è½¬å­˜æ–‡ä»¶åˆ—è¡¨"""
        start_time = time.time()
        results = []
        original_total_count = len(files)
        original_total_size = sum(file_info["size"] for file_info in files)
        filtered_count = 0
        folder_cache = {}
        RATE_LIMIT = TRANSFER_RATE_LIMIT
        last_request_time = time.time()
        
        for i, file_info in enumerate(files):
            file_path = file_info["file_name"]
            file_size = file_info["size"]
            
            if not is_allowed_file(file_path):
                filtered_count += 1
                continue
                
            # æ¯å¤„ç†10ä¸ªæ–‡ä»¶æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
            if i % 10 == 0:
                self.send_auto_delete_message(
                    update, context, 
                    f"â³ æ­£åœ¨å¤„ç†æ–‡ä»¶ [{i+1}/{original_total_count}]\næ–‡ä»¶å: {os.path.basename(file_path)}",
                    delay=5
                )
                
            elapsed = time.time() - last_request_time
            required_delay = max(0, 1.0/RATE_LIMIT - elapsed)
            if required_delay > 0:
                time.sleep(required_delay)
            
            try:
                path_parts = file_path.split('/')
                file_name = path_parts.pop()
                parent_id = self.pan_client.default_save_dir_id
                
                current_path = ""
                for part in path_parts:
                    if not part:
                        continue
                    current_path = f"{current_path}/{part}" if current_path else part
                    cache_key = f"{parent_id}/{current_path}"
                    
                    if cache_key in folder_cache:
                        parent_id = folder_cache[cache_key]
                        continue
                    
                    time.sleep(0.3)
                    folder = self.pan_client.create_folder(parent_id, part)
                    if folder:
                        folder_id = folder["FileId"]
                        folder_cache[cache_key] = folder_id
                        parent_id = folder_id
                
                etag = file_info["etag"]
                if file_info.get("is_v2_etag", False):
                    etag = FastLinkProcessor.optimized_etag_to_hex(etag, True)
                
                last_request_time = time.time()
                result = self.pan_client.rapid_upload(etag, file_size, file_name, parent_id)
                
                if result:
                    results.append({
                        "success": True,
                        "file_name": file_path,
                        "size": file_size,
                        "file_id": result["FileId"]
                    })
                else:
                    results.append({
                        "success": False,
                        "file_name": file_path,
                        "size": file_size,
                        "error": "ç§’ä¼ å¤±è´¥"
                    })
                    time.sleep(1.5)
            except (requests.exceptions.ConnectionError, ConnectionResetError) as e:
                results.append({
                    "success": False,
                    "file_name": file_path,
                    "size": file_size,
                    "error": f"ç½‘ç»œé”™è¯¯: {e}"
                })
                time.sleep(3.0)
            except Exception as e:
                results.append({
                    "success": False,
                    "file_name": file_path,
                    "size": file_size,
                    "error": str(e)
                })
                time.sleep(2.0)
        
        elapsed_time = time.time() - start_time
        return results, filtered_count, elapsed_time, original_total_count, original_total_size
    
    def send_transfer_results(self, update: Update, context: CallbackContext, 
                             results, filtered_count, elapsed_time, 
                             original_total_count, original_total_size):
        """å‘é€è½¬å­˜ç»“æœ"""
        success_count = sum(1 for r in results if r["success"])
        failed_count = len(results) - success_count
        
        original_total_size_gb = original_total_size / (1024 ** 3)
        success_size = sum(r["size"] for r in results if r["success"])
        success_size_gb = success_size / (1024 ** 3)
        
        hours, remainder = divmod(elapsed_time, 3600)
        minutes, seconds = divmod(remainder, 60)
        time_str = f"{int(minutes)}åˆ†{int(seconds)}ç§’"
        if hours > 0:
            time_str = f"{int(hours)}å°æ—¶{time_str}"
        
        result_text = (
            f"ğŸ“Š è½¬å­˜å®Œæˆï¼\n"
            f"â”œ æ–‡ä»¶æ•°é‡: {original_total_count}\n"
            f"â”œ æ–‡ä»¶å¤§å°: {format_size(original_total_size)}\n"
            f"â”œ æˆåŠŸæ•°é‡: {success_count} (å¤§å°: {format_size(success_size)})\n"
            f"â”œ å¤±è´¥æ•°é‡: {failed_count}\n"
            f"â”œ ä¿å­˜ç›®å½•: {DEFAULT_SAVE_DIR or 'æ ¹ç›®å½•'}\n"
            f"â”” è€—æ—¶: {time_str}\n"
        )
        
        if failed_count > 0:
            failed_files = []
            for result in results:
                if not result["success"]:
                    file_name = result["file_name"]
                    failed_files.append(f"â€¢ {file_name}: {result['error']}")
            failed_text = "\n".join(failed_files[:10])
            result_text += f"\nâŒ å¤±è´¥æ–‡ä»¶:\n{failed_text}"
            if failed_count > 10:
                result_text += f"\n...åŠå…¶ä»– {failed_count - 10} ä¸ªå¤±è´¥æ–‡ä»¶"
        
        context.bot.send_message(chat_id=update.message.chat_id, text=result_text)
    
    @admin_required
    def sync_full_command(self, update: Update, context: CallbackContext):
        """å¤„ç†/sync_fullå‘½ä»¤"""
        keyboard = [[
            InlineKeyboardButton("âœ… ç¡®è®¤", callback_data='sync_full_confirm'),
            InlineKeyboardButton("âŒ å–æ¶ˆ", callback_data='sync_full_cancel')
        ]]
        reply_markup = InlineKeyboardMarkup(keyboard)
        message = update.message.reply_text(
            "âš ï¸ ç¡®è®¤è¦æ‰§è¡Œå…¨é‡åŒæ­¥å—ï¼Ÿ\nè¿™å°†æ›´æ–°æ•´ä¸ªåª’ä½“åº“çš„ç›®å½•ç¼“å­˜ï¼Œå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ã€‚",
            reply_markup=reply_markup
        )
        context.user_data['confirmation_message_id'] = message.message_id

    def button_callback(self, update: Update, context: CallbackContext):
        """å¤„ç†æŒ‰é’®å›è°ƒ"""
        query = update.callback_query
        query.answer()
        data = query.data
        
        if data.startswith("export_"):
            self.export_choice_callback(update, context)
        elif data.startswith("sync_full_"):
            chat_id = query.message.chat_id
            message_id = query.message.message_id
            try:
                context.bot.delete_message(chat_id=chat_id, message_id=message_id)
            except Exception:
                pass
            
            if data == 'sync_full_confirm':
                self.execute_full_sync(update, context)
            else:
                context.bot.send_message(chat_id=chat_id, text="âŒ å…¨é‡åŒæ­¥å·²å–æ¶ˆ")

    def execute_full_sync(self, update: Update, context: CallbackContext):
        """æ‰§è¡Œå…¨é‡åŒæ­¥"""
        chat_id = getattr(context, '_chat_id', None)
        self.send_auto_delete_message(update, context, "ğŸ”„ æ­£åœ¨æ‰§è¡Œå…¨é‡åŒæ­¥...", chat_id=chat_id)
        
        try:
            start_time = time.time()
            update_count = self.pan_client.full_sync_directory_cache()
            elapsed = time.time() - start_time
            self.send_auto_delete_message(
                update, context, 
                f"âœ… å…¨é‡åŒæ­¥å®Œæˆï¼\nâ”œ æ›´æ–°ç›®å½•: {update_count} ä¸ª\nâ”” è€—æ—¶: {elapsed:.2f}ç§’",
                chat_id=chat_id
            )
        except Exception as e:
            logger.error(f"å…¨é‡åŒæ­¥å¤±è´¥: {e}")
            self.send_auto_delete_message(update, context, "âŒ å…¨é‡åŒæ­¥å¤±è´¥", chat_id=chat_id)
            
        if hasattr(context, '_chat_id'):
            del context._chat_id

    @admin_required
    def clear_trash_command(self, update: Update, context: CallbackContext):
        """å¤„ç†/clear_trashå‘½ä»¤"""
        self.send_auto_delete_message(update, context, "ğŸ”„ æ­£åœ¨æ¸…ç©ºå›æ”¶ç«™...")
        try:
            if self.pan_client.clear_trash():
                self.send_auto_delete_message(update, context, "âœ… å›æ”¶ç«™å·²æˆåŠŸæ¸…ç©º", delay=5)
            else:
                self.send_auto_delete_message(update, context, "âŒ æ¸…ç©ºå›æ”¶ç«™å¤±è´¥", delay=5)
        except Exception as e:
            logger.error(f"æ¸…ç©ºå›æ”¶ç«™å‡ºé”™: {e}")
            self.send_auto_delete_message(update, context, "âŒ æ¸…ç©ºå›æ”¶ç«™æ—¶å‡ºé”™", delay=5)

    @admin_required
    def process_share_link(self, update: Update, context: CallbackContext, share_url):
        """å¤„ç†123äº‘ç›˜åˆ†äº«é“¾æ¥ï¼ˆä¿ç•™ç›®å½•ç»“æ„ï¼‰"""
        try:
            # åœ¨åå°çº¿ç¨‹ä¸­å¤„ç†è½¬å­˜
            def do_share_transfer():
                try:
                    start_time = time.time()
                    success, failure, results, total_size = self.pan_client.save_share_files(
                        share_url, 
                        self.pan_client.default_save_dir_id
                    )
                    elapsed = time.time() - start_time
                    
                    # æ„å»ºç»“æœæ¶ˆæ¯
                    message = (
                        f"ğŸ“¦ åˆ†äº«é“¾æ¥è½¬å­˜å®Œæˆï¼\n"
                        f"â”œ æˆåŠŸ: {success} æ–‡ä»¶\n"
                        f"â”œ å¤±è´¥: {failure} æ–‡ä»¶\n"
                        f"â”œ æ€»å¤§å°: {format_size(total_size)}\n"
                        f"â”œ ä¿å­˜åˆ°: {DEFAULT_SAVE_DIR}\n"
                        f"â”” è€—æ—¶: {elapsed:.1f}ç§’"
                    )
                    
                    context.bot.send_message(
                        chat_id=update.message.chat_id, 
                        text=message
                    )
                    
                    # å¦‚æœæœ‰å¤±è´¥ï¼Œå‘é€å¤±è´¥è¯¦æƒ…
                    if failure > 0:
                        failed_list = "\n".join(
                            [f"â€¢ {r['file_name']}: {r.get('error', 'æœªçŸ¥é”™è¯¯')}" 
                             for r in results if not r['success']][:5]
                        )
                        if failure > 5:
                            failed_list += f"\n...åŠå…¶ä»–{failure-5}ä¸ªæ–‡ä»¶"
                        
                        context.bot.send_message(
                            chat_id=update.message.chat_id,
                            text=f"âŒ å¤±è´¥æ–‡ä»¶:\n{failed_list}",
                            parse_mode="Markdown"
                        )
                    
                except Exception as e:
                    logger.error(f"å¤„ç†åˆ†äº«é“¾æ¥å‡ºé”™: {e}")
                    self.send_auto_delete_message(
                        update, context, 
                        f"âŒ å¤„ç†åˆ†äº«é“¾æ¥æ—¶å‡ºé”™: {e}",
                        chat_id=update.message.chat_id
                    )
            
            # å¯åŠ¨åå°çº¿ç¨‹å¤„ç†
            threading.Thread(target=do_share_transfer).start()
            self.send_auto_delete_message(
                update, context, 
                "â³ æ­£åœ¨åå°è½¬å­˜æ–‡ä»¶å¹¶ä¿ç•™ç›®å½•ç»“æ„ï¼Œè¯·ç¨å€™...\nå®Œæˆåä¼šé€šçŸ¥ç»“æœ",
                delay=5
            )
            
        except Exception as e:
            logger.error(f"å¤„ç†åˆ†äº«é“¾æ¥å‡ºé”™: {e}")
            self.send_auto_delete_message(update, context, f"âŒ å¤„ç†åˆ†äº«é“¾æ¥æ—¶å‡ºé”™: {e}")

    @admin_required
    def handle_text(self, update: Update, context: CallbackContext):
        """å¤„ç†æ–‡æœ¬æ¶ˆæ¯ - ä»…ä¿ç•™ç§’ä¼ é“¾æ¥å¤„ç†"""
        text = update.message.text.strip()
        
        # ç§’ä¼ é“¾æ¥å¤„ç†
        if (text.startswith(LEGACY_FOLDER_LINK_PREFIX_V1) or 
            text.startswith(LEGACY_FOLDER_LINK_PREFIX_V2) or 
            text.startswith(COMMON_PATH_LINK_PREFIX_V1) or 
            text.startswith(COMMON_PATH_LINK_PREFIX_V2) or
            ('#' in text and '$' in text)):
            self.send_auto_delete_message(update, context, "ğŸ” æ£€æµ‹åˆ°ç§’ä¼ é“¾æ¥ï¼Œå¼€å§‹è§£æ...")
            self.process_fast_link(update, context, text)
        # 123äº‘ç›˜åˆ†äº«é“¾æ¥å¤„ç†
        elif re.search(r'https?://(?:[a-zA-Z0-9-]+\.)*123[a-zA-Z0-9-]*\.[a-z]{2,6}/s/[a-zA-Z0-9\-_]+', text):
            self.send_auto_delete_message(update, context, "ğŸ”— æ£€æµ‹åˆ°123äº‘ç›˜åˆ†äº«é“¾æ¥ï¼Œå¼€å§‹è§£æ...")
            self.process_share_link(update, context, text)
        # 115ç½‘ç›˜åˆ†äº«é“¾æ¥å¤„ç†
        elif re.search(SHARE_LINK_PATTERN, text):
            self.send_auto_delete_message(update, context, "ğŸ”— æ£€æµ‹åˆ°115åˆ†äº«é“¾æ¥ï¼Œå¼€å§‹å¤„ç†...")
            self.handle_115_share_link(update, context, text)
    
    @admin_required
    def add_command(self, update: Update, context: CallbackContext):
        """å¤„ç†/addå‘½ä»¤"""
        args = context.args
        reply_to = update.message.reply_to_message
        chat_id = update.message.chat_id
        message_id = update.message.message_id

        # æƒ…å†µ1ï¼šå›å¤æ¶ˆæ¯æ¨¡å¼
        if reply_to:
            try:
                # è·å–è¢«å›å¤ç”¨æˆ·çš„ä¿¡æ¯
                target_user = reply_to.from_user
                # ç¡®å®šæƒé™çº§åˆ«
                privilege_level = "user"
                if args and args[0].lower() == "svip":
                    privilege_level = "svip"
                # æ·»åŠ ç”¨æˆ·åˆ°æ•°æ®åº“
                with closing(sqlite3.connect(DB_PATH)) as conn:
                    c = conn.cursor()
                    c.execute('''INSERT OR REPLACE INTO user_privileges 
                              (user_id, privilege_level) 
                              VALUES (?, ?)''', 
                              (target_user.id, privilege_level))
                    conn.commit()

                # æ„å»ºå“åº”æ¶ˆæ¯
                name = target_user.first_name or target_user.username or str(target_user.id)
                response = (
                    f"âœ… å·²æ·»åŠ ç”¨æˆ·: {name}\n"
                    f"â”œ ID: `{target_user.id}`\n"
                    f"â”” æƒé™: {privilege_level}"
                )
                # å‘é€å›å¤æ¶ˆæ¯å¹¶å®‰æ’è‡ªåŠ¨åˆ é™¤
                msg = update.message.reply_text(response, parse_mode="Markdown")
                self.auto_delete_message(context, chat_id, msg.message_id, 5)
                # åˆ é™¤ç®¡ç†å‘˜å‘é€çš„å‘½ä»¤æ¶ˆæ¯
                try:
                    context.bot.delete_message(chat_id=chat_id, message_id=message_id)
                except Exception as e:
                    logger.warning(f"æ— æ³•åˆ é™¤å‘½ä»¤æ¶ˆæ¯: {e}")
                return
            except Exception as e:
                logger.error(f"é€šè¿‡å›å¤æ·»åŠ ç”¨æˆ·å¤±è´¥: {e}")
                msg = update.message.reply_text(f"âŒ æ·»åŠ å¤±è´¥: {e}")
                self.auto_delete_message(context, chat_id, msg.message_id, 5)
                return
            
        # æƒ…å†µ2ï¼šä¼ ç»Ÿå‚æ•°æ¨¡å¼
        if not args or len(args) < 1:
            usage = (
                "âŒ ç”¨æ³•:\n"
                "1. å›å¤ç”¨æˆ·æ¶ˆæ¯: `/add [svip]`\n"
                "2. ç›´æ¥æ·»åŠ : `/add [svip] <ç”¨æˆ·ID>`"
            )
            msg = update.message.reply_text(usage, parse_mode="Markdown")
            self.auto_delete_message(context, chat_id, msg.message_id, 5)
            return
        
        try:
            # æ£€æŸ¥æ˜¯å¦æŒ‡å®šäº†æƒé™çº§åˆ«
            if args[0].lower() == "svip":
                if len(args) < 2:
                    update.message.reply_text("âŒ è¯·æä¾›ç”¨æˆ·ID")
                    self.auto_delete_message(context, chat_id, msg.message_id, 5)
                    return
                user_id = int(args[1])
                privilege_level = "svip"
            else:
                user_id = int(args[0])
                privilege_level = "user"
            
            # æ·»åŠ ç”¨æˆ·åˆ°æ•°æ®åº“
            with closing(sqlite3.connect(DB_PATH)) as conn:
                c = conn.cursor()
                c.execute('''INSERT OR REPLACE INTO user_privileges 
                            (user_id, privilege_level) 
                            VALUES (?, ?)''', 
                          (user_id, privilege_level))
                conn.commit()
            response = (
                f"âœ… å·²æ·»åŠ ç”¨æˆ·\n"
                f"â”œ ID: `{user_id}`\n"
                f"â”” æƒé™: {privilege_level}"
            )
            # å‘é€å›å¤æ¶ˆæ¯å¹¶å®‰æ’è‡ªåŠ¨åˆ é™¤
            msg = update.message.reply_text(response, parse_mode="Markdown")
            self.auto_delete_message(context, chat_id, msg.message_id, 5)
            # åˆ é™¤ç®¡ç†å‘˜å‘é€çš„å‘½ä»¤æ¶ˆæ¯
            try:
                context.bot.delete_message(chat_id=chat_id, message_id=message_id)
            except Exception as e:
                logger.warning(f"æ— æ³•åˆ é™¤å‘½ä»¤æ¶ˆæ¯: {e}")
              
        except (ValueError, IndexError):
            msg = update.message.reply_text("âŒ æ— æ•ˆçš„ç”¨æˆ·IDæ ¼å¼")
            self.auto_delete_message(context, chat_id, msg.message_id, 5)
        except Exception as e:
            logger.error(f"æ·»åŠ ç”¨æˆ·å¤±è´¥: {e}")
            msg = update.message.reply_text(f"âŒ æ·»åŠ å¤±è´¥: {e}")
            self.auto_delete_message(context, chat_id, msg.message_id, 5)
    
    @admin_required
    def delete_command(self, update: Update, context: CallbackContext):
        """å¤„ç†/deleteå‘½ä»¤"""
        args = context.args
        reply_to = update.message.reply_to_message
        chat_id = update.message.chat_id
        message_id = update.message.message_id

        # æƒ…å†µ1ï¼šå›å¤æ¶ˆæ¯æ¨¡å¼
        if reply_to:
            try:
                # è·å–è¢«å›å¤ç”¨æˆ·çš„ä¿¡æ¯
                target_user = reply_to.from_user
                # åˆ é™¤ç”¨æˆ·
                with closing(sqlite3.connect(DB_PATH)) as conn:
                    c = conn.cursor()
                    c.execute("DELETE FROM user_privileges WHERE user_id = ?", (target_user.id,))
                    conn.commit()
                    if c.rowcount > 0:
                        # æ„å»ºå“åº”æ¶ˆæ¯
                        name = target_user.first_name or target_user.username or str(target_user.id)
                        response = (
                            f"âœ… å·²åˆ é™¤ç”¨æˆ·: {name}\n"
                            f"â”” ID: `{target_user.id}`"
                        )
                        # å‘é€å›å¤æ¶ˆæ¯å¹¶å®‰æ’è‡ªåŠ¨åˆ é™¤
                        msg = update.message.reply_text(response, parse_mode="Markdown")
                        self.auto_delete_message(context, chat_id, msg.message_id, 5)
                        # åˆ é™¤ç®¡ç†å‘˜å‘é€çš„å‘½ä»¤æ¶ˆæ¯
                        try:
                            context.bot.delete_message(chat_id=chat_id, message_id=message_id)
                        except Exception as e:
                            logger.warning(f"æ— æ³•åˆ é™¤å‘½ä»¤æ¶ˆæ¯: {e}")
                    else:
                        msg = update.message.reply_text(f"âŒ ç”¨æˆ·ä¸å­˜åœ¨: {target_user.id}")
                        self.auto_delete_message(context, chat_id, msg.message_id, 5)
                return
            except Exception as e:
                logger.error(f"é€šè¿‡å›å¤åˆ é™¤ç”¨æˆ·å¤±è´¥: {e}")
                msg = update.message.reply_text(f"âŒ åˆ é™¤å¤±è´¥: {e}")
                self.auto_delete_message(context, chat_id, msg.message_id, 5)
                return
            
        # æƒ…å†µ2ï¼šä¼ ç»Ÿå‚æ•°æ¨¡å¼
        if not args or len(args) < 1:
            usage = (
                "âŒ ç”¨æ³•:\n"
                "1. å›å¤ç”¨æˆ·æ¶ˆæ¯: `/delete`\n"
                "2. ç›´æ¥åˆ é™¤: `/delete <ç”¨æˆ·ID>`"
            )
            msg = update.message.reply_text(usage, parse_mode="Markdown")
            self.auto_delete_message(context, chat_id, msg.message_id, 5)
            return       
        try:
            user_id = int(args[0])
            
            # ä»æ•°æ®åº“åˆ é™¤ç”¨æˆ·
            with closing(sqlite3.connect(DB_PATH)) as conn:
                c = conn.cursor()
                c.execute("DELETE FROM user_privileges WHERE user_id = ?", (user_id,))
                conn.commit()
                
                if c.rowcount > 0:
                    response = (
                        f"âœ… å·²åˆ é™¤ç”¨æˆ·\n"
                        f"â”” ID: `{user_id}`"
                    )
                    # å‘é€å›å¤æ¶ˆæ¯å¹¶å®‰æ’è‡ªåŠ¨åˆ é™¤
                    msg = update.message.reply_text(response, parse_mode="Markdown")
                    self.auto_delete_message(context, chat_id, msg.message_id, 5)
                    # åˆ é™¤ç®¡ç†å‘˜å‘é€çš„å‘½ä»¤æ¶ˆæ¯
                    try:
                        context.bot.delete_message(chat_id=chat_id, message_id=message_id)
                    except Exception as e:
                        logger.warning(f"æ— æ³•åˆ é™¤å‘½ä»¤æ¶ˆæ¯: {e}")
                else:
                    msg = update.message.reply_text(f"âŒ ç”¨æˆ·ä¸å­˜åœ¨: {user_id}")
                    self.auto_delete_message(context, chat_id, msg.message_id, 5)

        except ValueError:
            msg = update.message.reply_text("âŒ æ— æ•ˆçš„ç”¨æˆ·IDæ ¼å¼")
            self.auto_delete_message(context, chat_id, msg.message_id, 5)
        except Exception as e:
            logger.error(f"åˆ é™¤ç”¨æˆ·å¤±è´¥: {e}")
            msg = update.message.reply_text(f"âŒ åˆ é™¤å¤±è´¥: {e}")
            self.auto_delete_message(context, chat_id, msg.message_id, 5)
    
    def info_command(self, update: Update, context: CallbackContext):
        """å¤„ç†/infoå‘½ä»¤ - ä¼˜åŒ–ç‰ˆç”¨æˆ·ä¿¡æ¯"""
        user = update.message.from_user
        user_id = user.id
        chat_id = update.message.chat_id
        chat_type = update.message.chat.type

        # åœ¨ç¾¤èŠä¸­åˆ é™¤ç”¨æˆ·å‘é€çš„/infoæ¶ˆæ¯
        if chat_type in ['group', 'supergroup']:
            try:
                context.bot.delete_message(chat_id=chat_id, message_id=update.message.message_id)
            except Exception:
                pass

        # è·å–ç”¨æˆ·æƒé™ä¿¡æ¯
        user_info = self.get_user_privilege(user_id)
        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å·²æ³¨å†Œ
        if user_id not in self.allowed_user_ids and not user_info:
            message = "âŒ æ‚¨å°šæœªæ³¨å†Œï¼Œæ— æ³•ä½¿ç”¨æ­¤åŠŸèƒ½\nè¯·è”ç³»ç®¡ç†å‘˜æ·»åŠ æ‚¨çš„è´¦æˆ·"
            self.send_auto_delete_message(update, context, message, delay=5)
            return
        
        username = f"@{user.username}" if user.username else "æœªè®¾ç½®"
        first_name = user.first_name or ""
        last_name = user.last_name or ""
        full_name = f"{first_name} {last_name}".strip()          
        
        # è·å–å¯¼å‡ºå†å²
        try:
            with closing(sqlite3.connect(DB_PATH)) as conn:
                conn.row_factory = sqlite3.Row
                c = conn.cursor()
                # ä»Šæ—¥å¯¼å‡ºæ¬¡æ•°
                today = datetime.now().strftime("%Y-%m-%d")
                c.execute("SELECT SUM(folder_count) FROM export_history WHERE user_id = ? AND DATE(export_date) = ?", 
                          (user_id, today))
                today_export = c.fetchone()[0] or 0
                
                # æ€»å¯¼å‡ºæ¬¡æ•°
                c.execute("SELECT SUM(folder_count) FROM export_history WHERE user_id = ?", (user_id,))
                total_export = c.fetchone()[0] or 0
                
                # æœ€åå¯¼å‡ºæ—¶é—´
                c.execute("SELECT MAX(export_date) FROM export_history WHERE user_id = ?", (user_id,))
                last_export = c.fetchone()[0]

                if user_info:
                    join_date = user_info.get("join_date")
                else:
                    c.execute("SELECT MIN(export_date) FROM export_history WHERE user_id = ?", (user_id,))
                    join_date_row = c.fetchone()
                    join_date = join_date_row[0] if join_date_row[0] else None                     
        except Exception as e:
            logger.error(f"æŸ¥è¯¢å¯¼å‡ºå†å²å¤±è´¥: {e}")
            today_export = 0
            total_export = 0
            last_export = None
            join_date = None

        # è®¡ç®—ä¸‹æ¬¡é‡ç½®æ—¶é—´ï¼ˆUTCæ—¶é—´æ¬¡æ—¥0ç‚¹ï¼‰
        now_utc = datetime.now(timezone.utc)
        reset_time = datetime(
            now_utc.year, 
            now_utc.month, 
            now_utc.day,
            tzinfo=timezone.utc
        ) + timedelta(days=1)

        def format_time(dt):
            if not dt:
                return "ä»æœªå¯¼å‡º"
            if isinstance(dt, str):
                dt = datetime.fromisoformat(dt)
            return dt.strftime("%Y-%m-%d %H:%M:%S UTC")
        
        # ç¡®å®šç”¨æˆ·çŠ¶æ€
        if user_id in self.allowed_user_ids:
            status = "ğŸ‘‘ ç®¡ç†å‘˜"
            status_desc = "æ‹¥æœ‰æ‰€æœ‰æƒé™"
            export_limit = "æ— é™åˆ¶"
            remaining = "æ— é™åˆ¶"
        elif user_info and user_info.get("privilege_level") == "svip":
            status = "ğŸŒŸ SVIPç”¨æˆ·"
            status_desc = "é«˜çº§ç‰¹æƒç”¨æˆ·"
            export_limit = "æ— é™åˆ¶"
            remaining = "æ— é™åˆ¶"
        else:
            status = "ğŸ‘¤ æ™®é€šç”¨æˆ·"
            status_desc = "åŸºç¡€æƒé™ç”¨æˆ·"
            remaining = max(0, DAILY_EXPORT_LIMIT - today_export)
            export_limit = f"{DAILY_EXPORT_LIMIT} ä¸ª/å¤© (å‰©ä½™: {remaining})"

        # æ„å»ºç”¨æˆ·ä¿¡æ¯æ¶ˆæ¯
        message_parts = [
            f"<b>ğŸ‘¤ ç”¨æˆ·ä¿¡æ¯</b>",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•",
            f"<b>â”œ ç”¨æˆ·ID:</b> <code>{user_id}</code>",
            f"<b>â”œ ç”¨æˆ·å:</b> {username}",
        ]

        if full_name:
            message_parts.append(f"<b>â”œ æ˜¾ç¤ºåç§°:</b> {full_name}")

        message_parts.extend([
            f"<b>â”œ çŠ¶æ€:</b> {status}",
            f"<b>â”œ çŠ¶æ€æè¿°:</b> {status_desc}",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•",
            f"<b>â”œ å¯¼å‡ºæƒé™:</b>",
            f"   â”œ ä»Šæ—¥å¯¼å‡º: <b>{today_export}</b> ä¸ªJSONæ–‡ä»¶",
            f"   â”œ å‰©ä½™æ¬¡æ•°: <b>{remaining}</b>",
            f"   â”œ æ€»å¯¼å‡ºæ¬¡æ•°: <b>{total_export}</b>",
            f"   â”œ æƒé™é™åˆ¶: {export_limit}",
            f"   â”œ æœ€åå¯¼å‡ºæ—¶é—´: {format_time(last_export)}",
            f"   â”” ä¸‹æ¬¡é‡ç½®: {reset_time.strftime('%Y-%m-%d %H:%M:%S UTC')}",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•",
        ])
        if join_date:
            message_parts.append(f"<b>â”” åŠ å…¥æ—¶é—´:</b> {format_time(join_date)}")
        else:
            message_parts.append(f"<b>â”” åŠ å…¥æ—¶é—´:</b> æœªçŸ¥")

        # æ·»åŠ æç¤ºä¿¡æ¯
        if status == "ğŸ‘¤ æ™®é€šç”¨æˆ·":
            if today_export >= DAILY_EXPORT_LIMIT:
                message_parts.append(f"\nâš ï¸ <i>æ‚¨çš„ä»Šæ—¥å¯¼å‡ºæ¬¡æ•°å·²è¾¾ä¸Šé™({DAILY_EXPORT_LIMIT}æ¬¡)ï¼Œè¯·æ˜å¤©å†è¯•</i>")
            else:
                message_parts.append(f"\nâ„¹ï¸ <i>ä½œä¸ºæ™®é€šç”¨æˆ·ï¼Œæ‚¨æ¯å¤©å¯å¯¼å‡ºæœ€å¤š {DAILY_EXPORT_LIMIT} ä¸ªJSONæ–‡ä»¶</i>")
            message_parts.append("\nğŸ’ <i>è”ç³»ç®¡ç†å‘˜å‡çº§SVIPå¯äº«å—æ— é™åˆ¶å¯¼å‡ºæƒé™</i>")

        # ç»„åˆæ‰€æœ‰æ¶ˆæ¯éƒ¨åˆ†
        message = "\n".join(message_parts)
        self.send_auto_delete_message(update, context, message, delay=10, parse_mode="HTML")

    @admin_required
    def refresh_token_command(self, update: Update, context: CallbackContext):
        """å¤„ç†/refresh_tokenå‘½ä»¤ - å¼ºåˆ¶åˆ·æ–°Token"""
        try:
            # å¼ºåˆ¶è·å–æ–°Token
            if self.pan_client.token_manager.get_new_token():
                # è·å–æ–°çš„Tokenä¿¡æ¯
                new_token = self.pan_client.token_manager.access_token
                new_expiry = self.pan_client.token_manager.token_expiry
                
                # æ„å»ºå“åº”æ¶ˆæ¯
                message = (
                    "âœ… Token å¼ºåˆ¶åˆ·æ–°æˆåŠŸï¼\n"
                    f"â”œ æ–°Token: `{new_token[:12]}...{new_token[-12:]}`\n"
                    f"â”” æœ‰æ•ˆæœŸè‡³: {new_expiry.strftime('%Y-%m-%d %H:%M:%S UTC')}"
                )
            else:
                message = "âŒ Token åˆ·æ–°å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—"
                
            update.message.reply_text(message, parse_mode="Markdown")
            
            # åˆ é™¤ç”¨æˆ·æ¶ˆæ¯ï¼ˆå¦‚æœæ˜¯ç¾¤èŠï¼‰
            if update.message.chat.type in ['group', 'supergroup']:
                try:
                    context.bot.delete_message(
                        chat_id=update.message.chat_id,
                        message_id=update.message.message_id
                    )
                except Exception:
                    pass
                    
        except Exception as e:
            logger.error(f"åˆ·æ–°Tokenå¤±è´¥: {e}")
            self.send_auto_delete_message(update, context, f"âŒ åˆ·æ–°Tokenå¤±è´¥: {e}")

    @admin_required
    def transport_command(self, update: Update, context: CallbackContext):
        """å¤„ç†/transportå‘½ä»¤ - è¿ç§»115æ–‡ä»¶åˆ°123äº‘ç›˜"""
        args = context.args
        source_path = DEFAULT_SOURCE_PATH
        
        # è§£æå‚æ•°
        if args and args[0] != "é»˜è®¤":
            source_path = ' '.join(args).strip()
        
        self.send_auto_delete_message(update, context, f"ğŸš€ å¼€å§‹è¿ç§»ä»»åŠ¡...\næºè·¯å¾„: {source_path}")
        
        try:
            # åˆå§‹åŒ–è¿ç§»å·¥å…·
            transfer = Pan115Transfer(
                self.pan_client, 
                self.pan_client.token_manager.access_token
            )
            
            # æ‰§è¡Œè¿ç§»
            success, report = transfer.transfer_files(source_path)
            
            # å‘é€ç»“æœï¼ˆä¸è‡ªåŠ¨åˆ é™¤ï¼‰
            context.bot.send_message(chat_id=update.message.chat_id, text=report)
        except Exception as e:
            error_msg = f"è¿ç§»è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}"
            logger.error(error_msg)
            self.send_auto_delete_message(update, context, f"âŒ è¿ç§»å¤±è´¥!\n{error_msg}")

    @admin_required
    def clear_command(self, update: Update, context: CallbackContext):
        """å¤„ç†/clearå‘½ä»¤ - æ¸…ç©ºä¸­è½¬ç«™"""
        self.send_auto_delete_message(update, context, f"ğŸ§¹ æ­£åœ¨æ¸…ç©ºæˆ‘çš„æ¥æ”¶ç›®å½•: {DEFAULT_SOURCE_PATH}...")
        try:
            transfer = Pan115Transfer(
                self.pan_client, 
                self.pan_client.token_manager.access_token
            )
            if transfer.clear_115_directory():
                self.send_auto_delete_message(update, context, f"âœ… æˆ‘çš„æ¥æ”¶ç›®å½•å·²æ¸…ç©ºï¼", delay=5)
            else:
                self.send_auto_delete_message(update, context, "âŒ æ¸…ç©ºå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—", delay=5)
        except Exception as e:
            error_msg = f"æ¸…ç©ºä¸­è½¬ç«™æ—¶å‡ºé”™: {str(e)}"
            logger.error(error_msg)
            self.send_auto_delete_message(update, context, f"âŒ {error_msg}", delay=5)

    @admin_required
    def handle_115_share_link(self, update: Update, context: CallbackContext, text):
        """å¤„ç†115åˆ†äº«é“¾æ¥"""
        self.send_auto_delete_message(update, context, f"ğŸ”— æ”¶åˆ°115åˆ†äº«é“¾æ¥ï¼Œæ­£åœ¨å¤„ç†...")
        
        try:
            # åˆå§‹åŒ–è¿ç§»å·¥å…·
            transfer = Pan115Transfer(
                self.pan_client, 
                self.pan_client.token_manager.access_token
            )
            
            # ä¿å­˜åˆ†äº«åˆ°115
            success = transfer.save_share_to_115(text)
            
            if success:
                # ç­‰å¾…æ–‡ä»¶å¤„ç† - å‡å°‘ç­‰å¾…æ—¶é—´
                self.send_auto_delete_message(update, context, "âœ… åˆ†äº«å†…å®¹å·²ä¿å­˜åˆ°æˆ‘çš„æ¥æ”¶!\nç­‰å¾…5ç§’è®©æ–‡ä»¶å¤„ç†å®Œæˆ...", delay=5)
                time.sleep(5)
                
                # è¿ç§»ä¸­è½¬ç«™å†…å®¹
                self.send_auto_delete_message(update, context, "ğŸš€ å¼€å§‹è¿ç§»...", delay=5)
                success, report = transfer.transfer_files(DEFAULT_SOURCE_PATH)
                
                # å‘é€ç»“æœï¼ˆä¸è‡ªåŠ¨åˆ é™¤ï¼‰
                context.bot.send_message(chat_id=update.message.chat_id, text=report)
            else:
                self.send_auto_delete_message(update, context, "âŒ ä¿å­˜åˆ†äº«å†…å®¹å¤±è´¥ï¼Œè¯·æ£€æŸ¥é“¾æ¥å’Œå¯†ç æ˜¯å¦æ­£ç¡®", delay=5)
        except Exception as e:
            error_msg = f"å¤„ç†åˆ†äº«é“¾æ¥æ—¶å‡ºé”™: {str(e)}"
            logger.error(error_msg)
            self.send_auto_delete_message(update, context, f"âŒ å¤„ç†åˆ†äº«é“¾æ¥å¤±è´¥!\n{error_msg}", delay=5)

def main():
    # æ·»åŠ æˆæƒä¿¡æ¯æç¤º
    logger.info("=============================================")
    logger.info("123äº‘ç›˜æœºå™¨äºº - ä¸“ä¸šç‰ˆ")
    logger.info(f"ç‰ˆæœ¬: {VERSION}")
    logger.info("æˆæƒéªŒè¯é€šè¿‡ï¼Œæ­£åœ¨å¯åŠ¨æœåŠ¡...")
    logger.info("=============================================")
    # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
    BOT_TOKEN = os.getenv("TG_BOT_TOKEN","")
    CLIENT_ID = os.getenv("PAN_CLIENT_ID","")
    CLIENT_SECRET = os.getenv("PAN_CLIENT_SECRET","")
    ADMIN_USER_IDS = [int(id.strip()) for id in os.getenv("TG_ADMIN_USER_IDS", "").split(",") if id.strip()]
    
    if not BOT_TOKEN:
        logger.error("âŒ ç¯å¢ƒå˜é‡ TG_BOT_TOKEN æœªè®¾ç½®")
        return
    
    if not CLIENT_ID:
        logger.error("âŒ ç¯å¢ƒå˜é‡ PAN_CLIENT_ID æœªè®¾ç½®")
        return
    
    if not CLIENT_SECRET:
        logger.error("âŒ ç¯å¢ƒå˜é‡ PAN_CLIENT_SECRET æœªè®¾ç½®")
        return
    
    logger.info("åˆå§‹åŒ–123äº‘ç›˜å®¢æˆ·ç«¯...")
    pan_client = Pan123Client(CLIENT_ID, CLIENT_SECRET)
    
    if not pan_client.token_manager.access_token:
        logger.error("âŒ æ— æ³•è·å–æœ‰æ•ˆçš„Token")
        return
    
    logger.info("åˆå§‹åŒ–Telegramæœºå™¨äºº...")
    bot_handler = TelegramBotHandler(BOT_TOKEN, pan_client, ADMIN_USER_IDS)
    bot_handler.start()

if __name__ == "__main__":
    main()
