import warnings

warnings.filterwarnings("ignore", message="python-telegram-bot is using upstream urllib3.*")

warnings.filterwarnings("ignore", message=".*pkg_resources is deprecated.*", category=UserWarning)
import os
import re
import json
import time
import logging
import requests
from datetime import datetime, timedelta, timezone
from telegram import Update
from telegram.ext import Updater, MessageHandler, Filters, CallbackContext, CommandHandler
from functools import wraps
import urllib3
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# ç¦ç”¨SSLè­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    format='%(asctime)s - %(levelname)s - %(message)s',
    level=logging.INFO,
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# å¿½ç•¥ç¬¬ä¸‰æ–¹åº“çš„è­¦å‘Š
logging.getLogger("telegram").setLevel(logging.WARNING)
logging.getLogger("apscheduler").setLevel(logging.WARNING)
logging.getLogger("urllib3").setLevel(logging.WARNING)

# 123äº‘ç›˜APIé…ç½®
PAN_HOST = "https://www.123pan.com"
API_PATHS = {
    "TOKEN": "/api/v1/access_token",
    "LIST_FILES_V2": "/api/v2/file/list",  # è·å–æ–‡ä»¶åˆ—è¡¨V2
    "FILE_INFOS": "/api/v1/file/infos",    # æ‰¹é‡è·å–æ–‡ä»¶ä¿¡æ¯
    "UPLOAD_REQUEST": "/b/api/file/upload_request",
}

# å¼€æ”¾å¹³å°åœ°å€
OPEN_API_HOST = "https://open-api.123pan.com"

# ç§’ä¼ é“¾æ¥å‰ç¼€
LEGACY_FOLDER_LINK_PREFIX_V1 = "123FSLinkV1$"
LEGACY_FOLDER_LINK_PREFIX_V2 = "123FSLinkV2$"
COMMON_PATH_LINK_PREFIX_V1 = "123FLCPV1$"
COMMON_PATH_LINK_PREFIX_V2 = "123FLCPV2$"
COMMON_PATH_DELIMITER = "%"

# Base62å­—ç¬¦é›†
BASE62_CHARS = "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ"

class TokenManager:
    """ç®¡ç†API tokençš„è·å–å’Œç¼“å­˜"""
    def __init__(self, client_id, client_secret):
        self.client_id = client_id
        self.client_secret = client_secret
        self.session = self._create_session()
        self.access_token = None
        self.token_expiry = None
    
    def _create_session(self):
        """åˆ›å»ºå¸¦é‡è¯•æœºåˆ¶çš„Session"""
        session = requests.Session()
        
        # é…ç½®é‡è¯•ç­–ç•¥
        retry_strategy = Retry(
            total=5,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504],
            allowed_methods=["GET", "POST"]
        )
        
        adapter = HTTPAdapter(
            max_retries=retry_strategy,
            pool_connections=100,
            pool_maxsize=100
        )
        
        session.mount("https://", adapter)
        session.mount("http://", adapter)
        
        # ç¦ç”¨SSLéªŒè¯
        session.verify = False
        return session
    
    def get_new_token(self):
        """è·å–æ–°tokenï¼ˆä½¿ç”¨å¼€æ”¾å¹³å°APIï¼‰"""
        try:
            logger.info("æ­£åœ¨è·å–æ–°Token...")
            url = f"{OPEN_API_HOST}{API_PATHS['TOKEN']}"
            payload = {
                "clientID": self.client_id,
                "clientSecret": self.client_secret
            }
            
            headers = {
                "Content-Type": "application/json",
                "Platform": "open_platform"
            }
            
            response = self.session.post(
                url,
                json=payload,
                headers=headers,
                timeout=20
            )
            
            if response.status_code != 200:
                logger.error(f"è®¤è¯å¤±è´¥: {response.status_code}")
                return False
            
            data = response.json()
            
            if data.get("code") != 0:
                logger.error(f"APIé”™è¯¯: {data.get('code')} - {data.get('message')}")
                return False
            
            # æå–å¹¶ä¿å­˜token
            self.access_token = data["data"]["accessToken"]
            
            # è§£æè¿‡æœŸæ—¶é—´å­—ç¬¦ä¸²
            expired_at_str = data["data"]["expiredAt"]
            
            # ä¿®å¤æ—¶é—´è§£æé—®é¢˜
            if expired_at_str.endswith('Z'):
                self.token_expiry = datetime.fromisoformat(expired_at_str[:-1]).replace(tzinfo=timezone.utc)
            elif '+' in expired_at_str or '-' in expired_at_str:
                dt = datetime.fromisoformat(expired_at_str)
                self.token_expiry = dt.astimezone(timezone.utc)
            else:
                self.token_expiry = datetime.fromisoformat(expired_at_str).replace(tzinfo=timezone.utc)
            
            logger.info(f"æ›´æ–°Token\nâ””â”€æœ‰æ•ˆæœŸè‡³: {self.token_expiry} (UTC)")
            return True
            
        except Exception as e:
            logger.error(f"è·å–Tokenå¤±è´¥: {str(e)}")
            return False
    
    def ensure_token_valid(self):
        """ç¡®ä¿tokenæœ‰æ•ˆ"""
        current_time = datetime.now(timezone.utc)
        if not self.access_token or not self.token_expiry or current_time >= self.token_expiry - timedelta(minutes=5):
            logger.info("Tokenæ— æ•ˆæˆ–å³å°†è¿‡æœŸï¼Œåˆ·æ–°ä¸­...")
            return self.get_new_token()
        return True
    
    def get_auth_header(self):
        """è·å–è®¤è¯å¤´"""
        if not self.ensure_token_valid():
            raise Exception("æ— æ³•è·å–æœ‰æ•ˆçš„Token")
        return {
            "Authorization": f"Bearer {self.access_token}",
            "Platform": "open_platform",
            "Content-Type": "application/json"
        }

class Pan123Client:
    def __init__(self, client_id, client_secret):
        self.token_manager = TokenManager(client_id, client_secret)
        self.session = self._create_session()
        self.last_api_call = 0  # è®°å½•æœ€åä¸€æ¬¡APIè°ƒç”¨æ—¶é—´
        self.api_rate_limit = 2  # é™ä½APIè°ƒç”¨é¢‘ç‡
        self.retry_delay = 2.0  # å¢åŠ é™æµæ—¶é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
    
    def _create_session(self):
        """åˆ›å»ºå¸¦é‡è¯•æœºåˆ¶çš„Session"""
        session = requests.Session()
        
        # é…ç½®é‡è¯•ç­–ç•¥
        retry_strategy = Retry(
            total=5,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504],
            allowed_methods=["GET", "POST"]
        )
        
        adapter = HTTPAdapter(
            max_retries=retry_strategy,
            pool_connections=100,
            pool_maxsize=100
        )
        
        session.mount("https://", adapter)
        session.mount("http://", adapter)
        
        # ç¦ç”¨SSLéªŒè¯
        session.verify = False
        return session

    # æ·»åŠ APIè°ƒç”¨æ§åˆ¶æ–¹æ³•
    def _call_api(self, method, url, **kwargs):
        """æ§åˆ¶APIè°ƒç”¨é¢‘ç‡ï¼Œé¿å…é™æµ"""
        retry_count = 0
        max_retries = 3
        
        while retry_count < max_retries:
            try:
                # è®¡ç®—è·ç¦»ä¸Šæ¬¡è°ƒç”¨çš„æ—¶é—´
                elapsed = time.time() - self.last_api_call
                required_delay = 1.0 / self.api_rate_limit
                
                # å¦‚æœè°ƒç”¨è¿‡å¿«ï¼Œç­‰å¾…è¶³å¤Ÿçš„æ—¶é—´
                if elapsed < required_delay:
                    wait_time = required_delay - elapsed
                    logger.debug(f"APIè°ƒç”¨è¿‡å¿«ï¼Œç­‰å¾… {wait_time:.2f} ç§’")
                    time.sleep(wait_time)
                
                # å‘é€APIè¯·æ±‚
                response = self.session.request(method, url, **kwargs)
                self.last_api_call = time.time()
                
                # æ£€æŸ¥æ˜¯å¦è¢«é™æµ
                if response.status_code == 429:
                    logger.warning(f"APIé™æµï¼Œç­‰å¾… {self.retry_delay} ç§’åé‡è¯•...")
                    time.sleep(self.retry_delay)
                    continue
                
                return response
                
            except (requests.exceptions.SSLError, requests.exceptions.ConnectionError) as e:
                retry_count += 1
                logger.error(f"âŒ SSL/è¿æ¥é”™è¯¯: {str(e)}ï¼Œé‡è¯• {retry_count}/{max_retries}")
                time.sleep(2 ** retry_count)  # æŒ‡æ•°é€€é¿
            except Exception as e:
                logger.error(f"APIè°ƒç”¨å‡ºé”™: {str(e)}")
                return None
        
        logger.error(f"APIè°ƒç”¨å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° {max_retries}")
        return None
    
    def _get_auth_headers(self):
        """è·å–è®¤è¯å¤´ï¼ˆæ·»åŠ åŸå§‹è„šæœ¬ä¸­çš„é¢å¤–å¤´ä¿¡æ¯ï¼‰"""
        auth_header = self.token_manager.get_auth_header()
        return {
            **auth_header,
            "platform": "web",
            "App-Version": "3",
            "Origin": PAN_HOST,
            "Referer": f"{PAN_HOST}/",
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36"
        }
    
    
    def create_folder(self, parent_id, folder_name, retry_count=3):
        """åˆ›å»ºæ–‡ä»¶å¤¹ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
        logger.info(f"åˆ›å»ºæ–‡ä»¶å¤¹: '{folder_name}' (çˆ¶ID: {parent_id})")
        
        for attempt in range(retry_count):
            try:
                url = f"{PAN_HOST}{API_PATHS['UPLOAD_REQUEST']}"
                payload = {
                    "driveId": 0,
                    "etag": "",
                    "fileName": folder_name,
                    "parentFileId": int(parent_id),
                    "size": 0,
                    "type": 1,
                    "NotReuse": True,
                    "RequestSource": None,
                    "duplicate": 1,
                    "event": "newCreateFolder",
                    "operateType": 1
                }
                headers = self._get_auth_headers()
                
                # ä½¿ç”¨æ›´å¥å£®çš„è¯·æ±‚æ–¹å¼
                response = self.session.post(
                    url, 
                    json=payload, 
                    headers=headers, 
                    timeout=20,
                    verify=False  # æ˜ç¡®ç¦ç”¨SSLéªŒè¯
                )
                
                data = response.json()
                
                if data.get("code") == 0 and data["data"].get("Info", {}).get("FileId"):
                    folder_id = data["data"]["Info"]["FileId"]
                    logger.info(f"âœ… æ–‡ä»¶å¤¹åˆ›å»ºæˆåŠŸ: '{folder_name}' (ID: {folder_id})")
                    return data["data"]["Info"]
                else:
                    error_msg = data.get("message", "æœªçŸ¥é”™è¯¯")
                    logger.error(f"âŒ åˆ›å»ºæ–‡ä»¶å¤¹å¤±è´¥: {error_msg}")
                    if attempt < retry_count - 1:
                        time.sleep(1)  # ç­‰å¾…åé‡è¯•
                        continue
                    return None
            except (requests.exceptions.SSLError, requests.exceptions.ConnectionError) as e:
                logger.error(f"âŒ SSL/è¿æ¥é”™è¯¯: {str(e)}")
                if attempt < retry_count - 1:
                    logger.info(f"ç­‰å¾…1ç§’åé‡è¯• ({attempt+1}/{retry_count})...")
                    time.sleep(1)
                    continue
                return None
            except Exception as e:
                logger.error(f"âŒ åˆ›å»ºæ–‡ä»¶å¤¹è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
                if attempt < retry_count - 1:
                    time.sleep(1)
                    continue
                return None
        return None
    
    def rapid_upload(self, etag, size, file_name, parent_id, retry_count=3):
        """ç§’ä¼ æ–‡ä»¶ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
        logger.info(f"å°è¯•ç§’ä¼ æ–‡ä»¶: '{file_name}' (å¤§å°: {size} bytes, çˆ¶ID: {parent_id})")
        
        for attempt in range(retry_count):
            try:
                url = f"{PAN_HOST}{API_PATHS['UPLOAD_REQUEST']}"
                payload = {
                    "driveId": 0,
                    "etag": etag,
                    "fileName": file_name,
                    "parentFileId": int(parent_id),
                    "size": int(size),
                    "type": 0,
                    "NotReuse": False,
                    "RequestSource": None,
                    "duplicate": 1,
                    "event": "rapidUpload",
                    "operateType": 1
                }
                headers = self._get_auth_headers()
                
                # ä½¿ç”¨æ›´å¥å£®çš„è¯·æ±‚æ–¹å¼
                response = self.session.post(
                    url, 
                    json=payload, 
                    headers=headers, 
                    timeout=20,
                    verify=False  # æ˜ç¡®ç¦ç”¨SSLéªŒè¯
                )
                
                data = response.json()
                
                if data.get("code") == 0 and data["data"].get("Info", {}).get("FileId"):
                    file_id = data["data"]["Info"]["FileId"]
                    logger.info(f"âœ… æ–‡ä»¶ç§’ä¼ æˆåŠŸ: '{file_name}' (ID: {file_id})")
                    return data["data"]["Info"]
                else:
                    error_msg = data.get("message", "æœªçŸ¥é”™è¯¯")
                    logger.error(f"âŒ æ–‡ä»¶ç§’ä¼ å¤±è´¥: {error_msg}")
                    if attempt < retry_count - 1:
                        time.sleep(1)
                        continue
                    return None
            except (requests.exceptions.SSLError, requests.exceptions.ConnectionError) as e:
                logger.error(f"âŒ SSL/è¿æ¥é”™è¯¯: {str(e)}")
                if attempt < retry_count - 1:
                    logger.info(f"ç­‰å¾…1ç§’åé‡è¯• ({attempt+1}/{retry_count})...")
                    time.sleep(1)
                    continue
                return None
            except Exception as e:
                logger.error(f"âŒ ç§’ä¼ è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
                if attempt < retry_count - 1:
                    time.sleep(1)
                    continue
                return None
        return None
    
    def search_folder_recursive(self, folder_name, parent_id=0, current_path=""):
        """é€’å½’æœç´¢æ•´ä¸ªäº‘ç›˜ç»“æ„ä¸­çš„æ–‡ä»¶å¤¹"""
        logger.info(f"æœç´¢æ–‡ä»¶å¤¹: '{folder_name}' (çˆ¶ID: {parent_id}, å½“å‰è·¯å¾„: '{current_path}')")
        
        # ç¡®ä¿tokenæœ‰æ•ˆ
        if not self.token_manager.ensure_token_valid():
            logger.error("æ— æ³•è·å–æœ‰æ•ˆçš„Token")
            return None
        
        # ä½¿ç”¨V2 APIè·å–ç›®å½•å†…å®¹
        last_file_id = 0
        while True:
            url = f"{OPEN_API_HOST}{API_PATHS['LIST_FILES_V2']}"
            params = {
                "parentFileId": parent_id,
                "trashed": 0,  # æ’é™¤å›æ”¶ç«™æ–‡ä»¶
                "limit": 100,
                "lastFileId": last_file_id
            }
            headers = self.token_manager.get_auth_header()
            
            try:
                # ä½¿ç”¨é™æµä¿æŠ¤çš„APIè°ƒç”¨
                response = self._call_api("GET", url, params=params, headers=headers, timeout=30)
                if not response or response.status_code != 200:
                    return None
                
                data = response.json()
                if data.get("code") != 0:
                    return None
                
                # æ£€æŸ¥å½“å‰ç›®å½•ä¸‹çš„æ–‡ä»¶å¤¹
                for item in data["data"].get("fileList", []):
                    if item["type"] != 1:  # è·³è¿‡éæ–‡ä»¶å¤¹
                        continue
                        
                    item_path = f"{current_path}/{item['filename']}" if current_path else item['filename']
                    
                    # æ£€æŸ¥æ˜¯å¦åŒ¹é…ç›®æ ‡æ–‡ä»¶å¤¹
                    if item["filename"] == folder_name:
                        logger.info(f"âœ… æ‰¾åˆ°æ–‡ä»¶å¤¹: {folder_name} (ID: {item['fileId']}, è·¯å¾„: '{item_path}')")
                        return {
                            "fileId": item["fileId"],
                            "filename": item["filename"],
                            "path": item_path
                        }
                    
                    # é€’å½’æœç´¢å­ç›®å½•
                    time.sleep(0.5)  # å¢åŠ å»¶è¿Ÿé¿å…é™æµ
                    found_folder = self.search_folder_recursive(
                        folder_name,
                        item["fileId"],
                        item_path
                    )
                    if found_folder:
                        return found_folder
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ›´å¤šé¡µé¢
                last_file_id = data["data"].get("lastFileId", -1)
                if last_file_id == -1:
                    break
                    
            except Exception as e:
                logger.error(f"æœç´¢æ–‡ä»¶å¤¹å‡ºé”™: {str(e)}")
                return None
        
        return None
    
    def get_directory_files(self, directory_id=0, base_path="", current_path=""):
        """
        è·å–ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶ï¼ˆä½¿ç”¨V2 APIï¼‰
        base_path: åŸºç¡€è·¯å¾„ï¼ˆæœç´¢åˆ°çš„æ–‡ä»¶å¤¹åç§°ï¼‰
        current_path: å½“å‰ç›¸å¯¹è·¯å¾„
        """
        logger.info(f"è·å–ç›®å½•å†…å®¹ (ID: {directory_id}, åŸºç¡€è·¯å¾„: '{base_path}', å½“å‰è·¯å¾„: '{current_path}')")
        all_files = []
        
        # ç¡®ä¿tokenæœ‰æ•ˆ
        if not self.token_manager.ensure_token_valid():
            logger.error("æ— æ³•è·å–æœ‰æ•ˆçš„Token")
            return []
        
        # ä½¿ç”¨V2 APIè·å–ç›®å½•å†…å®¹
        last_file_id = 0  # åˆå§‹å€¼ä¸º0
        while True:
            url = f"{OPEN_API_HOST}{API_PATHS['LIST_FILES_V2']}"
            params = {
                "parentFileId": directory_id,
                "trashed": 0,  # æ’é™¤å›æ”¶ç«™æ–‡ä»¶
                "limit": 100,   # æœ€å¤§ä¸è¶…è¿‡100
                "lastFileId": last_file_id
            }
            headers = self.token_manager.get_auth_header()
            
            try:
                logger.debug(f"è¯·æ±‚ç›®å½•åˆ—è¡¨: {url}, å‚æ•°: {params}")
                
                # ä½¿ç”¨é™æµä¿æŠ¤çš„APIè°ƒç”¨
                response = self._call_api("GET", url, params=params, headers=headers, timeout=30)
                if not response:
                    logger.error(f"è·å–ç›®å½•åˆ—è¡¨å¤±è´¥")
                    return all_files
                
                # è°ƒè¯•æ—¥å¿—
                logger.debug(f"å“åº”çŠ¶æ€ç : {response.status_code}")
                if response.status_code != 200:
                    logger.error(f"è·å–ç›®å½•åˆ—è¡¨å¤±è´¥: HTTP {response.status_code}")
                    return all_files
                
                try:
                    data = response.json()
                except json.JSONDecodeError as e:
                    logger.error(f"å“åº”JSONè§£æå¤±è´¥: {str(e)}")
                    logger.error(f"å®Œæ•´å“åº”: {response.text}")
                    return all_files
                
                if data.get("code") != 0:
                    error_msg = data.get("message", "æœªçŸ¥é”™è¯¯")
                    
                    # å¦‚æœæ˜¯é™æµé”™è¯¯ï¼Œç­‰å¾…åé‡è¯•
                    if "æ“ä½œé¢‘ç¹" in error_msg or "é™æµ" in error_msg:
                        logger.warning(f"APIé™æµ: {error_msg}, ç­‰å¾… {self.retry_delay} ç§’åé‡è¯•...")
                        time.sleep(self.retry_delay)
                        continue
                    
                    logger.error(f"APIé”™è¯¯: {error_msg}")
                    return all_files
                
                # å¤„ç†å½“å‰é¡µçš„æ–‡ä»¶
                for item in data["data"].get("fileList", []):
                    # æ’é™¤å›æ”¶ç«™æ–‡ä»¶
                    if item.get("trashed", 1) != 0:
                        continue
                    
                    # æ„å»ºæ–‡ä»¶ç›¸å¯¹è·¯å¾„
                    if current_path:
                        file_path = f"{current_path}/{item['filename']}"
                    else:
                        file_path = item['filename']
                    
                    if item["type"] == 0:  # æ–‡ä»¶
                        file_info = {
                            "path": file_path,  # å­˜å‚¨å®Œæ•´ç›¸å¯¹è·¯å¾„
                            "etag": item["etag"],
                            "size": item["size"]
                        }
                        all_files.append(file_info)
                    elif item["type"] == 1:  # æ–‡ä»¶å¤¹
                        # æ„å»ºå­ç›®å½•è·¯å¾„
                        if current_path:
                            sub_path = f"{current_path}/{item['filename']}"
                        else:
                            sub_path = item['filename']
                        
                        # é€’å½’è·å–å­ç›®å½•ï¼ˆæ·»åŠ å»¶è¿Ÿé¿å…é™æµï¼‰
                        time.sleep(0.5)  # å¢åŠ å»¶è¿Ÿ
                        sub_files = self.get_directory_files(
                            item["fileId"],
                            base_path,
                            sub_path
                        )
                        all_files.extend(sub_files)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ›´å¤šé¡µé¢
                last_file_id = data["data"].get("lastFileId", -1)
                if last_file_id == -1:
                    break
                    
            except Exception as e:
                logger.error(f"è·å–ç›®å½•åˆ—è¡¨å‡ºé”™: {str(e)}", exc_info=True)
                return all_files
        
        logger.info(f"æ‰¾åˆ° {len(all_files)} ä¸ªæ–‡ä»¶ (ID: {directory_id})")
        return all_files

class FastLinkProcessor:
    @staticmethod
    def parse_share_link(share_link):
        """è§£æç§’ä¼ é“¾æ¥"""
        logger.info("è§£æç§’ä¼ é“¾æ¥...")
        common_base_path = ""
        is_common_path_format = False
        is_v2_etag_format = False
        
        if share_link.startswith(COMMON_PATH_LINK_PREFIX_V2):
            is_common_path_format = True
            is_v2_etag_format = True
            share_link = share_link[len(COMMON_PATH_LINK_PREFIX_V2):]
        elif share_link.startswith(COMMON_PATH_LINK_PREFIX_V1):
            is_common_path_format = True
            share_link = share_link[len(COMMON_PATH_LINK_PREFIX_V1):]
        
        if is_common_path_format:
            delimiter_pos = share_link.find(COMMON_PATH_DELIMITER)
            if delimiter_pos > -1:
                common_base_path = share_link[:delimiter_pos]
                share_link = share_link[delimiter_pos + 1:]
        
        if not is_common_path_format:
            if share_link.startswith(LEGACY_FOLDER_LINK_PREFIX_V2):
                is_v2_etag_format = True
                share_link = share_link[len(LEGACY_FOLDER_LINK_PREFIX_V2):]
            elif share_link.startswith(LEGACY_FOLDER_LINK_PREFIX_V1):
                share_link = share_link[len(LEGACY_FOLDER_LINK_PREFIX_V1):]
        
        files = []
        for s_link in share_link.split('$'):
            parts = s_link.split('#')
            if len(parts) < 3:
                continue
            
            etag = parts[0]
            size = parts[1]
            file_path = '#'.join(parts[2:])
            
            if is_common_path_format and common_base_path:
                file_path = common_base_path + file_path
            
            files.append({
                "etag": etag,
                "size": int(size),
                "file_name": file_path,
                "is_v2_etag": is_v2_etag_format
            })
        
        logger.info(f"è§£æåˆ° {len(files)} ä¸ªæ–‡ä»¶")
        return files
    
    @staticmethod
    def optimized_etag_to_hex(optimized_etag, is_v2_etag):
        """å°†ä¼˜åŒ–åçš„ETagè½¬æ¢ä¸ºåå…­è¿›åˆ¶æ ¼å¼"""
        if not is_v2_etag:
            return optimized_etag
        
        try:
            logger.debug(f"è½¬æ¢V2 ETag: {optimized_etag}")
            num = 0
            for char in optimized_etag:
                num = num * 62 + BASE62_CHARS.index(char)
            
            hex_str = hex(num)[2:].lower()
            
            if len(hex_str) < 32:
                hex_str = hex_str.zfill(32)
            
            logger.debug(f"è½¬æ¢åETag: {hex_str}")
            return hex_str
        except Exception as e:
            logger.error(f"âŒ ETagè½¬æ¢å¤±è´¥: {str(e)}")
            return optimized_etag

class TelegramBotHandler:
    def __init__(self, token, pan_client, allowed_user_ids):
        self.token = token
        self.pan_client = pan_client
        self.allowed_user_ids = allowed_user_ids
        self.updater = Updater(token, use_context=True)
        self.dispatcher = self.updater.dispatcher
        
        # æ³¨å†Œå¤„ç†ç¨‹åº
        self.dispatcher.add_handler(CommandHandler("export", self.export_command))  # æ·»åŠ å¯¼å‡ºå‘½ä»¤
        self.dispatcher.add_handler(MessageHandler(Filters.text & ~Filters.command, self.handle_text))
        self.dispatcher.add_handler(MessageHandler(Filters.document, self.handle_document))
    
    def start(self):
        """å¯åŠ¨æœºå™¨äºº"""
        self.updater.start_polling()
        logger.info("ğŸ¤– æœºå™¨äººå·²å¯åŠ¨ï¼Œç­‰å¾…æ¶ˆæ¯...")
        logger.info(f"ç®¡ç†å‘˜ç”¨æˆ·ID: {self.allowed_user_ids}")
        self.updater.idle()
    
    # ç®¡ç†å‘˜æƒé™æ£€æŸ¥è£…é¥°å™¨
    def admin_required(func):
        @wraps(func)
        def wrapper(self, update: Update, context: CallbackContext, *args, **kwargs):
            user_id = update.message.from_user.id
            if user_id not in self.allowed_user_ids:
                #logger.warning(f"ç”¨æˆ· {user_id} å°è¯•è®¿é—®ä½†æ— æƒé™")
                #update.message.reply_text("ğŸš« æ‚¨æ²¡æœ‰æƒé™ä½¿ç”¨æ­¤æœºå™¨äºº")
                return
            return func(self, update, context, *args, **kwargs)
        return wrapper
    
    @admin_required
    def handle_text(self, update: Update, context: CallbackContext):
        """å¤„ç†æ–‡æœ¬æ¶ˆæ¯ï¼ˆç§’ä¼ é“¾æ¥ï¼‰"""
        text = update.message.text.strip()
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç§’ä¼ é“¾æ¥
        if any(prefix in text for prefix in [
            LEGACY_FOLDER_LINK_PREFIX_V1,
            LEGACY_FOLDER_LINK_PREFIX_V2,
            COMMON_PATH_LINK_PREFIX_V1,
            COMMON_PATH_LINK_PREFIX_V2
        ]):
            logger.info(f"æ”¶åˆ°ç§’ä¼ é“¾æ¥: {text[:50]}...")
            update.message.reply_text("ğŸ” æ£€æµ‹åˆ°ç§’ä¼ é“¾æ¥ï¼Œå¼€å§‹è§£æ...")
            self.process_fast_link(update, text)
    
    @admin_required
    def handle_document(self, update: Update, context: CallbackContext):
        """å¤„ç†æ–‡æ¡£æ¶ˆæ¯ï¼ˆJSONæ–‡ä»¶ï¼‰"""
        document = update.message.document
        user_id = update.message.from_user.id
        file_name = document.file_name
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯JSONæ–‡ä»¶
        if document.mime_type != "application/json" and not file_name.endswith(".json"):
            update.message.reply_text("âŒ è¯·å‘é€JSONæ ¼å¼çš„æ–‡ä»¶ï¼")
            return
        
        logger.info(f"æ”¶åˆ°JSONæ–‡ä»¶: {file_name}")
        update.message.reply_text("ğŸ“¥ æ”¶åˆ°JSONæ–‡ä»¶ï¼Œå¼€å§‹ä¸‹è½½å¹¶è§£æ...")
        
        # ä¸‹è½½æ–‡ä»¶
        file = context.bot.get_file(document.file_id)
        file_path = f"temp_{user_id}_{document.file_id}.json"
        file.download(file_path)
        
        # è¯»å–å¹¶è§£æJSON
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                json_data = json.load(f)
            os.remove(file_path)
            
            logger.info(f"è§£æJSONæ–‡ä»¶: {file_name}")
            self.process_json_file(update, json_data)
        except Exception as e:
            logger.error(f"âŒ å¤„ç†JSONæ–‡ä»¶å‡ºé”™: {str(e)}")
            update.message.reply_text(f"âŒ å¤„ç†JSONæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
    
    @admin_required
    def process_fast_link(self, update: Update, share_link):
        """å¤„ç†ç§’ä¼ é“¾æ¥è½¬å­˜"""
        try:
            files = FastLinkProcessor.parse_share_link(share_link)
            if not files:
                logger.warning("æ— æ³•è§£æç§’ä¼ é“¾æ¥æˆ–é“¾æ¥ä¸­æ— æœ‰æ•ˆæ–‡ä»¶ä¿¡æ¯")
                update.message.reply_text("âŒ æ— æ³•è§£æç§’ä¼ é“¾æ¥æˆ–é“¾æ¥ä¸­æ— æœ‰æ•ˆæ–‡ä»¶ä¿¡æ¯")
                return
            
            logger.info(f"å¼€å§‹è½¬å­˜ {len(files)} ä¸ªæ–‡ä»¶...")
            update.message.reply_text(f"âœ… è§£ææˆåŠŸï¼æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶ï¼Œå¼€å§‹è½¬å­˜...")
            
            # è½¬å­˜æ–‡ä»¶
            results = self.transfer_files(update, files)
            
            # å‘é€ç»“æœ
            self.send_transfer_results(update, results)
            
        except Exception as e:
            logger.error(f"âŒ å¤„ç†ç§’ä¼ é“¾æ¥å‡ºé”™: {str(e)}")
            update.message.reply_text(f"âŒ å¤„ç†ç§’ä¼ é“¾æ¥æ—¶å‡ºé”™: {str(e)}")
    
    @admin_required
    def process_json_file(self, update: Update, json_data):
        """å¤„ç†JSONæ–‡ä»¶è½¬å­˜"""
        try:
            if not isinstance(json_data, dict) or not json_data.get("files"):
                logger.warning("JSONæ ¼å¼æ— æ•ˆï¼Œç¼ºå°‘fileså­—æ®µ")
                update.message.reply_text("âŒ JSONæ ¼å¼æ— æ•ˆï¼Œç¼ºå°‘fileså­—æ®µ")
                return
            
            common_path = json_data.get("commonPath", "").strip()
            if common_path.endswith('/'):
                common_path = common_path[:-1]
            
            files = []
            for file_info in json_data["files"]:
                file_path = file_info.get("path", "")
                if common_path:
                    file_path = f"{common_path}/{file_path}"
                
                files.append({
                    "etag": file_info.get("etag", ""),
                    "size": int(file_info.get("size", 0)),
                    "file_name": file_path,
                    "is_v2_etag": json_data.get("usesBase62EtagsInExport", False)
                })
            
            logger.info(f"å¼€å§‹è½¬å­˜ {len(files)} ä¸ªæ–‡ä»¶...")
            update.message.reply_text(f"âœ… è§£ææˆåŠŸï¼æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶ï¼Œå¼€å§‹è½¬å­˜...")
            
            # è½¬å­˜æ–‡ä»¶
            results = self.transfer_files(update, files)
            
            # å‘é€ç»“æœ
            self.send_transfer_results(update, results)
            
        except Exception as e:
            logger.error(f"âŒ å¤„ç†JSONæ–‡ä»¶å‡ºé”™: {str(e)}")
            update.message.reply_text(f"âŒ å¤„ç†JSONæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
    
    
    def transfer_files(self, update: Update, files):
        """è½¬å­˜æ–‡ä»¶åˆ—è¡¨ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
        logger.info(f"å¼€å§‹è½¬å­˜ {len(files)} ä¸ªæ–‡ä»¶...")
        results = []
        total_files = len(files)
        root_dir_id = "0"
        
        # åˆ›å»ºæ–‡ä»¶å¤¹ç¼“å­˜
        folder_cache = {}
        
        for i, file_info in enumerate(files):
            file_path = file_info["file_name"]
            logger.info(f"å¤„ç†æ–‡ä»¶ [{i+1}/{total_files}]: {file_path}")
            
            try:
                # å¤„ç†æ–‡ä»¶è·¯å¾„
                path_parts = file_path.split('/')
                file_name = path_parts.pop()
                parent_id = root_dir_id
                
                # åˆ›å»ºç›®å½•ç»“æ„
                current_path = ""
                for part in path_parts:
                    if not part:
                        continue
                    
                    current_path = f"{current_path}/{part}" if current_path else part
                    cache_key = f"{parent_id}/{current_path}"
                    
                    # æ£€æŸ¥ç¼“å­˜
                    if cache_key in folder_cache:
                        parent_id = folder_cache[cache_key]
                        continue
                    
                    # åˆ›å»ºæ–°æ–‡ä»¶å¤¹ï¼ˆå¸¦é‡è¯•ï¼‰
                    folder = self.pan_client.create_folder(parent_id, part)
                    if folder:
                        folder_id = folder["FileId"]
                        folder_cache[cache_key] = folder_id
                        parent_id = folder_id
                    else:
                        logger.warning(f"âš ï¸ åˆ›å»ºæ–‡ä»¶å¤¹å¤±è´¥: {part}ï¼Œå°†ä½¿ç”¨æ ¹ç›®å½•")
                        parent_id = root_dir_id
                
                # å¤„ç†ETag
                etag = file_info["etag"]
                if file_info.get("is_v2_etag", False):
                    etag = FastLinkProcessor.optimized_etag_to_hex(etag, True)
                
                # ç§’ä¼ æ–‡ä»¶ï¼ˆå¸¦é‡è¯•ï¼‰
                result = self.pan_client.rapid_upload(
                    etag, 
                    file_info["size"],
                    file_name,
                    parent_id
                )
                
                if result:
                    results.append({
                        "success": True,
                        "file_name": file_path,
                        "file_id": result["FileId"]
                    })
                    logger.info(f"âœ… æ–‡ä»¶è½¬å­˜æˆåŠŸ: {file_path}")
                else:
                    results.append({
                        "success": False,
                        "file_name": file_path,
                        "error": "ç§’ä¼ å¤±è´¥"
                    })
                    logger.error(f"âŒ æ–‡ä»¶è½¬å­˜å¤±è´¥: {file_path}")
            except Exception as e:
                logger.error(f"âŒ è½¬å­˜æ–‡ä»¶ {file_path} å‡ºé”™: {str(e)}")
                results.append({
                    "success": False,
                    "file_name": file_path,
                    "error": str(e)
                })
        
        logger.info(f"æ–‡ä»¶è½¬å­˜å®Œæˆï¼ŒæˆåŠŸ: {sum(1 for r in results if r['success'])}, å¤±è´¥: {len(results) - sum(1 for r in results if r['success'])}")
        return results
    
    def send_transfer_results(self, update: Update, results):
        """å‘é€è½¬å­˜ç»“æœï¼ŒåŒ…å«å¤±è´¥æ–‡ä»¶è¯¦æƒ…"""
        success_count = sum(1 for r in results if r["success"])
        failed_count = len(results) - success_count
        
        result_text = (
            f"ğŸ“Š è½¬å­˜å®Œæˆï¼\n"
            f"âœ… æˆåŠŸ: {success_count}\n"
            f"âŒ å¤±è´¥: {failed_count}"
        )
        
        # æ·»åŠ å¤±è´¥æ–‡ä»¶è¯¦æƒ…
        if failed_count > 0:
            failed_files = []
            for result in results:
                if not result["success"]:
                    # ç®€åŒ–æ–‡ä»¶åæ˜¾ç¤º
                    file_name = result["file_name"]
                    if len(file_name) > 50:
                        file_name = f"...{file_name[-47:]}"
                    
                    failed_files.append(f"â€¢ {file_name}: {result['error']}")
            
            result_text += "\n\nâŒ å¤±è´¥æ–‡ä»¶:\n" + "\n".join(failed_files[:10])  # æœ€å¤šæ˜¾ç¤º10ä¸ªå¤±è´¥æ–‡ä»¶
            
            if failed_count > 10:
                result_text += f"\n...åŠå…¶ä»– {failed_count - 10} ä¸ªå¤±è´¥æ–‡ä»¶"
        
        update.message.reply_text(result_text)

    @admin_required
    def export_command(self, update: Update, context: CallbackContext):
        """å¤„ç†/exportå‘½ä»¤ï¼ŒæŒ‰åç§°å¯¼å‡ºæ–‡ä»¶å¤¹ä¸ºJSON"""
        logger.info("æ”¶åˆ°/exportå‘½ä»¤")
        
        # è·å–å‘½ä»¤å‚æ•°ï¼ˆåˆå¹¶æ‰€æœ‰å‚æ•°ä¸ºæ–‡ä»¶å¤¹åç§°ï¼‰
        folder_name = " ".join(context.args) if context.args else ""
        
        if not folder_name:
            update.message.reply_text("âŒ è¯·æŒ‡å®šè¦å¯¼å‡ºçš„æ–‡ä»¶å¤¹åç§°ï¼æ ¼å¼: /export <æ–‡ä»¶å¤¹åç§°>")
            return
        
        update.message.reply_text(f"ğŸ” æ­£åœ¨å…¨ç›˜æœç´¢æ–‡ä»¶å¤¹: '{folder_name}'...")
        
        try:
            # æ­¥éª¤1: é€’å½’æœç´¢æ–‡ä»¶å¤¹
            folder_info = self.pan_client.search_folder_recursive(folder_name)
            if not folder_info:
                update.message.reply_text(f"âŒ æœªæ‰¾åˆ°æ–‡ä»¶å¤¹: '{folder_name}'")
                return
            
            folder_id = folder_info["fileId"]
            folder_path = folder_info.get("path", folder_name)
            
            # æå–æœç´¢åˆ°çš„æ–‡ä»¶å¤¹åç§°ï¼ˆæœ€åä¸€éƒ¨åˆ†ï¼‰
            folder_name_only = folder_path.split('/')[-1]
            update.message.reply_text(f"âœ… æ‰¾åˆ°æ–‡ä»¶å¤¹: '{folder_path}' (ID: {folder_id})ï¼Œå¼€å§‹å¯¼å‡ºå†…å®¹...")
            
            # æ­¥éª¤2: è·å–æ–‡ä»¶å¤¹å†…å®¹ï¼Œä¿ç•™å®Œæ•´å­ç›®å½•ç»“æ„
            files = self.pan_client.get_directory_files(folder_id, folder_name_only)
            
            if not files:
                update.message.reply_text("âš ï¸ è¯¥æ–‡ä»¶å¤¹ä¸ºç©º")
                return
            
            # åˆ›å»ºJSONç»“æ„ï¼Œå°†æœç´¢åˆ°çš„æ–‡ä»¶å¤¹åç§°æ”¾åœ¨commonPathä¸­
            json_data = {
                "commonPath": folder_name_only,  # åªå­˜å‚¨æœç´¢åˆ°çš„æ–‡ä»¶å¤¹åç§°
                "usesBase62EtagsInExport": False,
                "files": [
                    {
                        "path": file_info["path"],  # åŒ…å«å®Œæ•´å­ç›®å½•ç»“æ„
                        "etag": file_info["etag"],
                        "size": file_info["size"]
                    }
                    for file_info in files
                ]
            }
            
            # æ¸…ç†æ–‡ä»¶å¤¹åç§°ï¼ˆç§»é™¤éæ³•å­—ç¬¦ï¼‰
            clean_folder_name = re.sub(r'[\\/*?:"<>|]', "", folder_name_only)
            
            # ç”Ÿæˆæ–‡ä»¶åï¼ˆä½¿ç”¨æ–‡ä»¶å¤¹åç§°ï¼‰
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            file_name = f"{clean_folder_name}_{timestamp}.json"
            
            # ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶
            with open(file_name, "w", encoding="utf-8") as f:
                json.dump(json_data, f, ensure_ascii=False, indent=2)
            
            # å‘é€æ–‡ä»¶ç»™ç”¨æˆ·
            with open(file_name, "rb") as f:
                update.message.reply_document(
                    document=f,
                    filename=file_name,
                    caption=f"âœ… å¯¼å‡ºå®Œæˆï¼æ–‡ä»¶å¤¹: '{folder_path}'\nå…± {len(files)} ä¸ªæ–‡ä»¶\nå°†æ­¤æ–‡ä»¶å‘é€å›æœºå™¨äººå¯å®ç°ç§’ä¼ "
                )
            
            # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            os.remove(file_name)
            logger.info(f"å·²å‘é€å¯¼å‡ºæ–‡ä»¶: {file_name}")
            
        except Exception as e:
            logger.error(f"å¯¼å‡ºæ–‡ä»¶å¤¹å¤±è´¥: {str(e)}")
            update.message.reply_text(f"âŒ å¯¼å‡ºå¤±è´¥: {str(e)}")

def main():
    # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
    BOT_TOKEN = os.getenv("TG_BOT_TOKEN","")
    CLIENT_ID = os.getenv("PAN_CLIENT_ID","")
    CLIENT_SECRET = os.getenv("PAN_CLIENT_SECRET","")
    ADMIN_USER_IDS = [int(id.strip()) for id in os.getenv("TG_ADMIN_USER_IDS", "").split(",") if id.strip()]
    
    # æ£€æŸ¥é…ç½®æ˜¯å¦å®Œæ•´
    if not BOT_TOKEN:
        logger.error("âŒ ç¯å¢ƒå˜é‡ TG_BOT_TOKEN æœªè®¾ç½®")
        return
    
    if not CLIENT_ID:
        logger.error("âŒ ç¯å¢ƒå˜é‡ PAN_CLIENT_ID æœªè®¾ç½®")
        return
    
    if not CLIENT_SECRET:
        logger.error("âŒ ç¯å¢ƒå˜é‡ PAN_CLIENT_SECRET æœªè®¾ç½®")
        return
    
    if not ADMIN_USER_IDS:
        logger.warning("âš ï¸ ç¯å¢ƒå˜é‡ TG_ADMIN_USER_IDS æœªè®¾ç½®æˆ–ä¸ºç©ºï¼Œæœºå™¨äººå°†å¯¹æ‰€æœ‰ç”¨æˆ·å¼€æ”¾")
    
    logger.info("åˆå§‹åŒ–123äº‘ç›˜å®¢æˆ·ç«¯...")
    pan_client = Pan123Client(CLIENT_ID, CLIENT_SECRET)
    
    logger.info("åˆå§‹åŒ–Telegramæœºå™¨äºº...")
    bot_handler = TelegramBotHandler(BOT_TOKEN, pan_client, ADMIN_USER_IDS)
    
    # å¯åŠ¨æœºå™¨äºº
    logger.info("æœºå™¨äººå¯åŠ¨ä¸­...")
    bot_handler.start()

if __name__ == "__main__":
    main()
