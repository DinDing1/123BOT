import warnings
warnings.filterwarnings("ignore", message="python-telegram-bot is using upstream urllib3.*")
warnings.filterwarnings("ignore", message=".*pkg_resources is deprecated.*", category=UserWarning)
import os
import re
import json
import time
import logging
import requests
import sqlite3
import threading
import traceback
import urllib.parse
from contextlib import closing
from datetime import datetime, timedelta, timezone
from telegram import Update, BotCommand, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import (
    Updater, 
    MessageHandler, 
    Filters, 
    CallbackContext, 
    CommandHandler,
    CallbackQueryHandler
)
from functools import wraps
import urllib3
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from collections import defaultdict, deque
from typing import Dict, Optional, List, Tuple

# ç¦ç”¨SSLè­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

######################ç‰ˆæœ¬ä¿¡æ¯###########
def get_version():
    """ä» VERSION æ–‡ä»¶ä¸­è¯»å–ç‰ˆæœ¬å·"""
    version_file = "/app/VERSION"
    if os.path.exists(version_file):
        with open(version_file, "r", encoding="utf-8") as f:
            return f.read().strip()
    return "æœªçŸ¥ç‰ˆæœ¬"

VERSION = get_version()
#######################################

# é…ç½®æ—¥å¿—
logging.basicConfig(
    format='%(asctime)s - %(levelname)s - %(message)s',
    level=logging.INFO,
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# å¿½ç•¥ç¬¬ä¸‰æ–¹åº“çš„è­¦å‘Š
logging.getLogger("telegram").setLevel(logging.WARNING)
logging.getLogger("apscheduler").setLevel(logging.WARNING)
logging.getLogger("urllib3").setLevel(logging.WARNING)
logging.getLogger("p115").setLevel(logging.WARNING)
logging.getLogger("p115client").setLevel(logging.WARNING)

# ====================== é…ç½®åŒºåŸŸ ======================
# æ•°æ®åº“æ–‡ä»¶è·¯å¾„
DB_PATH = os.getenv("DB_PATH", "bot123.db")

# 123äº‘ç›˜APIé…ç½®
PAN_HOST = "https://www.123pan.com"
API_PATHS = {
    "TOKEN": "/api/v1/access_token",
    "USER_INFO": "/api/v1/user/info",
    "LIST_FILES_V2": "/api/v2/file/list",
    "UPLOAD_REQUEST": "/b/api/file/upload_request",
    "CLEAR_TRASH": "/api/file/trash_delete_all",
    "GET_SHARE": "/b/api/share/get",
    "OFFLINE_DOWNLOAD": "/api/v1/offline/download",
    "DIRECTORY_CREATE": "/upload/v1/file/mkdir",
    "DOWNLOAD_PROGRESS": "/api/v1/offline/download/process"
}

# å¼€æ”¾å¹³å°åœ°å€
OPEN_API_HOST = "https://open-api.123pan.com"

# ç§’ä¼ é“¾æ¥å‰ç¼€
LEGACY_FOLDER_LINK_PREFIX_V1 = "123FSLinkV1$"
LEGACY_FOLDER_LINK_PREFIX_V2 = "123FSLinkV2$"
COMMON_PATH_LINK_PREFIX_V1 = "123FLCPV1$"
COMMON_PATH_LINK_PREFIX_V2 = "123FLCPV2$"
COMMON_PATH_DELIMITER = "%"

# Base62å­—ç¬¦é›†
BASE62_CHARS = "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ"

# ç¯å¢ƒå˜é‡é…ç½®
DEFAULT_SAVE_DIR = os.getenv("DEFAULT_SAVE_DIR", "").strip()
EXPORT_BASE_DIRS = [d.strip() for d in os.getenv("EXPORT_BASE_DIR", "").split(';') if d.strip()]
SEARCH_MAX_DEPTH = int(os.getenv("SEARCH_MAX_DEPTH", ""))
DAILY_EXPORT_LIMIT = int(os.getenv("DAILY_EXPORT_LIMIT", "3")) #å¯¼å‡ºæ¬¡æ•°
BANNED_EXPORT_NAMES = [name.strip().lower() for name in os.getenv("BANNED_EXPORT_NAMES", "ç”µè§†å‰§;ç”µå½±").split(';') if name.strip()]

# APIé€Ÿç‡æ§åˆ¶é…ç½®
API_RATE_LIMIT = float(os.getenv("API_RATE_LIMIT", "2.0"))
TRANSFER_RATE_LIMIT = float(os.getenv("TRANSFER_RATE_LIMIT", "3"))

# å…è®¸çš„æ–‡ä»¶ç±»å‹é…ç½®
ALLOWED_VIDEO_EXTENSIONS = [ext.strip().lower() for ext in os.getenv("ALLOWED_VIDEO_EXT", ".mp4,.mkv,.avi,.mov,.flv,.wmv,.webm,.ts,.m2ts,.iso,.mp3,.flac,.wav").split(',') if ext.strip()]
ALLOWED_SUB_EXTENSIONS = [ext.strip().lower() for ext in os.getenv("ALLOWED_SUB_EXT", ".srt,.ass,.ssa,.sub,.idx,.vtt,.sup").split(',') if ext.strip()]
# åˆå¹¶æ‰€æœ‰å…è®¸çš„æ–‡ä»¶ç±»å‹
ALLOWED_EXTENSIONS = ALLOWED_VIDEO_EXTENSIONS + ALLOWED_SUB_EXTENSIONS

# 115ç½‘ç›˜é…ç½®
COOKIES_115 = os.getenv("COOKIES_115", "")
CUSTOM_DIRECT_LINK_SERVICE = os.getenv("CUSTOM_DIRECT_LINK_SERVICE", "")
TARGET_PATH_115 = os.getenv("TARGET_PATH_115", "")
DELETE_AFTER_TRANSFER = os.getenv("DELETE_AFTER_TRANSFER", "true").lower() == "true"

# ä»»åŠ¡çŠ¶æ€æ˜ å°„
TASK_STATUS_MAP = {
    0: "è¿›è¡Œä¸­",
    1: "ä¸‹è½½å¤±è´¥",
    2: "ä¸‹è½½æˆåŠŸ",
    3: "é‡è¯•ä¸­"
}
# =====================================================

def init_db():
    """åˆå§‹åŒ–æ•°æ®åº“"""
    try:
        with closing(sqlite3.connect(DB_PATH)) as conn:
            c = conn.cursor()
            # åˆ›å»ºæ‰€æœ‰è¡¨
            tables = [
                '''CREATE TABLE IF NOT EXISTS token_cache (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    access_token TEXT NOT NULL,
                    client_id TEXT NOT NULL,
                    client_secret TEXT NOT NULL,
                    expired_at TIMESTAMP NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )''',
                '''CREATE TABLE IF NOT EXISTS directory_cache (
                    file_id INTEGER PRIMARY KEY,
                    filename TEXT NOT NULL,
                    parent_id INTEGER NOT NULL,
                    full_path TEXT NOT NULL,
                    base_dir_id INTEGER NOT NULL,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )''',
                '''CREATE TABLE IF NOT EXISTS user_privileges (
                    user_id INTEGER PRIMARY KEY,
                    privilege_level TEXT NOT NULL DEFAULT 'user',
                    export_count INTEGER NOT NULL DEFAULT 0,
                    last_export_date TIMESTAMP,
                    join_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )''',
                '''CREATE TABLE IF NOT EXISTS export_history (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_id INTEGER NOT NULL,
                    export_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    folder_count INTEGER NOT NULL
                )'''
            ]
            
            for table in tables:
                c.execute(table)
            
            # åˆ›å»ºç´¢å¼•
            indexes = [
                "CREATE INDEX IF NOT EXISTS idx_filename ON directory_cache (filename)",
                "CREATE INDEX IF NOT EXISTS idx_full_path ON directory_cache (full_path)",
                "CREATE INDEX IF NOT EXISTS idx_base_dir ON directory_cache (base_dir_id)"
            ]
            
            for index in indexes:
                c.execute(index)
                
            conn.commit()
    except Exception as e:
        logger.error(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")

init_db()

# ====================== å·¥å…·å‡½æ•° ======================
def format_size(size_bytes):
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    if size_bytes >= 1024 ** 4:
        return f"{size_bytes / (1024 ** 4):.2f} TB"
    elif size_bytes >= 1024 ** 3:
        return f"{size_bytes / (1024 ** 3):.2f} GB"
    elif size_bytes >= 1024 ** 2:
        return f"{size_bytes / (1024 ** 2):.2f} MB"
    elif size_bytes >= 1024:
        return f"{size_bytes / 1024:.2f} KB"
    else:
        return f"{size_bytes} bytes"

def generate_usage_bar(percent, length=20):
    """ç”Ÿæˆä½¿ç”¨ç‡è¿›åº¦æ¡"""
    filled = int(round(length * percent / 100))
    empty = length - filled
    return "[" + "â–ˆ" * filled + "â–‘" * empty + "]"

# =====================================================

class TokenManager:
    """ç®¡ç†API tokençš„è·å–å’Œç¼“å­˜"""
    def __init__(self, client_id, client_secret):
        self.client_id = client_id
        self.client_secret = client_secret
        self.session = self._create_session()
        self.access_token = None
        self.token_expiry = None
        self.start_time = datetime.now()
        
        if not self.load_token_from_cache():
            self.get_new_token()
    
    def _create_session(self):
        """åˆ›å»ºå¸¦é‡è¯•æœºåˆ¶çš„Session"""
        session = requests.Session()
        retry_strategy = Retry(
            total=5,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504],
            allowed_methods=["GET", "POST"]
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("https://", adapter)
        session.mount("http://", adapter)
        session.verify = False
        return session
    
    def load_token_from_cache(self):
        """ä»æ•°æ®åº“åŠ è½½ç¼“å­˜çš„Token"""
        try:
            with closing(sqlite3.connect(DB_PATH)) as conn:
                c = conn.cursor()
                c.execute("SELECT access_token, client_id, client_secret, expired_at FROM token_cache ORDER BY id DESC LIMIT 1")
                row = c.fetchone()
                
                if row:
                    token, cached_id, cached_secret, expired_at_str = row
                    expired_at = datetime.fromisoformat(expired_at_str).astimezone(timezone.utc)
                    now = datetime.now(timezone.utc)
                    
                    if (expired_at > now + timedelta(minutes=5) and \
                       self.client_id == cached_id and \
                       self.client_secret == cached_secret):
                        self.access_token = token
                        self.token_expiry = expired_at
                        logger.info("ä½¿ç”¨ç¼“å­˜Token")
                    
                        return True
        except Exception as e:
            logger.error(f"åŠ è½½Tokenç¼“å­˜å¤±è´¥: {e}")
        return False
    
    def save_token_to_cache(self, access_token, expired_at):
        """ä¿å­˜Tokenåˆ°æ•°æ®åº“"""
        try:
            with closing(sqlite3.connect(DB_PATH)) as conn:
                c = conn.cursor()
                c.execute("DELETE FROM token_cache")
                c.execute('''INSERT INTO token_cache 
                           (access_token, client_id, client_secret, expired_at)
                           VALUES (?,?,?,?)''',
                           (access_token, self.client_id, self.client_secret, expired_at.isoformat()))
                conn.commit()
                return True
        except Exception as e:
            logger.error(f"ä¿å­˜Tokenåˆ°ç¼“å­˜å¤±è´¥: {e}")
            return False
    
    def get_new_token(self):
        """è·å–æ–°token"""
        try:
            logger.info("æ­£åœ¨è·å–æ–°Token...")
            url = f"{OPEN_API_HOST}{API_PATHS['TOKEN']}"
            payload = {
                "clientID": self.client_id,
                "clientSecret": self.client_secret
            }
            
            headers = {
                "Content-Type": "application/json",
                "Platform": "open_platform"
            }
            
            response = self.session.post(url, json=payload, headers=headers, timeout=20)
            
            if response.status_code != 200:
                logger.error(f"è®¤è¯å¤±è´¥: HTTP {response.status_code}")
                return False
            
            data = response.json()
            if data.get("code") != 0:
                logger.error(f"APIé”™è¯¯: {data.get('code')} - {data.get('message')}")
                return False
            
            self.access_token = data["data"]["accessToken"]
            expired_at_str = data["data"]["expiredAt"]
            
            # ç»Ÿä¸€å¤„ç†æ—¶é—´æ ¼å¼
            if expired_at_str.endswith('Z'):
                expired_at_str = expired_at_str[:-1] + "+00:00"
            
            self.token_expiry = datetime.fromisoformat(expired_at_str).astimezone(timezone.utc)
            
            if self.save_token_to_cache(self.access_token, self.token_expiry):
                logger.info(f"æ›´æ–°TokenæˆåŠŸï¼Œæœ‰æ•ˆæœŸè‡³: {self.token_expiry} (UTC)")
                return True
            return False
        except Exception as e:
            logger.error(f"è·å–Tokenå¤±è´¥: {e}")
            return False
    
    def ensure_token_valid(self):
        """ç¡®ä¿tokenæœ‰æ•ˆ"""
        current_time = datetime.now(timezone.utc)
        if not self.access_token or not self.token_expiry or current_time >= self.token_expiry - timedelta(minutes=5):
            logger.info("Tokenæ— æ•ˆæˆ–å³å°†è¿‡æœŸï¼Œåˆ·æ–°ä¸­...")
            return self.get_new_token()
        return True
    
    def get_auth_header(self):
        """è·å–è®¤è¯å¤´"""
        if not self.ensure_token_valid():
            raise Exception("æ— æ³•è·å–æœ‰æ•ˆçš„Token")
        return {
            "Authorization": f"Bearer {self.access_token}",
            "Platform": "open_platform",
            "Content-Type": "application/json"
        }
        
def is_allowed_file(filename):
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºå…è®¸çš„ç±»å‹"""
    ext = os.path.splitext(filename)[1].lower()
    return ext in ALLOWED_VIDEO_EXTENSIONS or ext in ALLOWED_SUB_EXTENSIONS

class Pan123Client:
    def __init__(self, client_id, client_secret):
        self.token_manager = TokenManager(client_id, client_secret)
        self.session = self._create_session()
        self.last_api_call = 0
        self.api_rate_limit = API_RATE_LIMIT
        self.share_root_folder = ""
        
        # åˆå§‹åŒ–ç›®å½•ID
        self.default_save_dir_id = 0
        self.export_base_dir_ids = []
        self.export_base_dir_map = {0: "æ ¹ç›®å½•"}
        
        # APIé€Ÿç‡æ§åˆ¶
        self.rate_limit_lock = threading.Lock()
        
        if DEFAULT_SAVE_DIR:
            self.default_save_dir_id = self.get_or_create_directory(DEFAULT_SAVE_DIR)
            logger.info(f"é»˜è®¤ä¿å­˜ç›®å½•å·²è®¾ç½®: '{DEFAULT_SAVE_DIR}' (ID: {self.default_save_dir_id})")
        
        for base_dir in EXPORT_BASE_DIRS:
            base_dir_id = self.get_or_create_directory(base_dir)
            self.export_base_dir_ids.append(base_dir_id)
            self.export_base_dir_map[base_dir_id] = base_dir
            logger.info(f"å¯¼å‡ºåŸºç›®å½•å·²è®¾ç½®: '{base_dir}' (ID: {base_dir_id})")
        
        self.search_max_depth = SEARCH_MAX_DEPTH
        logger.info(f"æœç´¢æœ€å¤§æ·±åº¦å·²è®¾ç½®: {self.search_max_depth} å±‚")
        
        # åˆå§‹åŒ–ç›®å½•ç¼“å­˜
        self.directory_cache = {}
        self.load_directory_cache()
        logger.info(f"å·²åŠ è½½ {len(self.directory_cache)} ä¸ªç›®å½•ç¼“å­˜")
    
    def _create_session(self):
        """åˆ›å»ºå¸¦é‡è¯•æœºåˆ¶çš„Session"""
        session = requests.Session()
        session.trust_env = False
        retry_strategy = Retry(
            total=5,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504],
            allowed_methods=["GET", "POST"]
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("https://", adapter)
        session.mount("http://", adapter)
        session.verify = False
        return session
    
    def get_or_create_directory(self, path):
        """è·å–æˆ–åˆ›å»ºç›®å½•è·¯å¾„"""
        parent_id = 0
        parts = path.strip('/').split('/')
        
        for part in parts:
            if not part:
                continue
                
            folder_info = self.search_folder(part, parent_id)
            if folder_info:
                parent_id = folder_info["fileId"]
                logger.debug(f"æ‰¾åˆ°ç›®å½•: '{part}' (ID: {parent_id})")
            else:
                logger.info(f"åˆ›å»ºç›®å½•: '{part}' (çˆ¶ID: {parent_id})")
                folder = self.create_folder(parent_id, part)
                if folder:
                    parent_id = folder["FileId"]
                    logger.info(f"å·²åˆ›å»ºç›®å½•: '{part}' (ID: {parent_id})")
        
        return parent_id
    
    def search_folder(self, folder_name, parent_id=0):
        """åœ¨æŒ‡å®šçˆ¶ç›®å½•ä¸‹æœç´¢æ–‡ä»¶å¤¹"""
        try:
            url = f"{OPEN_API_HOST}{API_PATHS['LIST_FILES_V2']}"
            params = {
                "parentFileId": parent_id,
                "trashed": 0,
                "limit": 100,
                "lastFileId": 0
            }
            headers = self.token_manager.get_auth_header()
            
            response = self._call_api("GET", url, params=params, headers=headers, timeout=30)
            if not response or response.status_code != 200:
                return None
                
            data = response.json()
            if data.get("code") != 0:
                return None
                
            for item in data["data"].get("fileList", []):
                if item["type"] == 1 and item["filename"] == folder_name:
                    return {
                        "fileId": item["fileId"],
                        "filename": item["filename"]
                    }
        except Exception as e:
            logger.error(f"æœç´¢ç›®å½•å‡ºé”™: {e}")
        return None

    def _call_api(self, method, url, **kwargs):
        """æ§åˆ¶APIè°ƒç”¨é¢‘ç‡ï¼Œæ·»åŠ æœ€å¤§é‡è¯•æ¬¡æ•°é™åˆ¶"""
        retry_count = 0
        max_retries = 5
        
        while retry_count < max_retries:
            try:
                with self.rate_limit_lock:
                    elapsed = time.time() - self.last_api_call
                    required_delay = 1.0 / self.api_rate_limit
                    if elapsed < required_delay:
                        time.sleep(required_delay - elapsed)
                    response = self.session.request(method, url, **kwargs)
                    self.last_api_call = time.time()
                
                if response.status_code == 429:
                    retry_after = response.headers.get('Retry-After')
                    wait_time = float(retry_after) if retry_after else 5.0
                    logger.warning(f"APIé™æµï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                    retry_count += 1
                    continue
                
                try:
                    data = response.json()
                    if data.get("code") == 429 or "æ“ä½œé¢‘ç¹" in data.get("message", ""):
                        logger.warning("APIé™æµï¼ˆå†…å®¹æ£€æµ‹ï¼‰ï¼Œç­‰å¾…5ç§’åé‡è¯•...")
                        time.sleep(5.0)
                        retry_count += 1
                        continue
                except:
                    pass
                
                return response
                
            except (requests.exceptions.SSLError, 
                    requests.exceptions.ConnectionError,
                    requests.exceptions.ChunkedEncodingError,
                    requests.exceptions.HTTPError) as e:
                retry_count += 1
                logger.error(f"ç½‘ç»œè¿æ¥é”™è¯¯: {e}ï¼Œé‡è¯• {retry_count}/{max_retries}")
                time.sleep(2 ** retry_count)
            except Exception as e:
                logger.error(f"APIè°ƒç”¨å‡ºé”™: {e}")
                retry_count += 1
                time.sleep(2 ** retry_count)
        
        logger.error(f"APIè°ƒç”¨å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° {max_retries}")
        return None
    
    def _get_auth_headers(self):
        """è·å–è®¤è¯å¤´"""
        auth_header = self.token_manager.get_auth_header()
        return {
            **auth_header,
            "platform": "web",
            "App-Version": "3",
            "Origin": PAN_HOST,
            "Referer": f"{PAN_HOST}/",
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36"
        }
    
    def get_user_info(self):
        """è·å–ç”¨æˆ·ä¿¡æ¯"""
        try:
            if not self.token_manager.ensure_token_valid():
                return None
                
            url = f"{OPEN_API_HOST}{API_PATHS['USER_INFO']}"
            headers = self.token_manager.get_auth_header()
            response = self._call_api("GET", url, headers=headers, timeout=30)
            if not response or response.status_code != 200:
                return None
                
            data = response.json()
            if data.get("code") != 0:
                return None
                
            return data.get("data")
        except Exception as e:
            logger.error(f"è·å–ç”¨æˆ·ä¿¡æ¯å‡ºé”™: {e}")
            return None
    
    def create_folder(self, parent_id, folder_name, retry_count=3):
        """åˆ›å»ºæ–‡ä»¶å¤¹"""
        for attempt in range(retry_count):
            try:
                url = f"{PAN_HOST}{API_PATHS['UPLOAD_REQUEST']}"
                payload = {
                    "driveId": 0,
                    "etag": "",
                    "fileName": folder_name,
                    "parentFileId": int(parent_id),
                    "size": 0,
                    "type": 1,
                    "NotReuse": True,
                    "RequestSource": None,
                    "duplicate": 1,
                    "event": "newCreateFolder",
                    "operateType": 1
                }
                headers = self._get_auth_headers()
                response = self.session.post(url, json=payload, headers=headers, timeout=20, verify=False)
                data = response.json()
                
                if data.get("code") == 0 and data["data"].get("Info", {}).get("FileId"):
                    folder_id = data["data"]["Info"]["FileId"]
                    logger.info(f"æ–‡ä»¶å¤¹åˆ›å»ºæˆåŠŸ: '{folder_name}' (ID: {folder_id})")
                    return data["data"]["Info"]
                else:
                    error_msg = data.get("message", "æœªçŸ¥é”™è¯¯")
                    logger.error(f"åˆ›å»ºæ–‡ä»¶å¤¹å¤±è´¥: {error_msg}")
            except Exception as e:
                logger.error(f"åˆ›å»ºæ–‡ä»¶å¤¹è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            time.sleep(1)
        return None
    
    def rapid_upload(self, etag, size, file_name, parent_id, max_retries=8):
        """ç§’ä¼ æ–‡ä»¶"""
        original_etag = etag
        
        if len(etag) != 32 or not all(c in '0123456789abcdef' for c in etag.lower()):
            etag = FastLinkProcessor.optimized_etag_to_hex(etag, True)
        
        base_delay = 2.0
        max_delay = 180.0
        
        for attempt in range(max_retries):
            try:
                delay = min(max_delay, base_delay * (2 ** attempt))
                if attempt > 0:
                    time.sleep(delay)
                
                url = f"{PAN_HOST}{API_PATHS['UPLOAD_REQUEST']}"
                payload = {
                    "driveId": 0,
                    "etag": etag,
                    "fileName": file_name,
                    "parentFileId": int(parent_id),
                    "size": int(size),
                    "type": 0,
                    "NotReuse": False,
                    "RequestSource": None,
                    "duplicate": 1,
                    "event": "rapidUpload",
                    "operateType": 1
                }
                headers = self._get_auth_headers()
                response = self._call_api("POST", url, json=payload, headers=headers, timeout=30)
                
                if not response:
                    continue
                
                try:
                    data = response.json()
                except json.JSONDecodeError:
                    continue
                
                if data.get("code") == 0 and data["data"].get("Info", {}).get("FileId"):
                    file_id = data["data"]["Info"]["FileId"]
                    logger.info(f"æ–‡ä»¶ç§’ä¼ æˆåŠŸ: '{file_name}' (ID: {file_id})")
                    return data["data"]["Info"]
                else:
                    error_msg = data.get("message", "æœªçŸ¥é”™è¯¯")
                    logger.error(f"æ–‡ä»¶ç§’ä¼ å¤±è´¥: {error_msg}")
                    if "etag" in error_msg.lower() and etag != original_etag:
                        etag = original_etag
                        continue
                    if "æ“ä½œé¢‘ç¹" in error_msg or "é™æµ" in error_msg or "é¢‘ç¹" in error_msg:
                        with self.rate_limit_lock:
                            self.api_rate_limit = max(0.8, self.api_rate_limit * 0.9)
                        logger.warning(f"è§¦å‘é™æµï¼Œé™ä½å…¨å±€é€Ÿç‡è‡³ {self.api_rate_limit:.2f} è¯·æ±‚/ç§’")
                        continue
            except Exception as e:
                logger.error(f"ç§’ä¼ è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        logger.error(f"ç§’ä¼ å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° {max_retries}")
        return None
    
    def load_directory_cache(self):
        """ä»æ•°æ®åº“åŠ è½½ç›®å½•ç¼“å­˜"""
        try:
            with closing(sqlite3.connect(DB_PATH)) as conn:
                conn.row_factory = sqlite3.Row
                c = conn.cursor()
                
                if not self.export_base_dir_ids:
                    c.execute("SELECT * FROM directory_cache")
                else:
                    placeholders = ','.join(['?'] * len(self.export_base_dir_ids))
                    c.execute(f"SELECT * FROM directory_cache WHERE base_dir_id IN ({placeholders})", 
                              self.export_base_dir_ids)
                
                rows = c.fetchall()
                for row in rows:
                    file_id = row["file_id"]
                    self.directory_cache[file_id] = dict(row)
                logger.info(f"å·²åŠ è½½ {len(rows)} ä¸ªç›®å½•ç¼“å­˜")
        except Exception as e:
            logger.error(f"åŠ è½½ç›®å½•ç¼“å­˜å¤±è´¥: {e}")
    
    def update_directory_cache(self, file_id, filename, parent_id, full_path, base_dir_id):
        """æ›´æ–°ç›®å½•ç¼“å­˜"""
        try:
            if file_id in self.directory_cache:
                existing = self.directory_cache[file_id]
                if (existing["filename"] == filename and 
                    existing["parent_id"] == parent_id and 
                    existing["full_path"] == full_path and
                    existing["base_dir_id"] == base_dir_id):
                    return False
            
            cache_entry = {
                "file_id": file_id,
                "filename": filename,
                "parent_id": parent_id,
                "full_path": full_path,
                "base_dir_id": base_dir_id
            }
            self.directory_cache[file_id] = cache_entry
            
            with closing(sqlite3.connect(DB_PATH)) as conn:
                c = conn.cursor()
                c.execute('''INSERT OR REPLACE INTO directory_cache 
                            (file_id, filename, parent_id, full_path, base_dir_id) 
                            VALUES (?,?,?,?,?)''',
                          (file_id, filename, parent_id, full_path, base_dir_id))
                conn.commit()
            logger.info(f"æ›´æ–°ç›®å½•ç¼“å­˜: {filename} (ID: {file_id}, è·¯å¾„: {full_path})")
            return True
        except Exception as e:
            logger.error(f"æ›´æ–°ç›®å½•ç¼“å­˜å¤±è´¥: {e}")
            return False
    
    def full_sync_directory_cache(self):
        """å…¨é‡åŒæ­¥ç›®å½•ç¼“å­˜"""
        logger.info("å¼€å§‹å…¨é‡åŒæ­¥ç›®å½•ç¼“å­˜...")
        try:
            with closing(sqlite3.connect(DB_PATH)) as conn:
                c = conn.cursor()
                c.execute("DELETE FROM directory_cache")
                c.execute("DELETE FROM sqlite_sequence WHERE name='directory_cache'")
                conn.commit()
                logger.info("å·²æ¸…ç©ºæ—§ç¼“å­˜æ•°æ®è¡¨")

            self.directory_cache = {}
            update_count = 0
            
            for base_dir_id in self.export_base_dir_ids:
                base_dir_path = self.export_base_dir_map.get(base_dir_id, f"åŸºç›®å½•({base_dir_id})")
                update_count += self.sync_directory(base_dir_id, base_dir_path, base_dir_id)
            
            logger.info(f"å…¨é‡åŒæ­¥å®Œæˆï¼Œæ›´æ–° {update_count} ä¸ªç›®å½•")
            return update_count
        except Exception as e:
            logger.error(f"å…¨é‡åŒæ­¥å¤±è´¥: {e}")
            return 0
    
    def sync_directory(self, directory_id, current_path, base_dir_id, current_depth=0):
        """åŒæ­¥æŒ‡å®šç›®å½•åŠå…¶å­ç›®å½•"""
        last_file_id = 0
        update_count = 0
        
        while True:
            url = f"{OPEN_API_HOST}{API_PATHS['LIST_FILES_V2']}"
            params = {
                "parentFileId": directory_id,
                "trashed": 0,
                "limit": 100,
                "lastFileId": last_file_id
            }
            headers = self.token_manager.get_auth_header()
            
            try:
                response = self._call_api("GET", url, params=params, headers=headers, timeout=30)
                if not response or response.status_code != 200:
                    break
                
                data = response.json()
                if data.get("code") != 0:
                    break
                
                for item in data["data"].get("fileList", []):
                    if item.get("trashed", 1) != 0:
                        continue
                    
                    item_path = f"{current_path}/{item['filename']}" if current_path else item['filename']
                    
                    if item["type"] == 1:
                        updated = self.update_directory_cache(
                            item["fileId"],
                            item["filename"],
                            directory_id,
                            item_path,
                            base_dir_id
                        )
                        if updated:
                            update_count += 1
                        
                        if current_depth < self.search_max_depth:
                            update_count += self.sync_directory(
                                item["fileId"],
                                item_path,
                                base_dir_id,
                                current_depth + 1
                            )
                
                last_file_id = data["data"].get("lastFileId", -1)
                if last_file_id == -1:
                    break
            except Exception as e:
                logger.error(f"åŒæ­¥ç›®å½•å‡ºé”™: {e}")
                break
        
        return update_count
    
    def get_directory_files(self, directory_id=0, base_path="", current_path=""):
        """è·å–ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶"""
        all_files = []
        
        if not self.token_manager.ensure_token_valid():
            return []
        
        last_file_id = 0
        while True:
            url = f"{OPEN_API_HOST}{API_PATHS['LIST_FILES_V2']}"
            params = {
                "parentFileId": directory_id,
                "trashed": 0,
                "limit": 100,
                "lastFileId": last_file_id
            }
            headers = self.token_manager.get_auth_header()
            
            try:
                response = self._call_api("GET", url, params=params, headers=headers, timeout=30)
                if not response or response.status_code != 200:
                    return all_files
                
                data = response.json()
                if data.get("code") != 0:
                    return all_files
                
                for item in data["data"].get("fileList", []):
                    if item.get("trashed", 1) != 0:
                        continue
                    
                    if current_path:
                        file_path = f"{current_path}/{item['filename']}"
                    else:
                        file_path = item['filename']
                    
                    if item["type"] == 0:
                        if not is_allowed_file(item['filename']):
                            continue
                        all_files.append({
                            "path": file_path,
                            "etag": item["etag"],
                            "size": item["size"]
                        })
                    elif item["type"] == 1:
                        if current_path:
                            sub_path = f"{current_path}/{item['filename']}"
                        else:
                            sub_path = item['filename']
                        time.sleep(0.5)
                        sub_files = self.get_directory_files(item["fileId"], base_path, sub_path)
                        all_files.extend(sub_files)
                
                last_file_id = data["data"].get("lastFileId", -1)
                if last_file_id == -1:
                    break
            except Exception as e:
                logger.error(f"è·å–ç›®å½•åˆ—è¡¨å‡ºé”™: {e}")
                return all_files
        
        return all_files

    def clear_trash(self):
        """æ¸…ç©ºå›æ”¶ç«™"""
        try:
            url = f"{PAN_HOST}{API_PATHS['CLEAR_TRASH']}"
            headers = self._get_auth_headers()
            payload = {"event": "recycleClear"}
            response = self._call_api("POST", url, json=payload, headers=headers, timeout=30)
            if not response or response.status_code != 200:
                return False
            data = response.json()
            if data.get("code") == 7301 or data.get("code") == 0:
                logger.info("å›æ”¶ç«™å·²æ¸…ç©º")
                return True
            return False
        except Exception as e:
            logger.error(f"æ¸…ç©ºå›æ”¶ç«™å‡ºé”™: {e}")
            return False
   
    def extract_share_info(self, share_url):
        """ä»åˆ†äº«é“¾æ¥æå–åˆ†äº«Keyå’Œå¯†ç ï¼ˆä½¿ç”¨æ”¹è¿›çš„æ­£åˆ™ï¼‰"""
        pattern = r'(https?://(?:[a-zA-Z0-9-]+\.)*123[a-zA-Z0-9-]*\.[a-z]{2,6}+/s/)([a-zA-Z0-9\-_]+)(?:[\s\S]*?(?:æå–ç |å¯†ç |code)[\s:ï¼š=]*(\w{4}))?'
        match = re.search(pattern, share_url)
        if not match:
            raise ValueError("æ— æ•ˆçš„åˆ†äº«é“¾æ¥æ ¼å¼")
        
        share_key = match.group(2)
        password = match.group(3) or ""
        
        return share_key, password

    def save_share_files(self, share_url, save_dir_id):
        """ä¿å­˜åˆ†äº«é“¾æ¥ä¸­çš„æ–‡ä»¶åˆ°æŒ‡å®šç›®å½•ï¼Œä¿ç•™åŸå§‹ç›®å½•ç»“æ„"""
        try:
            # æå–åˆ†äº«ä¿¡æ¯
            share_key, password = self.extract_share_info(share_url)
            
            # é€’å½’è·å–æ‰€æœ‰æ–‡ä»¶
            files = self._get_share_files_recursive(share_key, password, "0", "")
            if not files:
                logger.warning("åˆ†äº«ä¸­æ²¡æœ‰æ–‡ä»¶")
                return 0, 0, [], 0
                
            # ç”¨äºå­˜å‚¨ç›®å½•æ˜ å°„ï¼šè·¯å¾„ -> äº‘ç›˜ç›®å½•ID
            dir_map = {"": save_dir_id}  # æ ¹ç›®å½•æ˜ å°„
            success_count = 0
            failure_count = 0
            results = []
            total_size = 0  # ç»Ÿè®¡æ€»å¤§å°
            
            # é¦–å…ˆåˆ›å»ºæ‰€æœ‰éœ€è¦çš„ç›®å½•
            all_dirs = {os.path.dirname(f["path"]) for f in files}
            for dir_path in sorted(all_dirs):
                if not dir_path or dir_path in dir_map:
                    continue
                    
                # åˆ›å»ºç›®å½•è·¯å¾„
                parent_id = save_dir_id
                parts = dir_path.split('/')
                current_path = ""
                
                for part in parts:
                    if not part:
                        continue
                        
                    current_path = f"{current_path}/{part}" if current_path else part
                    if current_path in dir_map:
                        parent_id = dir_map[current_path]
                        continue
                        
                    # åˆ›å»ºç›®å½•
                    folder = self.create_folder(parent_id, part)
                    if folder:
                        dir_map[current_path] = folder["FileId"]
                        parent_id = folder["FileId"]
                    else:
                        break
            
            # è½¬å­˜æ–‡ä»¶
            for file_info in files:
                file_path = file_info["path"]
                file_name = os.path.basename(file_path)
                dir_path = os.path.dirname(file_path)
                parent_id = dir_map.get(dir_path, save_dir_id)
                
                # åªè½¬å­˜å…è®¸çš„æ–‡ä»¶ç±»å‹
                if not is_allowed_file(file_name):
                    continue
                
                total_size += file_info["size"]
                
                try:
                    result = self.rapid_upload(
                        file_info["etag"], 
                        file_info["size"], 
                        file_name, 
                        parent_id
                    )
                    
                    if result:
                        success_count += 1
                        results.append({
                            "success": True,
                            "file_name": file_path,
                            "size": file_info["size"]
                        })
                    else:
                        failure_count += 1
                        results.append({
                            "success": False,
                            "file_name": file_path,
                            "size": file_info["size"],
                            "error": "ç§’ä¼ å¤±è´¥"
                        })
                except Exception as e:
                    failure_count += 1
                    results.append({
                        "success": False,
                        "file_name": file_path,
                        "size": file_info["size"],
                        "error": str(e)
                    })
            
            return success_count, failure_count, results, total_size
        except Exception as e:
            logger.error(f"ä¿å­˜åˆ†äº«æ–‡ä»¶å¤±è´¥: {e}")
            return 0, 0, [], 0
    
    def _get_share_files_recursive(self, share_key, password, fid, current_path):
        """é€’å½’è·å–åˆ†äº«ä¸­çš„æ‰€æœ‰æ–‡ä»¶"""
        files = []
        items = self._get_share_files(share_key, password, fid)
        
        for item in items:
            if item["Type"] == 0:  # æ–‡ä»¶
                file_path = f"{current_path}/{item['FileName']}" if current_path else item['FileName']
                files.append({
                    "path": file_path,
                    "name": item["FileName"],
                    "size": item["Size"],
                    "etag": item["Etag"]
                })
            elif item["Type"] == 1:  # ç›®å½•
                sub_path = f"{current_path}/{item['FileName']}" if current_path else item['FileName']
                sub_files = self._get_share_files_recursive(
                    share_key, 
                    password, 
                    item["FileId"], 
                    sub_path
                )
                files.extend(sub_files)
        
        return files
    
    def _get_share_files(self, share_key, password, fid="0"):
        """è·å–åˆ†äº«ä¸­çš„æ–‡ä»¶å’Œç›®å½•åˆ—è¡¨ï¼ˆéé€’å½’ï¼‰"""
        items = []
        next_marker = "0"
        page = 1
        
        while next_marker != "-1":
            params = {
                "shareKey": share_key,
                "SharePwd": password,
                "parentFileId": fid,
                "limit": 100,
                "next": next_marker,
                "orderBy": "file_name",
                "orderDirection": "asc",
                "Page": page
            }
            
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36",
                "Referer": f"{PAN_HOST}/s/{share_key}",
                "Origin": PAN_HOST
            }
            
            try:
                response = self._call_api("GET", f"{PAN_HOST}{API_PATHS['GET_SHARE']}", 
                                         params=params, headers=headers, timeout=30)
                if not response or response.status_code != 200:
                    break
                
                data = response.json()
                if data.get("code") != 0:
                    logger.warning(f"è·å–åˆ†äº«æ–‡ä»¶å¤±è´¥: {data.get('message', 'æœªçŸ¥é”™è¯¯')}")
                    break
                
                # æ·»åŠ å½“å‰é¡µçš„é¡¹ç›®
                for item in data["data"]["InfoList"]:
                    item["Type"] = item.get("Type", 0)
                    items.append(item)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é¡µ
                next_marker = data["data"].get("Next", "-1")
                page += 1
                
            except Exception as e:
                logger.error(f"è·å–åˆ†äº«æ–‡ä»¶æ—¶å‡ºé”™: {e}")
                break
        
        return items
    
    # ====================== 115ç½‘ç›˜åŠŸèƒ½ ======================
    def create_directory(self, parent_id, name):
        """åœ¨123äº‘ç›˜ä¸Šåˆ›å»ºç›®å½•"""
        headers = self.token_manager.get_auth_header()
        payload = {
            "parentID": parent_id,
            "name": name
        }
        
        try:
            url = f"{OPEN_API_HOST}{API_PATHS['DIRECTORY_CREATE']}"
            response = self._call_api("POST", url, json=payload, headers=headers)
            if not response or response.status_code != 200:
                return None
                
            data = response.json()
            if data.get("code") == 0:
                return data["data"]["dirID"]
            else:
                logger.error(f"åˆ›å»ºç›®å½•å¤±è´¥: {data.get('message', 'æœªçŸ¥é”™è¯¯')}")
                return None
        except Exception as e:
            logger.error(f"åˆ›å»ºç›®å½•å¼‚å¸¸: {e}")
            return None
    
    def list_directory(self, parent_id):
        """è·å–123äº‘ç›˜ç›®å½•ä¸‹çš„å­ç›®å½•åˆ—è¡¨"""
        headers = self.token_manager.get_auth_header()
        dirs = []
        last_file_id = 0
        
        while True:
            params = {
                "parentFileId": parent_id,
                "trashed": 0,
                "limit": 100,
                "lastFileId": last_file_id
            }
            
            try:
                url = f"{OPEN_API_HOST}{API_PATHS['LIST_FILES_V2']}"
                response = self._call_api("GET", url, params=params, headers=headers)
                if not response or response.status_code != 200:
                    break
                
                data = response.json()
                if data.get("code") != 0:
                    logger.error(f"è·å–ç›®å½•åˆ—è¡¨å¤±è´¥: {data.get('message', 'æœªçŸ¥é”™è¯¯')}")
                    break
                
                for item in data["data"].get("fileList", []):
                    if item["type"] == 1 and item.get("trashed", 0) == 0:
                        dirs.append({
                            "id": item["fileId"],
                            "name": item["filename"]
                        })
                
                last_file_id = data["data"].get("lastFileId", -1)
                if last_file_id == -1:
                    break
            except Exception as e:
                logger.error(f"è·å–ç›®å½•åˆ—è¡¨å¼‚å¸¸: {e}")
                break
        
        return dirs
    
    def ensure_directory(self, parent_id, dir_name):
        """ç¡®ä¿ç›®å½•å­˜åœ¨ï¼Œå¦‚æœå·²å­˜åœ¨åˆ™è¿”å›ç°æœ‰ç›®å½•ID"""
        existing_dirs = self.list_directory(parent_id)
        for d in existing_dirs:
            if d["name"] == dir_name:
                return d["id"]
        
        return self.create_directory(parent_id, dir_name)
    
    def offline_download(self, url, parent_id, filename, retry_count=0):
        """æäº¤ç¦»çº¿ä¸‹è½½ä»»åŠ¡"""
        headers = self.token_manager.get_auth_header()
        payload = {
            "url": url,
            "dirID": parent_id,
            "fileName": filename
        }
        
        for attempt in range(retry_count + 1):
            try:
                download_url = f"{OPEN_API_HOST}{API_PATHS['OFFLINE_DOWNLOAD']}"
                response = self._call_api("POST", download_url, json=payload, headers=headers)
                if not response or response.status_code != 200:
                    continue
                
                data = response.json()
                if data.get("code") == 0:
                    return data["data"]["taskID"]
            except Exception as e:
                logger.error(f"æäº¤ç¦»çº¿ä¸‹è½½ä»»åŠ¡å¤±è´¥: {e}")
            time.sleep(1)
        return None
    
    def get_offline_task_progress(self, task_id):
        """è·å–ç¦»çº¿ä¸‹è½½ä»»åŠ¡è¿›åº¦"""
        headers = self.token_manager.get_auth_header()
        params = {"taskID": task_id}
        
        try:
            progress_url = f"{OPEN_API_HOST}{API_PATHS['DOWNLOAD_PROGRESS']}"
            response = self._call_api("GET", progress_url, params=params, headers=headers)
            if not response or response.status_code != 200:
                return 0, -1, "æŸ¥è¯¢å¤±è´¥"
            
            data = response.json()
            if data.get("code") == 0:
                progress_data = data["data"]
                progress = progress_data.get("process", 0)
                status = progress_data.get("status", -1)
                status_text = TASK_STATUS_MAP.get(status, "æœªçŸ¥çŠ¶æ€")
                return progress, status, status_text
            else:
                return 0, -1, "æŸ¥è¯¢å¤±è´¥"
        except Exception as e:
            logger.error(f"è·å–ç¦»çº¿ä»»åŠ¡è¿›åº¦å¤±è´¥: {e}")
            return 0, -1, "æŸ¥è¯¢å¼‚å¸¸"

class FastLinkProcessor:
    @staticmethod
    def parse_share_link(share_link):
        """è§£æç§’ä¼ é“¾æ¥"""
        common_base_path = ""
        is_common_path_format = False
        is_v2_etag_format = False
        
        # ä½¿ç”¨å‰ç¼€æ˜ å°„ç®€åŒ–å¤„ç†
        prefix_map = {
            COMMON_PATH_LINK_PREFIX_V2: (True, True),
            COMMON_PATH_LINK_PREFIX_V1: (True, False),
            LEGACY_FOLDER_LINK_PREFIX_V2: (False, True),
            LEGACY_FOLDER_LINK_PREFIX_V1: (False, False)
        }
        
        for prefix, (is_common, is_v2) in prefix_map.items():
            if share_link.startswith(prefix):
                share_link = share_link[len(prefix):]
                is_common_path_format = is_common
                is_v2_etag_format = is_v2
                break
        
        if is_common_path_format:
            delimiter_pos = share_link.find(COMMON_PATH_DELIMITER)
            if delimiter_pos > -1:
                common_base_path = share_link[:delimiter_pos]
                share_link = share_link[delimiter_pos + 1:]
        
        files = []
        for s_link in share_link.split('$'):
            if not s_link:
                continue
            parts = s_link.split('#')
            if len(parts) < 3:
                continue
            
            etag = parts[0]
            size = parts[1]
            file_path = '#'.join(parts[2:])
            
            if is_common_path_format and common_base_path:
                file_path = common_base_path + file_path
            
            files.append({
                "etag": etag,
                "size": int(size),
                "file_name": file_path,
                "is_v2_etag": is_v2_etag_format
            })
        
        return files
    
    @staticmethod
    def optimized_etag_to_hex(optimized_etag, is_v2_etag):
        """å°†ä¼˜åŒ–åçš„ETagè½¬æ¢ä¸ºåå…­è¿›åˆ¶æ ¼å¼"""
        if not is_v2_etag:
            return optimized_etag
        
        try:
            # å¦‚æœå·²ç»æ˜¯åå…­è¿›åˆ¶æ ¼å¼ï¼Œç›´æ¥è¿”å›
            if len(optimized_etag) == 32 and all(c in '0123456789abcdefABCDEF' for c in optimized_etag):
                return optimized_etag.lower()
            
            num = 0
            for char in optimized_etag:
                if char not in BASE62_CHARS:
                    return optimized_etag
                num = num * 62 + BASE62_CHARS.index(char)
            
            hex_str = hex(num)[2:].lower()
            # å¤„ç†é•¿åº¦
            if len(hex_str) > 32:
                hex_str = hex_str[-32:]
            elif len(hex_str) < 32:
                hex_str = hex_str.zfill(32)
            
            return hex_str
        except Exception as e:
            logger.error(f"ETagè½¬æ¢å¤±è´¥: {e}")
            return optimized_etag
        

# ====================== 115ç½‘ç›˜å·¥å…·ç±» ======================
class ShareTransferTool:
    """115åˆ†äº«é“¾æ¥è½¬å­˜å·¥å…·"""
    
    def __init__(self, cookies: str):
        self.cookies = cookies
        self.user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        
        try:
            from p115 import P115ShareFileSystem
            from p115client import P115Client
            from p115client.tool.util import share_extract_payload
            
            logger.info("ğŸ› ï¸ æ­£åœ¨åˆå§‹åŒ–115å®¢æˆ·ç«¯...")
            self.client = P115Client(cookies)
            logger.info("âœ… 115å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except ImportError:
            logger.error("âŒ ç¼ºå°‘p115clientåº“ï¼Œæ— æ³•ä½¿ç”¨115åŠŸèƒ½")
            raise
        except Exception as e:
            logger.error(f"âŒ 115å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            raise
    
    def get_target_directory_id(self, target_path: str) -> int:
        """è·å–ç›®æ ‡ç›®å½•IDï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º"""
        root_id = 0
        path_parts = [part for part in target_path.split("/") if part]
        current_id = root_id
        
        for part in path_parts:
            found = False
            offset = 0
            limit = 1000
            
            while True:
                resp = self.client.fs_files({"cid": current_id, "offset": offset, "limit": limit})
                
                if not resp["state"]:
                    raise Exception(f"è·å–ç›®å½•åˆ—è¡¨å¤±è´¥: {resp.get('error', 'æœªçŸ¥é”™è¯¯')}")
                
                data_list = resp["data"]
                count = len(data_list)
                
                for item in data_list:
                    if item.get("n") == part and "cid" in item:
                        current_id = int(item["cid"])
                        found = True
                        break
                
                if found:
                    break
                
                total_count = resp.get("count", count)
                if (offset + count) >= total_count:
                    break
                
                offset += count
            
            if not found:
                resp = self.client.fs_mkdir({"pid": current_id, "cname": part})
                
                if resp["state"]:
                    current_id = int(resp["cid"])
                else:
                    error_msg = resp.get("error", "æœªçŸ¥é”™è¯¯")
                    if "å·²å­˜åœ¨" in error_msg or "é‡å" in error_msg:
                        resp = self.client.fs_files({"cid": current_id, "offset": 0, "limit": 1000})
                        if resp["state"]:
                            for item in resp["data"]:
                                if item.get("n") == part and "cid" in item:
                                    current_id = int(item["cid"])
                                    found = True
                                    break
                        if not found:
                            raise Exception(f"åˆ›å»ºç›®å½•å¤±è´¥: {part} - {error_msg}")
                    else:
                        raise Exception(f"åˆ›å»ºç›®å½•å¤±è´¥: {part} - {error_msg}")
        
        return current_id
    
    def transfer_share(self, share_url: str, receive_code: Optional[str], target_path: str) -> int:
        """è½¬å­˜åˆ†äº«å†…å®¹åˆ°æŒ‡å®šç›®å½•ï¼Œè¿”å›ç›®æ ‡ç›®å½•ID"""
        from p115client.tool.util import share_extract_payload
        from p115 import P115ShareFileSystem
        
        data = share_extract_payload(share_url)
        
        share_code = data["share_code"]
        if not receive_code:
            receive_code = data.get("receive_code", "")
        
        # è·å–ç›®æ ‡ç›®å½•ID
        target_dir_id = self.get_target_directory_id(target_path)
        
        # åˆ›å»ºåˆ†äº«æ–‡ä»¶ç³»ç»Ÿå®ä¾‹
        share_fs = P115ShareFileSystem(
            client=self.client, 
            share_code=share_code, 
            receive_code=receive_code
        )
        
        # å‘é€è½¬å­˜è¯·æ±‚
        resp = share_fs.receive(0, target_dir_id)
        
        if resp["state"]:
            logger.info("âœ… è½¬å­˜æˆåŠŸï¼")
            return target_dir_id
        else:
            error_msg = resp.get("error", "æœªçŸ¥é”™è¯¯")
            raise Exception(f"è½¬å­˜å¤±è´¥: {error_msg}")

class PanTransfer:
    """115ç½‘ç›˜åˆ°123äº‘ç›˜è¿ç§»å·¥å…·"""
    
    def __init__(self, pan_client: Pan123Client, cookies: str):
        self.pan_client = pan_client
        
        # åˆå§‹åŒ–115å®¢æˆ·ç«¯
        try:
            from p115client import P115Client
            from p115client.tool.iterdir import iterdir
            
            logger.info("æ­£åœ¨åˆå§‹åŒ–115ç½‘ç›˜å®¢æˆ·ç«¯...")
            self.client_115 = P115Client(cookies=cookies)
            logger.info("115ç½‘ç›˜ç™»å½•æˆåŠŸ")
        except ImportError:
            logger.error("âŒ ç¼ºå°‘p115clientåº“ï¼Œæ— æ³•ä½¿ç”¨115åŠŸèƒ½")
            raise
        except Exception as e:
            logger.error(f"115ç½‘ç›˜ç™»å½•éªŒè¯å¤±è´¥: {str(e)}")
            raise
    
    def get_115_directory_id_by_path(self, path: str) -> int:
        """æ ¹æ®è·¯å¾„è·å–115ç½‘ç›˜ç›®å½•ID"""
        current_id = 0
        path_parts = [part for part in path.split("/") if part]
        
        for part in path_parts:
            found = False
            offset = 0
            limit = 1000
            
            while True:
                resp = self.client_115.fs_files({"cid": current_id, "offset": offset, "limit": limit})
                
                if not resp["state"]:
                    raise Exception(f"è·å–ç›®å½•åˆ—è¡¨å¤±è´¥: {resp.get('error', 'æœªçŸ¥é”™è¯¯')}")
                
                data_list = resp["data"]
                count = len(data_list)
                
                for item in data_list:
                    if item.get("n") == part and "cid" in item:
                        current_id = int(item["cid"])
                        found = True
                        break
                
                if found:
                    break
                
                total_count = resp.get("count", count)
                if (offset + count) >= total_count:
                    break
                
                offset += count
            
            if not found:
                raise Exception(f"åœ¨115ç½‘ç›˜ä¸­æ‰¾ä¸åˆ°ç›®å½•: {part}")
        
        return current_id
    
    def filter_allowed_files(self, file_list: list) -> tuple:
        """è¿‡æ»¤æ‰ä¸å…è®¸çš„æ–‡ä»¶ç±»å‹"""
        allowed_files = []
        filtered_files = []
        
        for file_info in file_list:
            _, ext = os.path.splitext(file_info["name"].lower())
            if ext in ALLOWED_EXTENSIONS:
                allowed_files.append(file_info)
            else:
                filtered_files.append(file_info)
        
        return allowed_files, filtered_files
    
    def get_115_structure(self, dir_id: int) -> tuple:
        """è·å–115ç½‘ç›˜æŒ‡å®šç›®å½•ä¸‹çš„å®Œæ•´ç»“æ„"""
        dir_list = []
        file_list = []
        
        try:
            from p115client.tool.iterdir import iterdir
            
            queue = deque([dir_id])
            visited = set([dir_id])
            
            while queue:
                current_dir_id = queue.popleft()
                
                for item in iterdir(
                    client=self.client_115,
                    cid=current_dir_id,
                    recursive=False,
                    include_dir=True
                ):
                    if item.get("is_dir", False) or item.get("is_directory", False):
                        dir_info = {
                            "id": item["id"],
                            "parent_id": current_dir_id,
                            "name": item["name"]
                        }
                        dir_list.append(dir_info)
                        
                        if item["id"] not in visited:
                            visited.add(item["id"])
                            queue.append(item["id"])
                    else:
                        file_info = {
                            "name": item["name"],
                            "pickcode": item["pickcode"],
                            "size": item["size"],
                            "parent_id": current_dir_id
                        }
                        file_list.append(file_info)
                
                time.sleep(0.2)
        
        except Exception as e:
            logger.error(f"è·å–ç›®å½•ç»“æ„å¤±è´¥: {str(e)}")
        
        return dir_list, file_list
    
    def transfer_files(self, source_dir_id: int, target_dir_id_123: int) -> dict:
        """ä»115ç½‘ç›˜è¿ç§»æ–‡ä»¶åˆ°123äº‘ç›˜ï¼Œè¿”å›ç»Ÿè®¡ä¿¡æ¯"""
        start_time = time.time()
        stats = {
            "start_time": start_time,
            "end_time": None,
            "total_files": 0,
            "filtered_files": 0,
            "submitted_files": 0,
            "success_files": 0,
            "failed_files": 0,
            "total_size": 0,
            "filtered_size": 0,
            "submitted_size": 0
        }
        
        # å»ºç«‹ç›®å½•æ˜ å°„
        dir_mapping = {source_dir_id: target_dir_id_123}
        
        # è·å–115æ–‡ä»¶ä¿¡æ¯
        dir_list, file_list = self.get_115_structure(source_dir_id)
        
        if not dir_list and not file_list:
            logger.warning("æ²¡æœ‰æ‰¾åˆ°å¯è¿ç§»çš„æ–‡ä»¶æˆ–ç›®å½•")
            return stats
        
        # æ„å»ºç›®å½•æ ‘ç»“æ„
        dir_tree = defaultdict(list)
        for dir_info in dir_list:
            dir_tree[dir_info["parent_id"]].append(dir_info)
        
        # ä½¿ç”¨BFSåˆ›å»ºç›®å½•ç»“æ„
        queue = deque(dir_tree.get(source_dir_id, []))
        created_dirs = 0
        
        logger.info("å¼€å§‹åœ¨123äº‘ç›˜ä¸Šåˆ›å»ºç›®å½•ç»“æ„...")
        while queue:
            dir_info = queue.popleft()
            parent_115_id = dir_info["parent_id"]
            dir_name = dir_info["name"]
            
            parent_123_id = dir_mapping.get(parent_115_id)
            if parent_123_id is None:
                continue
            
            new_dir_id = self.pan_client.ensure_directory(parent_123_id, dir_name)
            if new_dir_id:
                dir_mapping[dir_info["id"]] = new_dir_id
                created_dirs += 1
                
                if dir_info["id"] in dir_tree:
                    queue.extend(dir_tree[dir_info["id"]])
            
            time.sleep(0.2)
        
        logger.info(f"ç›®å½•åˆ›å»ºå®Œæˆ! æˆåŠŸåˆ›å»º {created_dirs} ä¸ªç›®å½•")
        
        # æ–‡ä»¶è¿‡æ»¤
        allowed_files, filtered_files = self.filter_allowed_files(file_list)
        stats["total_files"] = len(file_list)
        stats["filtered_files"] = len(filtered_files)
        stats["total_size"] = sum(f["size"] for f in file_list)
        stats["filtered_size"] = sum(f["size"] for f in filtered_files)
        
        # è¿ç§»æ–‡ä»¶
        submitted_files = allowed_files
        stats["submitted_files"] = len(submitted_files)
        stats["submitted_size"] = sum(f["size"] for f in submitted_files)
        
        logger.info(f"å¼€å§‹è¿ç§» {len(submitted_files)} ä¸ªæ–‡ä»¶åˆ°123äº‘ç›˜ (æ€»å¤§å°: {self.format_size(stats['submitted_size'])})...")
        
        success_count = 0
        failed_files = []
        task_list = []
        
        for i, file_info in enumerate(submitted_files, 1):
            file_name = file_info["name"]
            target_dir_id = dir_mapping.get(file_info["parent_id"], target_dir_id_123)
            direct_link = f"{CUSTOM_DIRECT_LINK_SERVICE}{file_info['pickcode']}"
            
            task_id = self.pan_client.offline_download(direct_link, target_dir_id, file_name, retry_count=2)
            if task_id:
                success_count += 1
                task_list.append({
                    "task_id": task_id,
                    "file_name": file_name
                })
            else:
                failed_files.append(file_info)
            
            # æ¯10ä¸ªæ–‡ä»¶æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
            if i % 10 == 0 or i == len(submitted_files):
                logger.info(f"å·²æäº¤: {i}/{len(submitted_files)}")
            
            time.sleep(0.5)
        
        # æœ€ç»ˆç»Ÿè®¡
        end_time = time.time()
        stats["end_time"] = end_time
        stats["success_files"] = success_count
        stats["failed_files"] = len(failed_files)
        
        elapsed_time = end_time - start_time
        hours, rem = divmod(elapsed_time, 3600)
        minutes, seconds = divmod(rem, 60)
        time_str = f"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d}"
        
        logger.info(f"è¿ç§»å®Œæˆ! æˆåŠŸæäº¤ {success_count}/{len(submitted_files)} ä¸ªæ–‡ä»¶")
        logger.info(f"æ€»è€—æ—¶: {time_str}")
        
        return stats
    
    def delete_115_directory(self, dir_id: int):
        """åˆ é™¤115ç½‘ç›˜ç›®å½•ï¼ˆç§»åŠ¨åˆ°å›æ”¶ç«™ï¼‰"""
        try:
            resp = self.client_115.fs_delete([dir_id])
            if not resp["state"]:
                logger.error(f"åˆ é™¤å¤±è´¥: {resp.get('error', 'æœªçŸ¥é”™è¯¯')}")
        except Exception as e:
            logger.error(f"åˆ é™¤ç›®å½•æ—¶å‡ºé”™: {str(e)}")
    
    @staticmethod
    def format_size(size_bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        for unit in ["B", "KB", "MB", "GB", "TB"]:
            if size_bytes < 1024.0:
                return f"{size_bytes:.2f} {unit}"
            size_bytes /= 1024.0
        return f"{size_bytes:.2f} TB"


class TelegramBotHandler:
    def __init__(self, token, pan_client, allowed_user_ids):
        self.token = token
        self.pan_client = pan_client
        self.allowed_user_ids = allowed_user_ids
        self.updater = Updater(token, use_context=True)
        self.dispatcher = self.updater.dispatcher
        self.start_time = pan_client.token_manager.start_time
        self.active_tasks = {}

        # åˆå§‹åŒ–115å·¥å…·
        self.share_transfer = None
        if COOKIES_115:
            try:
                self.share_transfer = ShareTransferTool(COOKIES_115)
            except Exception as e:
                logger.error(f"115å·¥å…·åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # æ³¨å†Œå¤„ç†ç¨‹åº
        self.dispatcher.add_handler(CommandHandler("start", self.start_command))
        self.dispatcher.add_handler(CommandHandler("export", self.export_command))
        self.dispatcher.add_handler(CommandHandler("sync_full", self.sync_full_command))
        self.dispatcher.add_handler(CommandHandler("clear_trash", self.clear_trash_command))
        self.dispatcher.add_handler(CommandHandler("add", self.add_command))
        self.dispatcher.add_handler(CommandHandler("delete", self.delete_command))
        self.dispatcher.add_handler(CommandHandler("info", self.info_command))
        self.dispatcher.add_handler(CommandHandler("refresh_token", self.refresh_token_command))
        self.dispatcher.add_handler(CommandHandler("migrate", self.migrate_command))
        self.dispatcher.add_handler(MessageHandler(Filters.text & ~Filters.command, self.handle_text))
        self.dispatcher.add_handler(MessageHandler(Filters.document, self.handle_document))
        self.dispatcher.add_handler(CallbackQueryHandler(self.button_callback))
        
        # è®¾ç½®èœå•å‘½ä»¤
        self.set_menu_commands()
    
    def set_menu_commands(self):
        """è®¾ç½®Telegram Botèœå•å‘½ä»¤"""
        commands = [
            BotCommand("start", "ä¸ªäººä¿¡æ¯"),
            BotCommand("export", "å¯¼å‡ºJSON"),
            BotCommand("sync_full", "å…¨é‡åŒæ­¥"),
            BotCommand("info", "ç”¨æˆ·ä¿¡æ¯"),
            BotCommand("add", "æ·»åŠ ç”¨æˆ·"),
            BotCommand("delete", "åˆ é™¤ç”¨æˆ·"),
            BotCommand("migrate", "115æ¬è¿"),            
            BotCommand("clear_trash", "æ¸…ç©ºå›æ”¶ç«™"),
            BotCommand("refresh_token", "åˆ·æ–°Token"),
        ]
        
        try:
            self.updater.bot.set_my_commands(commands)
        except Exception as e:
            logger.error(f"è®¾ç½®èœå•å‘½ä»¤å¤±è´¥: {e}")
    
    def start(self):
        """å¯åŠ¨æœºå™¨äºº"""
        try:
            # å¯åŠ¨è½®è¯¢å¹¶æ¸…é™¤å†å²æ¶ˆæ¯
            self.updater.start_polling(drop_pending_updates=True)
            logger.info("ğŸ¤– æœºå™¨äººå·²å¯åŠ¨ï¼Œç­‰å¾…æ¶ˆæ¯...")
            self.updater.idle()
        except Exception as e:
            logger.error(f"å¯åŠ¨æœºå™¨äººå¤±è´¥: {e}")
    
    # ç®¡ç†å‘˜æƒé™æ£€æŸ¥è£…é¥°å™¨
    def admin_required(func):
        @wraps(func)
        def wrapper(self, update: Update, context: CallbackContext, *args, **kwargs):
            user_id = update.message.from_user.id
            if user_id not in self.allowed_user_ids:
                return
            return func(self, update, context, *args, **kwargs)
        return wrapper
    
    def auto_delete_message(self, context, chat_id, message_id, delay=3):
        """è‡ªåŠ¨åˆ é™¤æ¶ˆæ¯ï¼ˆæ”¯æŒç¾¤èŠå’Œç§èŠï¼‰"""
        def delete():
            try:
                context.bot.delete_message(chat_id=chat_id, message_id=message_id)
            except Exception:
                pass
        threading.Timer(delay, delete).start()
    
    def send_auto_delete_message(self, update, context, text, delay=3, chat_id=None, parse_mode=None):
        """å‘é€è‡ªåŠ¨åˆ é™¤çš„æ¶ˆæ¯"""
        if chat_id is None:
            if update and update.message:
                chat_id = update.message.chat_id
            elif update and update.callback_query and update.callback_query.message:
                chat_id = update.callback_query.message.chat_id
            elif context and hasattr(context, '_chat_id'):
                chat_id = context._chat_id
            else:
                return None
        
        message = context.bot.send_message(chat_id=chat_id, text=text, parse_mode=parse_mode)
        self.auto_delete_message(context, chat_id, message.message_id, delay)
        return message  # è¿”å›æ¶ˆæ¯å¯¹è±¡
    
    @admin_required
    def start_command(self, update: Update, context: CallbackContext):
        """å¤„ç†/startå‘½ä»¤ - ä¼˜åŒ–ç‰ˆç”¨æˆ·ä¿¡æ¯è¾“å‡º"""
        try:
            user_info = self.pan_client.get_user_info()
            if not user_info:
                self.send_auto_delete_message(update, context, "âŒ æ— æ³•è·å–ç”¨æˆ·ä¿¡æ¯")
                return
            
            # è®¡ç®—è¿è¡Œæ—¶é—´
            uptime = datetime.now() - self.start_time
            days = uptime.days
            hours, remainder = divmod(uptime.seconds, 3600)
            minutes, seconds = divmod(remainder, 60)
            
            # æ ¼å¼åŒ–æ‰‹æœºå·ç å’ŒUID
            phone = user_info.get("passport", "")
            if phone and len(phone) > 7:
                phone = phone[:3] + "*" * 4 + phone[-4:]
            
            uid = str(user_info.get("uid", ""))
            if uid and len(uid) > 6:
                uid = uid[:3] + "*" * (len(uid) - 6) + uid[-3:]
            
            # æ ¼å¼åŒ–å­˜å‚¨ç©ºé—´
            space_permanent = format_size(user_info.get("spacePermanent", 0))
            space_used = format_size(user_info.get("spaceUsed", 0))
            direct_traffic = format_size(user_info.get("directTraffic", 0))
            
            # è®¡ç®—å­˜å‚¨ç©ºé—´ä½¿ç”¨ç‡
            if user_info.get("spacePermanent", 0) > 0:
                usage_percent = (user_info.get("spaceUsed", 0) / user_info.get("spacePermanent", 1)) * 100
                usage_bar = generate_usage_bar(usage_percent)
            else:
                usage_percent = 0
                usage_bar = ""
            
            # æ„å»ºç”¨æˆ·ä¿¡æ¯æ¶ˆæ¯
            message = (
                f"ğŸš€ <b>123äº‘ç›˜ç”¨æˆ·ä¿¡æ¯</b> | {'ğŸ‘‘ <b>å°Šäº«è´¦æˆ·</b>' if user_info.get('vip', False) else 'ğŸ”’ <b>æ™®é€šè´¦æˆ·</b>'}\n"
                f"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
                f"ğŸ‘¤ <b>æ˜µç§°:</b> {user_info.get('nickname', 'æœªçŸ¥')}\n"
                f"ğŸ†” <b>è´¦æˆ·ID:</b> {uid}\n"
                f"ğŸ“± <b>æ‰‹æœºå·ç :</b> {phone}\n\n"
                f"ğŸ’¾ <b>å­˜å‚¨ç©ºé—´</b> ({usage_percent:.1f}%)\n"
                f"â”œ æ°¸ä¹…: {space_permanent}\n"
                f"â”œ å·²ç”¨: {space_used}\n"
                f"â”” {usage_bar}\n\n"
                f"ğŸ“¡ <b>æµé‡ä¿¡æ¯</b>\n"
                f"â”” ç›´é“¾: {direct_traffic}\n"
                f"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n"
                f"âš™ï¸ <b>å½“å‰é…ç½®:</b>\n"
                f"â”œ ä¿å­˜ç›®å½•: <code>{DEFAULT_SAVE_DIR or 'æ ¹ç›®å½•'}</code>\n"
                f"â”œ å¯¼å‡ºç›®å½•: <code>{', '.join(EXPORT_BASE_DIRS) if EXPORT_BASE_DIRS else 'æ ¹ç›®å½•'}</code>\n"
                f"â”œ æœç´¢æ·±åº¦: <code>{SEARCH_MAX_DEPTH}å±‚</code>\n"
                f"â”” æ•°æ®ç¼“å­˜: <code>{len(self.pan_client.directory_cache)}</code>\n\n"
                f"ğŸ¤– <b>æœºå™¨äººæ§åˆ¶ä¸­å¿ƒ</b>\n"
                f"â–«ï¸ /export - å¯¼å‡ºæ–‡ä»¶\n"
                f"â–«ï¸ /sync_full - å…¨é‡åŒæ­¥\n"
                f"â–«ï¸ /info - æŸ¥è¯¢ç”¨æˆ·ä¿¡æ¯\n"
                f"â–«ï¸ /add - æ·»åŠ ç”¨æˆ·\n"    
                f"â–«ï¸ /delete - åˆ é™¤ç”¨æˆ·\n"                                             
                f"â–«ï¸ /clear_trash - æ¸…ç©ºå›æ”¶ç«™\n"
                f"â–«ï¸ /migrate - 115æ¬è¿\n\n"
                f"ğŸ“¦ <b>Version:</b> <code>{VERSION}</code>\n"
                f"â±ï¸ <b>å·²è¿è¡Œ:</b> {days}å¤©{hours}å°æ—¶{minutes}åˆ†{seconds}ç§’"
            )

            update.message.reply_text(
                message, 
                parse_mode="HTML",
                disable_web_page_preview=True
            )
        except Exception as e:
            logger.error(f"å¤„ç†/startå‘½ä»¤å‡ºé”™: {e}")
            self.send_auto_delete_message(update, context, "âŒ è·å–ç”¨æˆ·ä¿¡æ¯å¤±è´¥")

    def search_database_by_name(self, name_pattern):
        """åœ¨æ•°æ®åº“ä¸­è¿›è¡Œæ¨¡ç³Šæœç´¢"""
        try:
            with closing(sqlite3.connect(DB_PATH)) as conn:
                conn.row_factory = sqlite3.Row
                c = conn.cursor()
                c.execute("SELECT * FROM directory_cache WHERE filename LIKE ? ORDER BY filename", (f'%{name_pattern}%',))
                rows = c.fetchall()
                return [dict(row) for row in rows]
        except Exception as e:
            logger.error(f"æ•°æ®åº“æœç´¢å¤±è´¥: {e}")
            return []
    
    def get_user_privilege(self, user_id):
        """è·å–ç”¨æˆ·æƒé™ä¿¡æ¯"""
        try:
            with closing(sqlite3.connect(DB_PATH)) as conn:
                conn.row_factory = sqlite3.Row
                c = conn.cursor()
                c.execute("SELECT * FROM user_privileges WHERE user_id = ?", (user_id,))
                row = c.fetchone()
                if row:
                    return dict(row)
        except Exception as e:
            logger.error(f"æŸ¥è¯¢ç”¨æˆ·æƒé™å¤±è´¥: {e}")
        return None
    
    def update_user_export_count(self, user_id, folder_count):
        """æ›´æ–°ç”¨æˆ·å¯¼å‡ºæ¬¡æ•°"""
        try:
            with closing(sqlite3.connect(DB_PATH)) as conn:
                c = conn.cursor()
                today = datetime.now().strftime("%Y-%m-%d")
                
                # è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯
                user_info = self.get_user_privilege(user_id)
                if user_info:
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡ç½®
                    last_export_date = user_info.get("last_export_date")
                    if last_export_date and last_export_date != today:
                        # é‡ç½®æ¬¡æ•°
                        c.execute("UPDATE user_privileges SET export_count = 0, last_export_date = ? WHERE user_id = ?", 
                                  (today, user_id))
                    
                    # å¢åŠ å¯¼å‡ºæ¬¡æ•°
                    c.execute("UPDATE user_privileges SET export_count = export_count + ?, last_export_date = ? WHERE user_id = ?", 
                              (folder_count, today, user_id))
                else:
                    # æ–°ç”¨æˆ·
                    c.execute("INSERT INTO user_privileges (user_id, privilege_level, export_count, last_export_date) VALUES (?, ?, ?, ?)",
                              (user_id, "user", folder_count, today))
                
                # è®°å½•å¯¼å‡ºå†å²
                c.execute("INSERT INTO export_history (user_id, folder_count) VALUES (?, ?)",
                          (user_id, folder_count))
                
                conn.commit()
            return True
        except Exception as e:
            logger.error(f"æ›´æ–°ç”¨æˆ·å¯¼å‡ºæ¬¡æ•°å¤±è´¥: {e}")
            return False

    def export_command(self, update: Update, context: CallbackContext):
        """å¤„ç†/exportå‘½ä»¤"""
        user_id = update.message.from_user.id
        search_query = " ".join(context.args) if context.args else ""
        chat_type = update.message.chat.type
        in_group = chat_type in ['group', 'supergroup']

        # å¦‚æœæ˜¯ç¾¤èŠï¼Œå…ˆåˆ é™¤ç”¨æˆ·æ¶ˆæ¯
        if in_group:
            try:
                update.message.delete()
            except Exception:
                pass

        if not search_query:
            self.send_auto_delete_message(update, context, "âŒ è¯·æŒ‡å®šæ–‡ä»¶å¤¹åç§°ï¼æ ¼å¼: /export <æ–‡ä»¶å¤¹åç§°>")
            return
         
        # æ£€æŸ¥ç”¨æˆ·æƒé™
        user_info = self.get_user_privilege(user_id)
        is_admin = user_id in self.allowed_user_ids
        is_svip = user_info and user_info.get("privilege_level") == "svip"  # æ–°å¢SVIPæ£€æŸ¥

        # éç®¡ç†å‘˜ä¸”éSVIPç”¨æˆ·æ£€æŸ¥æƒé™
        if not is_admin and not is_svip:  # ä¿®æ”¹æ£€æŸ¥æ¡ä»¶
            if not user_info:
                self.send_auto_delete_message(update, context, "âŒ æ‚¨æ²¡æœ‰ä½¿ç”¨å¯¼å‡ºåŠŸèƒ½çš„æƒé™ï¼Œè¯·è”ç³»ç®¡ç†å‘˜")
                return
            if search_query.lower() in BANNED_EXPORT_NAMES:
                self.send_auto_delete_message(update, context, f"âŒ ç¦æ­¢å¯¼å‡ºåç§°ä¸º '{search_query}' çš„æ–‡ä»¶å¤¹")
                return
     
            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶
            today = datetime.now().strftime("%Y-%m-%d")
            last_export_date = user_info.get("last_export_date", "")
            export_count = user_info.get("export_count", 0)
            
            # å¦‚æœæ˜¯æ–°çš„ä¸€å¤©ï¼Œé‡ç½®æ¬¡æ•°
            if last_export_date != today:
                export_count = 0
            
            if export_count >= DAILY_EXPORT_LIMIT:
                self.send_auto_delete_message(update, context, f"âŒ æ‚¨ä»Šæ—¥çš„å¯¼å‡ºæ¬¡æ•°å·²è¾¾ä¸Šé™ï¼ˆ{DAILY_EXPORT_LIMIT}æ¬¡ï¼‰ï¼Œè¯·æ˜å¤©å†è¯•æˆ–è”ç³»ç®¡ç†å‘˜å‡çº§æƒé™")
                return
        
        if in_group:
            # å‘é€æç¤ºæ¶ˆæ¯å¹¶ä¿å­˜æ¶ˆæ¯IDä»¥ä¾¿æ’¤å›
            msg = self.send_auto_delete_message(
              update, context,
              f"ğŸ” æ­£åœ¨æœç´¢æ–‡ä»¶å¤¹: '{search_query}'...\nç»“æœå°†é€šè¿‡ç§èŠå‘é€ç»™æ‚¨",
              delay=5
            )
            context.user_data['group_temp_msg_id'] = msg.message_id
            context.user_data['group_chat_id'] = update.message.chat_id  # ä¿å­˜ç¾¤èŠID
        else:
            self.send_auto_delete_message(update, context, f"ğŸ” æ­£åœ¨æœç´¢æ–‡ä»¶å¤¹: '{search_query}'...")

        try:
            results = self.search_database_by_name(search_query)
            if not results:
                self.send_auto_delete_message(update, context, f"âŒ æœªæ‰¾åˆ°åŒ…å« '{search_query}' çš„æ–‡ä»¶å¤¹")
                return
            
            context.user_data['export_search_results'] = results
            context.user_data['export_selected_indices'] = set()
            
            keyboard = []
            max_buttons = 40
            for i, result in enumerate(results[:max_buttons]):
                filename = result["filename"]
                display_name = filename if len(filename) <= 50 else f"{filename[:47]}..."
                keyboard.append([
                    InlineKeyboardButton(f"{i+1}. {display_name}", callback_data=f"export_toggle_{i}")
                ])
            
            action_buttons = [
                InlineKeyboardButton("âœ… å…¨é€‰", callback_data="export_select_all"),
                InlineKeyboardButton("ğŸ”„ åé€‰", callback_data="export_deselect_all"),
                InlineKeyboardButton("ğŸš€ å¯¼å‡º", callback_data="export_confirm"),
                InlineKeyboardButton("âŒ é€€å‡º", callback_data="export_cancel")
            ]
            
            keyboard.append(action_buttons[:2])
            keyboard.append(action_buttons[2:])
            reply_markup = InlineKeyboardMarkup(keyboard)

            if in_group:
                message = context.bot.send_message(
                    chat_id=update.message.chat_id,
                    text=f"âœ… æ‰¾åˆ° {len(results)} ä¸ªåŒ¹é…é¡¹\nè¯·é€‰æ‹©è¦å¯¼å‡ºçš„æ–‡ä»¶å¤¹:",
                    reply_markup=reply_markup
                )
            else:
                message = update.message.reply_text(
                    f"âœ… æ‰¾åˆ° {len(results)} ä¸ªåŒ¹é…é¡¹\nè¯·é€‰æ‹©è¦å¯¼å‡ºçš„æ–‡ä»¶å¤¹:",
                    reply_markup=reply_markup
                )
            
            context.user_data['export_message_id'] = message.message_id
            
            job_context = {
                "chat_id": update.message.chat_id,
                "user_data": context.user_data
            }
            context.job_queue.run_once(
                self.export_timeout, 
                60, 
                context=job_context,
                name=f"export_timeout_{message.message_id}"
            )
        except Exception as e:
            logger.error(f"æœç´¢æ–‡ä»¶å¤¹å¤±è´¥: {e}")
            self.send_auto_delete_message(update, context, f"âŒ æœç´¢å¤±è´¥: {e}")

    def export_choice_callback(self, update: Update, context: CallbackContext):
        """å¤„ç†å¯¼å‡ºé€‰æ‹©çš„å›è°ƒ"""
        query = update.callback_query
        query.answer()
        data = query.data
        
        results = context.user_data.get('export_search_results', [])
        selected_indices = context.user_data.get('export_selected_indices', set())
        
        if not results:
            query.edit_message_text("âŒ é€‰æ‹©è¶…æ—¶ï¼Œè¯·é‡æ–°æœç´¢")
            return
        
        if data.startswith("export_toggle_"):
            try:
                index = int(data.split("_")[2])
                if index in selected_indices:
                    selected_indices.remove(index)
                else:
                    selected_indices.add(index)
            except (ValueError, IndexError):
                pass
        elif data == "export_select_all":
            selected_indices = set(range(len(results)))
        elif data == "export_deselect_all":
            selected_indices = set()
        elif data == "export_confirm":
            self.process_export_selection(update, context, selected_indices)
            return
        elif data == "export_cancel":
            query.edit_message_text("âŒ å¯¼å‡ºæ“ä½œå·²å–æ¶ˆ")
            self.cleanup_export_context(context.user_data)
            return
        
        context.user_data['export_selected_indices'] = selected_indices
        self.update_export_message(update, context, results, selected_indices)
    
    def update_export_message(self, update: Update, context: CallbackContext, results, selected_indices):
        """æ›´æ–°å¯¼å‡ºé€‰æ‹©æ¶ˆæ¯"""
        query = update.callback_query
        selected_count = len(selected_indices)
        
        keyboard = []
        max_buttons = 40
        for i, result in enumerate(results[:max_buttons]):
            filename = result["filename"]
            display_name = filename if len(filename) <= 50 else f"{filename[:47]}..."
            prefix = "âœ… " if i in selected_indices else "â¬œ "
            keyboard.append([
                InlineKeyboardButton(f"{prefix}{i+1}. {display_name}", callback_data=f"export_toggle_{i}")
            ])
        
        action_buttons = [
            InlineKeyboardButton("âœ… å…¨é€‰", callback_data="export_select_all"),
            InlineKeyboardButton("ğŸ”„ åé€‰", callback_data="export_deselect_all"),
            InlineKeyboardButton(f"ğŸš€ å¯¼å‡º({selected_count})", callback_data="export_confirm"),
            InlineKeyboardButton("âŒ å–æ¶ˆ", callback_data="export_cancel")
        ]
        
        keyboard.append(action_buttons[:2])
        keyboard.append(action_buttons[2:])
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        query.edit_message_text(
            text=f"âœ… æ‰¾åˆ° {len(results)} ä¸ªåŒ¹é…é¡¹\nå·²é€‰æ‹© {selected_count} ä¸ªæ–‡ä»¶å¤¹:",
            reply_markup=reply_markup
        )
    
    def export_timeout(self, context: CallbackContext):
        """å¯¼å‡ºé€‰æ‹©è¶…æ—¶å¤„ç†"""
        job = context.job
        if not job or not job.context:
            return
        
        job_context = job.context
        chat_id = job_context.get("chat_id")
        user_data = job_context.get("user_data", {})

        if not chat_id:
            return
        
        if 'export_message_id' in user_data:
            message_id = user_data['export_message_id']
            try:
                self.updater.bot.edit_message_text(chat_id=chat_id, message_id=message_id, text="â±ï¸ æ“ä½œè¶…æ—¶ï¼Œå¯¼å‡ºå·²è‡ªåŠ¨å–æ¶ˆ")
            except Exception:
                pass
        
        self.cleanup_export_context(user_data)
    
    def cleanup_export_context(self, user_data: dict):
        """æ¸…ç†å¯¼å‡ºç›¸å…³çš„ä¸Šä¸‹æ–‡æ•°æ®"""
        keys_to_remove = ['export_search_results', 'export_selected_indices', 'export_message_id', 'group_temp_msg_id']
        for key in keys_to_remove:
            if key in user_data:
                del user_data[key]
    
    def process_export_selection(self, update: Update, context: CallbackContext, selected_indices):
        """å¤„ç†é€‰æ‹©çš„å¯¼å‡ºä»»åŠ¡"""
        query = update.callback_query
        results = context.user_data.get('export_search_results', [])
        if not results or not selected_indices:
            query.edit_message_text("âŒ è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæ–‡ä»¶å¤¹")
            return
            
        user_id = query.from_user.id
        folder_count = len(selected_indices)
        
        # æ£€æŸ¥ç”¨æˆ·æƒé™
        user_info = self.get_user_privilege(user_id)
        is_admin = user_id in self.allowed_user_ids
        is_svip = user_info and user_info.get("privilege_level") == "svip"  # æ–°å¢SVIPæ£€æŸ¥
        
        # æ™®é€šç”¨æˆ·æ£€æŸ¥å¯¼å‡ºé™åˆ¶
        if not is_admin and not is_svip:  # æ™®é€šç”¨æˆ·
            today = datetime.now().strftime("%Y-%m-%d")
            last_export_date = user_info.get("last_export_date", "")
            export_count = user_info.get("export_count", 0)
            
            # å¦‚æœæ˜¯æ–°çš„ä¸€å¤©ï¼Œé‡ç½®æ¬¡æ•°
            if last_export_date != today:
                export_count = 0
            
            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶
            if export_count + folder_count > DAILY_EXPORT_LIMIT:
                query.edit_message_text(f"âŒ æ‚¨ä»Šæ—¥çš„å¯¼å‡ºæ¬¡æ•°å·²è¾¾ä¸Šé™ï¼ˆ{DAILY_EXPORT_LIMIT}æ¬¡ï¼‰ï¼Œå·²ä½¿ç”¨: {export_count}æ¬¡ï¼Œæœ¬æ¬¡è¯·æ±‚: {folder_count}æ¬¡")
                return
            
        # åˆ¤æ–­æ˜¯å¦ç¾¤èŠç¯å¢ƒ
        in_group = 'group_temp_msg_id' in context.user_data

        # å‘é€ä¸´æ—¶æ¶ˆæ¯
        if in_group:
            # æ’¤å›ä¹‹å‰çš„ä¸´æ—¶æ¶ˆæ¯
            try:
                context.bot.delete_message(
                    chat_id=context.user_data['group_chat_id'],
                    message_id=context.user_data['group_temp_msg_id']
                )
            except Exception:
                pass
        
        # å‘é€æ–°æç¤º
        if in_group:
            query.edit_message_text(f"â³ å¼€å§‹å¯¼å‡º {folder_count} ä¸ªæ–‡ä»¶å¤¹åˆ°ç§èŠ...")
            self.auto_delete_message(context, query.message.chat_id, query.message.message_id, 3)
        else:
            query.edit_message_text(f"â³ å¼€å§‹å¯¼å‡º {folder_count} ä¸ªæ–‡ä»¶å¤¹...")
            self.auto_delete_message(context, query.message.chat_id, query.message.message_id, 3)
         
        if 'export_message_id' in context.user_data:
            message_id = context.user_data['export_message_id']
            job_name = f"export_timeout_{message_id}"
            for job in context.job_queue.get_jobs_by_name(job_name):
                job.schedule_removal()
        
        total = folder_count
        progress_messages = []
        
        for i, idx in enumerate(selected_indices):
            selected_folder = results[idx]
            folder_id = selected_folder["file_id"]
            folder_name = selected_folder["filename"]
            folder_path = selected_folder["full_path"]
            
            files = self.pan_client.get_directory_files(folder_id, folder_name)
            if not files:
                logger.warning(f"æ–‡ä»¶å¤¹ä¸ºç©º: {folder_name}")
                continue
                
            # æ¸…ç†æ–‡ä»¶å¤¹åç§°ï¼ˆç§»é™¤éæ³•å­—ç¬¦ï¼‰
            clean_folder_name = re.sub(r'[\\/*?:"<>|]', "", folder_name)
            # åœ¨æ–‡ä»¶å¤¹åç§°åæ·»åŠ æ–œæ 
            common_path = f"{clean_folder_name}/"
            # æ–‡ä»¶åä¿æŒåŸå§‹æ ¼å¼ï¼ˆä¸å¸¦æ–œæ ï¼‰
            file_name = f"{clean_folder_name}.json"
            
            # æ¯å¤„ç†3ä¸ªæ–‡ä»¶å¤¹æ›´æ–°ä¸€æ¬¡è¿›åº¦
            if i % 3 == 0:
                try:
                    msg = context.bot.send_message(
                        chat_id=query.message.chat_id,
                        text=f"â³ æ­£åœ¨å¤„ç†æ–‡ä»¶å¤¹ [{i+1}/{total}]:\nâ”œ åç§°: {folder_name}\nâ”” è·¯å¾„: {folder_path}"
                    )
                    progress_messages.append(msg.message_id)
                except Exception:
                    pass
            
            # è®¡ç®—æ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯
            total_size = sum(file_info["size"] for file_info in files)
            file_count = len(files)
            
            json_data = {
                "usesBase62EtagsInExport": False,
                "commonPath": common_path,
                "totalFilesCount": file_count,
                "totalSize": total_size,
                "formattedTotalSize": format_size(total_size),
                "files": [
                    {"path": file_info["path"], "etag": file_info["etag"], "size": file_info["size"]}
                    for file_info in files
                ]
            }
            
            with open(file_name, "w", encoding="utf-8") as f:
                json.dump(json_data, f, ensure_ascii=False, indent=2)
            
            user_info = self.pan_client.get_user_info()
            nickname = user_info.get("nickname", "æœªçŸ¥ç”¨æˆ·") if user_info else "æœªçŸ¥ç”¨æˆ·"

            # è®¡ç®—å¹³å‡å¤§å°
            avg_size = total_size / file_count if file_count > 0 else 0
            
            caption = (             
                f"âœ¨ åˆ†äº«è€…ï¼š{nickname}\n"
                f"ğŸ“ æ–‡ä»¶å: {clean_folder_name}\n"
                f"ğŸ“ æ–‡ä»¶æ•°: {file_count}\n"
                f"ğŸ’¾ æ€»å¤§å°ï¼š{format_size(total_size)}\n"
                f"ğŸ“Š å¹³å‡å¤§å°ï¼š{format_size(avg_size)}\n\n"
                f"â¤ï¸ 123å› æ‚¨åˆ†äº«æ›´å®Œç¾ï¼"
            )

            # åœ¨å‘é€æ–‡ä»¶å¤„ä¿®æ”¹ä¸ºç§èŠå‘é€
            if in_group:
                # é€šè¿‡ç§èŠå‘é€æ–‡ä»¶
                try:
                    with open(file_name, "rb") as f:
                        context.bot.send_document(
                            chat_id=user_id,  # ç›´æ¥å‘é€ç»™ç”¨æˆ·IDï¼ˆç§èŠï¼‰
                            document=f,
                            filename=file_name,
                            caption=caption
                        )
                except Exception as e:
                    logger.error(f"ç§èŠå‘é€å¤±è´¥: {e}")
                    # åœ¨ç¾¤èŠä¸­æç¤ºç”¨æˆ·
                    context.bot.send_message(
                        chat_id=context.user_data['group_chat_id'],
                        text=f"âŒ æ— æ³•å‘é€ç§èŠæ¶ˆæ¯ï¼Œè¯·å…ˆç§èŠæˆ‘ @{context.bot.username} å¹¶ç‚¹å‡»'å¼€å§‹'"
                    )
            else:
                # ç§èŠç¯å¢ƒæ­£å¸¸å‘é€
                with open(file_name, "rb") as f:
                    context.bot.send_document(
                    chat_id=query.message.chat_id,
                    document=f,
                    filename=file_name,
                    caption=caption
                )               
            
            os.remove(file_name)
        
        # æ›´æ–°ç”¨æˆ·å¯¼å‡ºæ¬¡æ•°
        self.update_user_export_count(user_id, folder_count)
        
        # å¯¼å‡ºå®Œæˆååˆ é™¤æ‰€æœ‰è¿›åº¦æ¶ˆæ¯
        chat_id = query.message.chat_id
        for msg_id in progress_messages:
            try:
                context.bot.delete_message(chat_id=chat_id, message_id=msg_id)
            except Exception:
                pass
        
        self.cleanup_export_context(context.user_data)
 
    @admin_required
    def handle_document(self, update: Update, context: CallbackContext):
        """å¤„ç†æ–‡æ¡£æ¶ˆæ¯"""
        document = update.message.document
        file_name = document.file_name
        
        if document.mime_type != "application/json" and not file_name.endswith(".json"):
            self.send_auto_delete_message(update, context, "âŒ è¯·å‘é€JSONæ ¼å¼çš„æ–‡ä»¶ï¼")
            return
        
        self.send_auto_delete_message(update, context, "ğŸ“¥ æ”¶åˆ°JSONæ–‡ä»¶ï¼Œå¼€å§‹ä¸‹è½½å¹¶è§£æ...")
        
        file = context.bot.get_file(document.file_id)
        file_path = f"temp_{document.file_id}.json"
        file.download(file_path)
        
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                json_data = json.load(f)
            os.remove(file_path)
            self.process_json_file(update, context, json_data)
        except Exception as e:
            logger.error(f"å¤„ç†JSONæ–‡ä»¶å‡ºé”™: {e}")
            self.send_auto_delete_message(update, context, f"âŒ å¤„ç†JSONæ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    @admin_required
    def process_fast_link(self, update: Update, context: CallbackContext, share_link):
        """å¤„ç†ç§’ä¼ é“¾æ¥è½¬å­˜"""
        try:
            files = FastLinkProcessor.parse_share_link(share_link)
            if not files:
                logger.warning("æ— æ³•è§£æç§’ä¼ é“¾æ¥æˆ–é“¾æ¥ä¸­æ— æœ‰æ•ˆæ–‡ä»¶ä¿¡æ¯")
                self.send_auto_delete_message(update, context, "âŒ æ— æ³•è§£æç§’ä¼ é“¾æ¥")
                return
            
            self.send_auto_delete_message(update, context, f"âœ… è§£ææˆåŠŸï¼æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶ï¼Œå¼€å§‹è½¬å­˜...")
            results, filtered_count, elapsed_time, original_total_count, original_total_size = self.transfer_files(update, context, files)
            self.send_transfer_results(update, context, results, filtered_count, elapsed_time, original_total_count, original_total_size)
        except Exception as e:
            logger.error(f"å¤„ç†ç§’ä¼ é“¾æ¥å‡ºé”™: {e}")
            self.send_auto_delete_message(update, context, f"âŒ å¤„ç†ç§’ä¼ é“¾æ¥æ—¶å‡ºé”™: {e}")
    
    @admin_required
    def process_json_file(self, update: Update, context: CallbackContext, json_data):
        """å¤„ç†JSONæ–‡ä»¶è½¬å­˜"""
        try:
            if not isinstance(json_data, dict) or not json_data.get("files"):
                logger.warning("JSONæ ¼å¼æ— æ•ˆï¼Œç¼ºå°‘fileså­—æ®µ")
                self.send_auto_delete_message(update, context, "âŒ JSONæ ¼å¼æ— æ•ˆ")
                return
            
            common_path = json_data.get("commonPath", "").strip()
            if common_path.endswith('/'):
                common_path = common_path[:-1]
            
            files = []
            for file_info in json_data["files"]:
                file_path = file_info.get("path", "")
                if common_path:
                    file_path = f"{common_path}/{file_path}"
                if not is_allowed_file(file_path):
                    continue
                files.append({
                    "etag": file_info.get("etag", ""),
                    "size": int(file_info.get("size", 0)),
                    "file_name": file_path,
                    "is_v2_etag": json_data.get("usesBase62EtagsInExport", False)
                })
            
            self.send_auto_delete_message(update, context, f"âœ… è§£ææˆåŠŸï¼æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶ï¼Œå¼€å§‹è½¬å­˜...")
            results, filtered_count, elapsed_time, original_total_count, original_total_size = self.transfer_files(update, context, files)
            self.send_transfer_results(update, context, results, filtered_count, elapsed_time, original_total_count, original_total_size)
        except Exception as e:
            logger.error(f"å¤„ç†JSONæ–‡ä»¶å‡ºé”™: {e}")
            self.send_auto_delete_message(update, context, f"âŒ å¤„ç†JSONæ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    def transfer_files(self, update: Update, context: CallbackContext, files):
        """è½¬å­˜æ–‡ä»¶åˆ—è¡¨"""
        start_time = time.time()
        results = []
        original_total_count = len(files)
        original_total_size = sum(file_info["size"] for file_info in files)
        filtered_count = 0
        folder_cache = {}
        RATE_LIMIT = TRANSFER_RATE_LIMIT
        last_request_time = time.time()
        
        for i, file_info in enumerate(files):
            file_path = file_info["file_name"]
            file_size = file_info["size"]
            
            if not is_allowed_file(file_path):
                filtered_count += 1
                continue
                
            # æ¯å¤„ç†10ä¸ªæ–‡ä»¶æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
            if i % 10 == 0:
                self.send_auto_delete_message(
                    update, context, 
                    f"â³ æ­£åœ¨å¤„ç†æ–‡ä»¶ [{i+1}/{original_total_count}]\næ–‡ä»¶å: {os.path.basename(file_path)}",
                    delay=5
                )
                
            elapsed = time.time() - last_request_time
            required_delay = max(0, 1.0/RATE_LIMIT - elapsed)
            if required_delay > 0:
                time.sleep(required_delay)
            
            try:
                path_parts = file_path.split('/')
                file_name = path_parts.pop()
                parent_id = self.pan_client.default_save_dir_id
                
                current_path = ""
                for part in path_parts:
                    if not part:
                        continue
                    current_path = f"{current_path}/{part}" if current_path else part
                    cache_key = f"{parent_id}/{current_path}"
                    
                    if cache_key in folder_cache:
                        parent_id = folder_cache[cache_key]
                        continue
                    
                    time.sleep(0.3)
                    folder = self.pan_client.create_folder(parent_id, part)
                    if folder:
                        folder_id = folder["FileId"]
                        folder_cache[cache_key] = folder_id
                        parent_id = folder_id
                
                etag = file_info["etag"]
                if file_info.get("is_v2_etag", False):
                    etag = FastLinkProcessor.optimized_etag_to_hex(etag, True)
                
                last_request_time = time.time()
                result = self.pan_client.rapid_upload(etag, file_size, file_name, parent_id)
                
                if result:
                    results.append({
                        "success": True,
                        "file_name": file_path,
                        "size": file_size,
                        "file_id": result["FileId"]
                    })
                else:
                    results.append({
                        "success": False,
                        "file_name": file_path,
                        "size": file_size,
                        "error": "ç§’ä¼ å¤±è´¥"
                    })
                    time.sleep(1.5)
            except (requests.exceptions.ConnectionError, ConnectionResetError) as e:
                results.append({
                    "success": False,
                    "file_name": file_path,
                    "size": file_size,
                    "error": f"ç½‘ç»œé”™è¯¯: {e}"
                })
                time.sleep(3.0)
            except Exception as e:
                results.append({
                    "success": False,
                    "file_name": file_path,
                    "size": file_size,
                    "error": str(e)
                })
                time.sleep(2.0)
        
        elapsed_time = time.time() - start_time
        return results, filtered_count, elapsed_time, original_total_count, original_total_size
    
    def send_transfer_results(self, update: Update, context: CallbackContext, 
                             results, filtered_count, elapsed_time, 
                             original_total_count, original_total_size):
        """å‘é€è½¬å­˜ç»“æœ"""
        success_count = sum(1 for r in results if r["success"])
        failed_count = len(results) - success_count
        
        original_total_size_gb = original_total_size / (1024 ** 3)
        success_size = sum(r["size"] for r in results if r["success"])
        success_size_gb = success_size / (1024 ** 3)
        
        hours, remainder = divmod(elapsed_time, 3600)
        minutes, seconds = divmod(remainder, 60)
        time_str = f"{int(minutes)}åˆ†{int(seconds)}ç§’"
        if hours > 0:
            time_str = f"{int(hours)}å°æ—¶{time_str}"
        
        result_text = (
            f"ğŸ“Š è½¬å­˜å®Œæˆï¼\n"
            f"â”œ æ–‡ä»¶æ•°é‡: {original_total_count}\n"
            f"â”œ æ–‡ä»¶å¤§å°: {format_size(original_total_size)}\n"
            f"â”œ æˆåŠŸæ•°é‡: {success_count} (å¤§å°: {format_size(success_size)})\n"
            f"â”œ å¤±è´¥æ•°é‡: {failed_count}\n"
            f"â”œ ä¿å­˜ç›®å½•: {DEFAULT_SAVE_DIR or 'æ ¹ç›®å½•'}\n"
            f"â”” è€—æ—¶: {time_str}\n"
        )
        
        if failed_count > 0:
            failed_files = []
            for result in results:
                if not result["success"]:
                    file_name = result["file_name"]
                    failed_files.append(f"â€¢ {file_name}: {result['error']}")
            failed_text = "\n".join(failed_files[:10])
            result_text += f"\nâŒ å¤±è´¥æ–‡ä»¶:\n{failed_text}"
            if failed_count > 10:
                result_text += f"\n...åŠå…¶ä»– {failed_count - 10} ä¸ªå¤±è´¥æ–‡ä»¶"
        
        context.bot.send_message(chat_id=update.message.chat_id, text=result_text)
    
    @admin_required
    def sync_full_command(self, update: Update, context: CallbackContext):
        """å¤„ç†/sync_fullå‘½ä»¤"""
        keyboard = [[
            InlineKeyboardButton("âœ… ç¡®è®¤", callback_data='sync_full_confirm'),
            InlineKeyboardButton("âŒ å–æ¶ˆ", callback_data='sync_full_cancel')
        ]]
        reply_markup = InlineKeyboardMarkup(keyboard)
        message = update.message.reply_text(
            "âš ï¸ ç¡®è®¤è¦æ‰§è¡Œå…¨é‡åŒæ­¥å—ï¼Ÿ\nè¿™å°†æ›´æ–°æ•´ä¸ªåª’ä½“åº“çš„ç›®å½•ç¼“å­˜ï¼Œå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ã€‚",
            reply_markup=reply_markup
        )
        context.user_data['confirmation_message_id'] = message.message_id

    def button_callback(self, update: Update, context: CallbackContext):
        """å¤„ç†æŒ‰é’®å›è°ƒ"""
        query = update.callback_query
        query.answer()
        data = query.data
        
        if data.startswith("export_"):
            self.export_choice_callback(update, context)
        elif data.startswith("sync_full_"):
            chat_id = query.message.chat_id
            message_id = query.message.message_id
            try:
                context.bot.delete_message(chat_id=chat_id, message_id=message_id)
            except Exception:
                pass
            
            if data == 'sync_full_confirm':
                self.execute_full_sync(update, context)
            else:
                context.bot.send_message(chat_id=chat_id, text="âŒ å…¨é‡åŒæ­¥å·²å–æ¶ˆ")

    def execute_full_sync(self, update: Update, context: CallbackContext):
        """æ‰§è¡Œå…¨é‡åŒæ­¥"""
        chat_id = getattr(context, '_chat_id', None)
        self.send_auto_delete_message(update, context, "ğŸ”„ æ­£åœ¨æ‰§è¡Œå…¨é‡åŒæ­¥...", chat_id=chat_id)
        
        try:
            start_time = time.time()
            update_count = self.pan_client.full_sync_directory_cache()
            elapsed = time.time() - start_time
            self.send_auto_delete_message(
                update, context, 
                f"âœ… å…¨é‡åŒæ­¥å®Œæˆï¼\nâ”œ æ›´æ–°ç›®å½•: {update_count} ä¸ª\nâ”” è€—æ—¶: {elapsed:.2f}ç§’",
                chat_id=chat_id
            )
        except Exception as e:
            logger.error(f"å…¨é‡åŒæ­¥å¤±è´¥: {e}")
            self.send_auto_delete_message(update, context, "âŒ å…¨é‡åŒæ­¥å¤±è´¥", chat_id=chat_id)
            
        if hasattr(context, '_chat_id'):
            del context._chat_id

    @admin_required
    def clear_trash_command(self, update: Update, context: CallbackContext):
        """å¤„ç†/clear_trashå‘½ä»¤"""
        self.send_auto_delete_message(update, context, "ğŸ”„ æ­£åœ¨æ¸…ç©ºå›æ”¶ç«™...")
        try:
            if self.pan_client.clear_trash():
                self.send_auto_delete_message(update, context, "âœ… å›æ”¶ç«™å·²æˆåŠŸæ¸…ç©º", delay=5)
            else:
                self.send_auto_delete_message(update, context, "âŒ æ¸…ç©ºå›æ”¶ç«™å¤±è´¥", delay=5)
        except Exception as e:
            logger.error(f"æ¸…ç©ºå›æ”¶ç«™å‡ºé”™: {e}")
            self.send_auto_delete_message(update, context, "âŒ æ¸…ç©ºå›æ”¶ç«™æ—¶å‡ºé”™", delay=5)

    @admin_required
    def process_share_link(self, update: Update, context: CallbackContext, share_url):
        """å¤„ç†123äº‘ç›˜åˆ†äº«é“¾æ¥ï¼ˆä¿ç•™ç›®å½•ç»“æ„ï¼‰"""
        try:
            # åœ¨åå°çº¿ç¨‹ä¸­å¤„ç†è½¬å­˜
            def do_share_transfer():
                try:
                    start_time = time.time()
                    success, failure, results, total_size = self.pan_client.save_share_files(
                        share_url, 
                        self.pan_client.default_save_dir_id
                    )
                    elapsed = time.time() - start_time
                    
                    # æ„å»ºç»“æœæ¶ˆæ¯
                    message = (
                        f"ğŸ“¦ åˆ†äº«é“¾æ¥è½¬å­˜å®Œæˆï¼\n"
                        f"â”œ æˆåŠŸ: {success} æ–‡ä»¶\n"
                        f"â”œ å¤±è´¥: {failure} æ–‡ä»¶\n"
                        f"â”œ æ€»å¤§å°: {format_size(total_size)}\n"
                        f"â”œ ä¿å­˜åˆ°: {DEFAULT_SAVE_DIR}\n"
                        f"â”” è€—æ—¶: {elapsed:.1f}ç§’"
                    )
                    
                    context.bot.send_message(
                        chat_id=update.message.chat_id, 
                        text=message
                    )
                    
                    # å¦‚æœæœ‰å¤±è´¥ï¼Œå‘é€å¤±è´¥è¯¦æƒ…
                    if failure > 0:
                        failed_list = "\n".join(
                            [f"â€¢ {r['file_name']}: {r.get('error', 'æœªçŸ¥é”™è¯¯')}" 
                             for r in results if not r['success']][:5]
                        )
                        if failure > 5:
                            failed_list += f"\n...åŠå…¶ä»–{failure-5}ä¸ªæ–‡ä»¶"
                        
                        context.bot.send_message(
                            chat_id=update.message.chat_id,
                            text=f"âŒ å¤±è´¥æ–‡ä»¶:\n{failed_list}",
                            parse_mode="Markdown"
                        )
                    
                except Exception as e:
                    logger.error(f"å¤„ç†åˆ†äº«é“¾æ¥å‡ºé”™: {e}")
                    self.send_auto_delete_message(
                        update, context, 
                        f"âŒ å¤„ç†åˆ†äº«é“¾æ¥æ—¶å‡ºé”™: {e}",
                        chat_id=update.message.chat_id
                    )
            
            # å¯åŠ¨åå°çº¿ç¨‹å¤„ç†
            threading.Thread(target=do_share_transfer).start()
            self.send_auto_delete_message(
                update, context, 
                "â³ æ­£åœ¨åå°è½¬å­˜æ–‡ä»¶å¹¶ä¿ç•™ç›®å½•ç»“æ„ï¼Œè¯·ç¨å€™...\nå®Œæˆåä¼šé€šçŸ¥ç»“æœ",
                delay=5
            )
            
        except Exception as e:
            logger.error(f"å¤„ç†åˆ†äº«é“¾æ¥å‡ºé”™: {e}")
            self.send_auto_delete_message(update, context, f"âŒ å¤„ç†åˆ†äº«é“¾æ¥æ—¶å‡ºé”™: {e}")

    # ====================== 115è½¬å­˜åŠŸèƒ½ ======================
    @admin_required
    def extract_115_links(self, text: str) -> List[str]:
        """ä»æ–‡æœ¬ä¸­æå–115åˆ†äº«é“¾æ¥ï¼ˆæ”¹è¿›ç‰ˆï¼‰"""
        pattern = r'(https?://(?:115\.com|115cdn\.com)/s/[a-zA-Z0-9]+(?:\?password=[a-zA-Z0-9]+)?)'
        return re.findall(pattern, text)

    @admin_required
    def handle_text(self, update: Update, context: CallbackContext):
        """å¤„ç†æ–‡æœ¬æ¶ˆæ¯ - ä»…ä¿ç•™ç§’ä¼ é“¾æ¥å¤„ç†"""
        text = update.message.text.strip()
        
        # ç§’ä¼ é“¾æ¥å¤„ç†
        if (text.startswith(LEGACY_FOLDER_LINK_PREFIX_V1) or 
            text.startswith(LEGACY_FOLDER_LINK_PREFIX_V2) or 
            text.startswith(COMMON_PATH_LINK_PREFIX_V1) or 
            text.startswith(COMMON_PATH_LINK_PREFIX_V2) or
            ('#' in text and '$' in text)):
            self.send_auto_delete_message(update, context, "ğŸ” æ£€æµ‹åˆ°ç§’ä¼ é“¾æ¥ï¼Œå¼€å§‹è§£æ...")
            self.process_fast_link(update, context, text)
        # 123äº‘ç›˜åˆ†äº«é“¾æ¥å¤„ç†
        elif re.search(r'https?://(?:[a-zA-Z0-9-]+\.)*123[a-zA-Z0-9-]*\.[a-z]{2,6}/s/[a-zA-Z0-9\-_]+', text):
            self.send_auto_delete_message(update, context, "ğŸ”— æ£€æµ‹åˆ°123äº‘ç›˜åˆ†äº«é“¾æ¥ï¼Œå¼€å§‹è§£æ...")
            self.process_share_link(update, context, text)

        # 115åˆ†äº«é“¾æ¥å¤„ç†
        share_links = self.extract_115_links(text)
        if share_links:
            for share_url in share_links:
                # åœ¨åå°çº¿ç¨‹ä¸­å¤„ç†è½¬å­˜ä»»åŠ¡
                thread = threading.Thread(
                    target=self.process_115_share_link,
                    args=(update, context, share_url),
                    daemon=True
                )
                thread.start()
                self.active_tasks[share_url] = thread
                self.send_auto_delete_message(update, context, "ğŸ”— æ£€æµ‹åˆ°115åˆ†äº«é“¾æ¥ï¼Œå¼€å§‹å¤„ç†: {share_url}")
            return
        
    @admin_required
    def migrate_command(self, update: Update, context: CallbackContext):
        """å¤„ç†/migrateå‘½ä»¤"""
        user_id = update.effective_user.id
        chat_id = update.message.chat_id
        
        # æ£€æŸ¥ç”¨æˆ·æƒé™
        if user_id not in self.allowed_user_ids:
            self.send_auto_delete_message(update, context, "âŒ æŠ±æ­‰ï¼Œæ‚¨æ²¡æœ‰ä½¿ç”¨æ­¤å‘½ä»¤çš„æƒé™")
            return
        
        # è·å–ç”¨æˆ·è¾“å…¥çš„è‡ªå®šä¹‰è·¯å¾„
        custom_path = " ".join(context.args).strip() if context.args else TARGET_PATH_115
        
        # éªŒè¯è·¯å¾„
        if not custom_path or len(custom_path) > 100:
            self.send_auto_delete_message(update, context, "âŒ è·¯å¾„æ— æ•ˆï¼šè·¯å¾„ä¸èƒ½ä¸ºç©ºä¸”é•¿åº¦ä¸èƒ½è¶…è¿‡100å­—ç¬¦")
            return
        
        self.send_auto_delete_message(update, context, "ğŸ”„ æ”¶åˆ°è¿ç§»å‘½ä»¤ï¼Œç›®æ ‡è·¯å¾„: {custom_path}\nå¼€å§‹å¤„ç†...")
        
        # åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œè¿ç§»
        thread = threading.Thread(
            target=self.process_manual_migration,
            args=(update, context, custom_path),
            daemon=True
        )
        thread.start()
        self.active_tasks[f"manual_migration_{custom_path}"] = thread
    
    def format_stats_message(self, stats: Dict) -> str:
        """æ ¼å¼åŒ–ç»Ÿè®¡ä¿¡æ¯ä¸ºæ¶ˆæ¯"""
        elapsed = stats["end_time"] - stats["start_time"]
        hours, rem = divmod(elapsed, 3600)
        minutes, seconds = divmod(rem, 60)
        time_str = f"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d}"
        
        message = (
            "ğŸ“Š è¿ç§»ç»Ÿè®¡æŠ¥å‘Š\n"
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n"
            f"ğŸ“‚ æ‰«ææ–‡ä»¶æ€»æ•°: {stats['total_files']}\n"
            f"ğŸš« è¿‡æ»¤æ–‡ä»¶æ•°: {stats['filtered_files']} (å¤§å°: {PanTransfer.format_size(stats['filtered_size'])})\n"
            f"ğŸ“¤ æäº¤è¿ç§»æ–‡ä»¶æ•°: {stats['submitted_files']} (å¤§å°: {PanTransfer.format_size(stats['submitted_size'])})\n"
            f"âœ… æˆåŠŸè¿ç§»æ–‡ä»¶æ•°: {stats['success_files']}\n"
            f"âŒ è¿ç§»å¤±è´¥æ–‡ä»¶æ•°: {stats['failed_files']}\n"
            f"â±ï¸ æ€»è€—æ—¶: {time_str}\n"
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        )
        
        return message
    
    def process_manual_migration(self, update: Update, context: CallbackContext, custom_path: str) -> None:
        """æ‰§è¡Œæ‰‹åŠ¨è¿ç§»æµç¨‹"""
        bot = self.updater.bot
        chat_id = update.message.chat_id
        
        try:
            # ç¬¬ä¸€æ­¥ï¼šè·å–115ç›®å½•ID
            msg = bot.send_message(
                chat_id=chat_id,
                text=f"ğŸ” ç¬¬ä¸€æ­¥ï¼šè·å–115ç½‘ç›˜ç›®å½•ID...\nè·¯å¾„: {custom_path}"
            )
            self.auto_delete_message(context, chat_id, msg.message_id, 5)
        
            
            pan_transfer = PanTransfer(pan_client=self.pan_client, cookies=COOKIES_115)
            source_dir_id = pan_transfer.get_115_directory_id_by_path(custom_path)
            msg = bot.send_message(
                chat_id=chat_id,
                text=f"âœ… 115ç½‘ç›˜ç›®å½•ID: {source_dir_id}\n"
                     f"è·¯å¾„: {custom_path}"
            )
            self.auto_delete_message(context, chat_id, msg.message_id, 5)
            
            # ç¬¬äºŒæ­¥ï¼šè·å–123ç›®æ ‡ç›®å½•ID
            msg = bot.send_message(
                chat_id=chat_id,
                text="ğŸ” ç¬¬äºŒæ­¥ï¼šè·å–123äº‘ç›˜ç›®å½•ID..."
            )
            self.auto_delete_message(context, chat_id, msg.message_id, 5)
            target_dir_id_123 = self.pan_client.get_or_create_directory(DEFAULT_SAVE_DIR)
            msg = bot.send_message(
                chat_id=chat_id,
                text=f"âœ… 123äº‘ç›˜ç›®å½•ID: {target_dir_id_123}\n"
                     f"è·¯å¾„: {DEFAULT_SAVE_DIR}"
            )
            self.auto_delete_message(context, chat_id, msg.message_id, 5)
            # ç¬¬ä¸‰æ­¥ï¼šæ‰§è¡Œè¿ç§»
            msg = bot.send_message(
                chat_id=chat_id,
                text="ğŸš€ ç¬¬ä¸‰æ­¥ï¼šå¼€å§‹è¿ç§»æ–‡ä»¶..."
            )
            self.auto_delete_message(context, chat_id, msg.message_id, 5)
            stats = pan_transfer.transfer_files(
                source_dir_id=source_dir_id,
                target_dir_id_123=target_dir_id_123
            )
            
            # å‘é€ç»Ÿè®¡ä¿¡æ¯
            stats_message = self.format_stats_message(stats)
            bot.send_message(chat_id=chat_id, text=stats_message)
            
            # ç¬¬å››æ­¥ï¼šæ¸…ç†æºæ–‡ä»¶
            if DELETE_AFTER_TRANSFER and stats["failed_files"] == 0:
                msg = bot.send_message(
                    chat_id=chat_id,
                    text="ğŸ§¹ æ¸…ç†115ç½‘ç›˜æºæ–‡ä»¶..."
                )
                self.auto_delete_message(context, chat_id, msg.message_id, 5)
                pan_transfer.delete_115_directory(source_dir_id)
                msg = bot.send_message(chat_id=chat_id, text="âœ… æºæ–‡ä»¶å·²æˆåŠŸåˆ é™¤")
                self.auto_delete_message(context, chat_id, msg.message_id, 5)
            elif DELETE_AFTER_TRANSFER and stats["failed_files"] > 0:
                msg = bot.send_message(
                    chat_id=chat_id,
                    text=f"âš ï¸ ç”±äºå­˜åœ¨ {stats['failed_files']} ä¸ªè¿ç§»å¤±è´¥çš„æ–‡ä»¶ï¼Œå·²è·³è¿‡åˆ é™¤115æºæ–‡ä»¶"
                )
                self.auto_delete_message(context, chat_id, msg.message_id, 5)
            else:
                msg = bot.send_message(
                    chat_id=chat_id,
                    text="â„¹ï¸ å·²è·³è¿‡åˆ é™¤115æºæ–‡ä»¶ï¼ˆé…ç½®é€‰é¡¹ï¼‰"
                )
                self.auto_delete_message(context, chat_id, msg.message_id, 5)
            
        except Exception as e:
            self.send_auto_delete_message(update, context, "âŒ æ‰‹åŠ¨è¿ç§»è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
            traceback.print_exc()
        
        finally:
            # æ¸…ç†ä»»åŠ¡
            task_key = f"manual_migration_{custom_path}"
            if task_key in self.active_tasks:
                del self.active_tasks[task_key]
    
    def process_115_share_link(self, update: Update, context: CallbackContext, share_url: str) -> None:
        """å¤„ç†å•ä¸ª115åˆ†äº«é“¾æ¥çš„è½¬å­˜å’Œè¿ç§»"""
        bot = self.updater.bot
        chat_id = update.message.chat_id
        
        try:
            if not self.share_transfer:
                self.send_auto_delete_message(update, context, "âŒ 115åŠŸèƒ½æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥é…ç½®")
                return
            
            # ç¬¬ä¸€æ­¥ï¼šè½¬å­˜åˆ†äº«é“¾æ¥åˆ°115ç½‘ç›˜
            msg = bot.send_message(
                chat_id=chat_id,
                text=f"ğŸ”— ç¬¬ä¸€æ­¥ï¼šè½¬å­˜åˆ†äº«é“¾æ¥åˆ°115ç½‘ç›˜...\né“¾æ¥: {share_url}"
            )
            self.auto_delete_message(context, chat_id, msg.message_id, 5)
           
            target_dir_id = self.share_transfer.transfer_share(
                share_url=share_url,
                receive_code=None,
                target_path=TARGET_PATH_115
            )
            
            msg = bot.send_message(
                chat_id=chat_id,
                text=f"âœ… è½¬å­˜æˆåŠŸ! ç›®æ ‡ç›®å½•ID: {target_dir_id}\n"
                     f"â³ ç­‰å¾…5ç§’ç¡®ä¿è½¬å­˜å®Œæˆ..."
            )
            self.auto_delete_message(context, chat_id, msg.message_id, 5)
            time.sleep(5)
            
            # ç¬¬äºŒæ­¥ï¼šè¿ç§»åˆ°123äº‘ç›˜
            msg = bot.send_message(
                chat_id=chat_id,
                text="ğŸŒ ç¬¬äºŒæ­¥ï¼šè¿ç§»åˆ°123äº‘ç›˜..."
            )
            self.auto_delete_message(context, chat_id, msg.message_id, 5)
            
            pan_transfer = PanTransfer(pan_client=self.pan_client, cookies=COOKIES_115)
            # è·å–æˆ–åˆ›å»º123ç›®æ ‡ç›®å½•
            target_dir_id_123 = self.pan_client.get_or_create_directory(DEFAULT_SAVE_DIR)
            msg = bot.send_message(
                chat_id=chat_id,
                text=f"âœ… 123äº‘ç›˜ç›®æ ‡ç›®å½•ID: {target_dir_id_123}"
            )
            self.auto_delete_message(context, chat_id, msg.message_id, 5)
            
            stats = pan_transfer.transfer_files(
                source_dir_id=target_dir_id,
                target_dir_id_123=target_dir_id_123
            )
            
            # å‘é€ç»Ÿè®¡ä¿¡æ¯
            stats_message = self.format_stats_message(stats)
            bot.send_message(chat_id=chat_id, text=stats_message)
            
            # ç¬¬ä¸‰æ­¥ï¼šæ¸…ç†æºæ–‡ä»¶
            if DELETE_AFTER_TRANSFER and stats["failed_files"] == 0:
                msg = bot.send_message(
                    chat_id=chat_id,
                    text="ğŸ§¹ æ¸…ç†115ç½‘ç›˜æºæ–‡ä»¶..."
                )
                self.auto_delete_message(context, chat_id, msg.message_id, 5)
                pan_transfer.delete_115_directory(target_dir_id)
                msg = bot.send_message(
                    chat_id=chat_id,
                    text="âœ… æºæ–‡ä»¶å·²æˆåŠŸåˆ é™¤"
                )
                self.auto_delete_message(context, chat_id, msg.message_id, 5)
            elif DELETE_AFTER_TRANSFER and stats["failed_files"] > 0:
                msg = bot.send_message(
                    chat_id=chat_id,
                    text=f"âš ï¸ ç”±äºå­˜åœ¨ {stats['failed_files']} ä¸ªè¿ç§»å¤±è´¥çš„æ–‡ä»¶ï¼Œå·²è·³è¿‡åˆ é™¤115æºæ–‡ä»¶"
                )
                self.auto_delete_message(context, chat_id, msg.message_id, 5)
            else:
                msg = bot.send_message(
                    chat_id=chat_id,
                    text="â„¹ï¸ å·²è·³è¿‡åˆ é™¤115æºæ–‡ä»¶ï¼ˆé…ç½®é€‰é¡¹ï¼‰"
                )
                self.auto_delete_message(context, chat_id, msg.message_id, 5)
            
        except Exception as e:
            self.send_auto_delete_message(update, context, "âŒ æ‰‹åŠ¨è¿ç§»è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
            traceback.print_exc()
        
        finally:
            # æ¸…ç†ä»»åŠ¡
            if share_url in self.active_tasks:
                del self.active_tasks[share_url]
    # ====================== END 115è½¬å­˜åŠŸèƒ½ ======================
    
    @admin_required
    def add_command(self, update: Update, context: CallbackContext):
        """å¤„ç†/addå‘½ä»¤"""
        args = context.args
        reply_to = update.message.reply_to_message
        chat_id = update.message.chat_id
        message_id = update.message.message_id

        # æƒ…å†µ1ï¼šå›å¤æ¶ˆæ¯æ¨¡å¼
        if reply_to:
            try:
                # è·å–è¢«å›å¤ç”¨æˆ·çš„ä¿¡æ¯
                target_user = reply_to.from_user
                # ç¡®å®šæƒé™çº§åˆ«
                privilege_level = "user"
                if args and args[0].lower() == "svip":
                    privilege_level = "svip"
                # æ·»åŠ ç”¨æˆ·åˆ°æ•°æ®åº“
                with closing(sqlite3.connect(DB_PATH)) as conn:
                    c = conn.cursor()
                    c.execute('''INSERT OR REPLACE INTO user_privileges 
                              (user_id, privilege_level) 
                              VALUES (?, ?)''', 
                              (target_user.id, privilege_level))
                    conn.commit()

                # æ„å»ºå“åº”æ¶ˆæ¯
                name = target_user.first_name or target_user.username or str(target_user.id)
                response = (
                    f"âœ… å·²æ·»åŠ ç”¨æˆ·: {name}\n"
                    f"â”œ ID: `{target_user.id}`\n"
                    f"â”” æƒé™: {privilege_level}"
                )
                # å‘é€å›å¤æ¶ˆæ¯å¹¶å®‰æ’è‡ªåŠ¨åˆ é™¤
                msg = update.message.reply_text(response, parse_mode="Markdown")
                self.auto_delete_message(context, chat_id, msg.message_id, 5)
                # åˆ é™¤ç®¡ç†å‘˜å‘é€çš„å‘½ä»¤æ¶ˆæ¯
                try:
                    context.bot.delete_message(chat_id=chat_id, message_id=message_id)
                except Exception as e:
                    logger.warning(f"æ— æ³•åˆ é™¤å‘½ä»¤æ¶ˆæ¯: {e}")
                return
            except Exception as e:
                logger.error(f"é€šè¿‡å›å¤æ·»åŠ ç”¨æˆ·å¤±è´¥: {e}")
                msg = update.message.reply_text(f"âŒ æ·»åŠ å¤±è´¥: {e}")
                self.auto_delete_message(context, chat_id, msg.message_id, 5)
                return
            
        # æƒ…å†µ2ï¼šä¼ ç»Ÿå‚æ•°æ¨¡å¼
        if not args or len(args) < 1:
            usage = (
                "âŒ ç”¨æ³•:\n"
                "1. å›å¤ç”¨æˆ·æ¶ˆæ¯: `/add [svip]`\n"
                "2. ç›´æ¥æ·»åŠ : `/add [svip] <ç”¨æˆ·ID>`"
            )
            msg = update.message.reply_text(usage, parse_mode="Markdown")
            self.auto_delete_message(context, chat_id, msg.message_id, 5)
            return
        
        try:
            # æ£€æŸ¥æ˜¯å¦æŒ‡å®šäº†æƒé™çº§åˆ«
            if args[0].lower() == "svip":
                if len(args) < 2:
                    update.message.reply_text("âŒ è¯·æä¾›ç”¨æˆ·ID")
                    self.auto_delete_message(context, chat_id, msg.message_id, 5)
                    return
                user_id = int(args[1])
                privilege_level = "svip"
            else:
                user_id = int(args[0])
                privilege_level = "user"
            
            # æ·»åŠ ç”¨æˆ·åˆ°æ•°æ®åº“
            with closing(sqlite3.connect(DB_PATH)) as conn:
                c = conn.cursor()
                c.execute('''INSERT OR REPLACE INTO user_privileges 
                            (user_id, privilege_level) 
                            VALUES (?, ?)''', 
                          (user_id, privilege_level))
                conn.commit()
            response = (
                f"âœ… å·²æ·»åŠ ç”¨æˆ·\n"
                f"â”œ ID: `{user_id}`\n"
                f"â”” æƒé™: {privilege_level}"
            )
            # å‘é€å›å¤æ¶ˆæ¯å¹¶å®‰æ’è‡ªåŠ¨åˆ é™¤
            msg = update.message.reply_text(response, parse_mode="Markdown")
            self.auto_delete_message(context, chat_id, msg.message_id, 5)
            # åˆ é™¤ç®¡ç†å‘˜å‘é€çš„å‘½ä»¤æ¶ˆæ¯
            try:
                context.bot.delete_message(chat_id=chat_id, message_id=message_id)
            except Exception as e:
                logger.warning(f"æ— æ³•åˆ é™¤å‘½ä»¤æ¶ˆæ¯: {e}")
              
        except (ValueError, IndexError):
            msg = update.message.reply_text("âŒ æ— æ•ˆçš„ç”¨æˆ·IDæ ¼å¼")
            self.auto_delete_message(context, chat_id, msg.message_id, 5)
        except Exception as e:
            logger.error(f"æ·»åŠ ç”¨æˆ·å¤±è´¥: {e}")
            msg = update.message.reply_text(f"âŒ æ·»åŠ å¤±è´¥: {e}")
            self.auto_delete_message(context, chat_id, msg.message_id, 5)
    
    @admin_required
    def delete_command(self, update: Update, context: CallbackContext):
        """å¤„ç†/deleteå‘½ä»¤"""
        args = context.args
        reply_to = update.message.reply_to_message
        chat_id = update.message.chat_id
        message_id = update.message.message_id

        # æƒ…å†µ1ï¼šå›å¤æ¶ˆæ¯æ¨¡å¼
        if reply_to:
            try:
                # è·å–è¢«å›å¤ç”¨æˆ·çš„ä¿¡æ¯
                target_user = reply_to.from_user
                # åˆ é™¤ç”¨æˆ·
                with closing(sqlite3.connect(DB_PATH)) as conn:
                    c = conn.cursor()
                    c.execute("DELETE FROM user_privileges WHERE user_id = ?", (target_user.id,))
                    conn.commit()
                    if c.rowcount > 0:
                        # æ„å»ºå“åº”æ¶ˆæ¯
                        name = target_user.first_name or target_user.username or str(target_user.id)
                        response = (
                            f"âœ… å·²åˆ é™¤ç”¨æˆ·: {name}\n"
                            f"â”” ID: `{target_user.id}`"
                        )
                        # å‘é€å›å¤æ¶ˆæ¯å¹¶å®‰æ’è‡ªåŠ¨åˆ é™¤
                        msg = update.message.reply_text(response, parse_mode="Markdown")
                        self.auto_delete_message(context, chat_id, msg.message_id, 5)
                        # åˆ é™¤ç®¡ç†å‘˜å‘é€çš„å‘½ä»¤æ¶ˆæ¯
                        try:
                            context.bot.delete_message(chat_id=chat_id, message_id=message_id)
                        except Exception as e:
                            logger.warning(f"æ— æ³•åˆ é™¤å‘½ä»¤æ¶ˆæ¯: {e}")
                    else:
                        msg = update.message.reply_text(f"âŒ ç”¨æˆ·ä¸å­˜åœ¨: {target_user.id}")
                        self.auto_delete_message(context, chat_id, msg.message_id, 5)
                return
            except Exception as e:
                logger.error(f"é€šè¿‡å›å¤åˆ é™¤ç”¨æˆ·å¤±è´¥: {e}")
                msg = update.message.reply_text(f"âŒ åˆ é™¤å¤±è´¥: {e}")
                self.auto_delete_message(context, chat_id, msg.message_id, 5)
                return
            
        # æƒ…å†µ2ï¼šä¼ ç»Ÿå‚æ•°æ¨¡å¼
        if not args or len(args) < 1:
            usage = (
                "âŒ ç”¨æ³•:\n"
                "1. å›å¤ç”¨æˆ·æ¶ˆæ¯: `/delete`\n"
                "2. ç›´æ¥åˆ é™¤: `/delete <ç”¨æˆ·ID>`"
            )
            msg = update.message.reply_text(usage, parse_mode="Markdown")
            self.auto_delete_message(context, chat_id, msg.message_id, 5)
            return       
        try:
            user_id = int(args[0])
            
            # ä»æ•°æ®åº“åˆ é™¤ç”¨æˆ·
            with closing(sqlite3.connect(DB_PATH)) as conn:
                c = conn.cursor()
                c.execute("DELETE FROM user_privileges WHERE user_id = ?", (user_id,))
                conn.commit()
                
                if c.rowcount > 0:
                    response = (
                        f"âœ… å·²åˆ é™¤ç”¨æˆ·\n"
                        f"â”” ID: `{user_id}`"
                    )
                    # å‘é€å›å¤æ¶ˆæ¯å¹¶å®‰æ’è‡ªåŠ¨åˆ é™¤
                    msg = update.message.reply_text(response, parse_mode="Markdown")
                    self.auto_delete_message(context, chat_id, msg.message_id, 5)
                    # åˆ é™¤ç®¡ç†å‘˜å‘é€çš„å‘½ä»¤æ¶ˆæ¯
                    try:
                        context.bot.delete_message(chat_id=chat_id, message_id=message_id)
                    except Exception as e:
                        logger.warning(f"æ— æ³•åˆ é™¤å‘½ä»¤æ¶ˆæ¯: {e}")
                else:
                    msg = update.message.reply_text(f"âŒ ç”¨æˆ·ä¸å­˜åœ¨: {user_id}")
                    self.auto_delete_message(context, chat_id, msg.message_id, 5)

        except ValueError:
            msg = update.message.reply_text("âŒ æ— æ•ˆçš„ç”¨æˆ·IDæ ¼å¼")
            self.auto_delete_message(context, chat_id, msg.message_id, 5)
        except Exception as e:
            logger.error(f"åˆ é™¤ç”¨æˆ·å¤±è´¥: {e}")
            msg = update.message.reply_text(f"âŒ åˆ é™¤å¤±è´¥: {e}")
            self.auto_delete_message(context, chat_id, msg.message_id, 5)
    
    def info_command(self, update: Update, context: CallbackContext):
        """å¤„ç†/infoå‘½ä»¤ - ä¼˜åŒ–ç‰ˆç”¨æˆ·ä¿¡æ¯"""
        user = update.message.from_user
        user_id = user.id
        chat_id = update.message.chat_id
        chat_type = update.message.chat.type

        # åœ¨ç¾¤èŠä¸­åˆ é™¤ç”¨æˆ·å‘é€çš„/infoæ¶ˆæ¯
        if chat_type in ['group', 'supergroup']:
            try:
                context.bot.delete_message(chat_id=chat_id, message_id=update.message.message_id)
            except Exception:
                pass

        # è·å–ç”¨æˆ·æƒé™ä¿¡æ¯
        user_info = self.get_user_privilege(user_id)
        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å·²æ³¨å†Œ
        if user_id not in self.allowed_user_ids and not user_info:
            message = "âŒ æ‚¨å°šæœªæ³¨å†Œï¼Œæ— æ³•ä½¿ç”¨æ­¤åŠŸèƒ½\nè¯·è”ç³»ç®¡ç†å‘˜æ·»åŠ æ‚¨çš„è´¦æˆ·"
            self.send_auto_delete_message(update, context, message, delay=5)
            return
        
        username = f"@{user.username}" if user.username else "æœªè®¾ç½®"
        first_name = user.first_name or ""
        last_name = user.last_name or ""
        full_name = f"{first_name} {last_name}".strip()          
        
        # è·å–å¯¼å‡ºå†å²
        try:
            with closing(sqlite3.connect(DB_PATH)) as conn:
                conn.row_factory = sqlite3.Row
                c = conn.cursor()
                # ä»Šæ—¥å¯¼å‡ºæ¬¡æ•°
                today = datetime.now().strftime("%Y-%m-%d")
                c.execute("SELECT SUM(folder_count) FROM export_history WHERE user_id = ? AND DATE(export_date) = ?", 
                          (user_id, today))
                today_export = c.fetchone()[0] or 0
                
                # æ€»å¯¼å‡ºæ¬¡æ•°
                c.execute("SELECT SUM(folder_count) FROM export_history WHERE user_id = ?", (user_id,))
                total_export = c.fetchone()[0] or 0
                
                # æœ€åå¯¼å‡ºæ—¶é—´
                c.execute("SELECT MAX(export_date) FROM export_history WHERE user_id = ?", (user_id,))
                last_export = c.fetchone()[0]

                if user_info:
                    join_date = user_info.get("join_date")
                else:
                    c.execute("SELECT MIN(export_date) FROM export_history WHERE user_id = ?", (user_id,))
                    join_date_row = c.fetchone()
                    join_date = join_date_row[0] if join_date_row[0] else None                     
        except Exception as e:
            logger.error(f"æŸ¥è¯¢å¯¼å‡ºå†å²å¤±è´¥: {e}")
            today_export = 0
            total_export = 0
            last_export = None
            join_date = None

        # è®¡ç®—ä¸‹æ¬¡é‡ç½®æ—¶é—´ï¼ˆUTCæ—¶é—´æ¬¡æ—¥0ç‚¹ï¼‰
        now_utc = datetime.now(timezone.utc)
        reset_time = datetime(
            now_utc.year, 
            now_utc.month, 
            now_utc.day,
            tzinfo=timezone.utc
        ) + timedelta(days=1)

        def format_time(dt):
            if not dt:
                return "ä»æœªå¯¼å‡º"
            if isinstance(dt, str):
                dt = datetime.fromisoformat(dt)
            return dt.strftime("%Y-%m-%d %H:%M:%S UTC")
        
        # ç¡®å®šç”¨æˆ·çŠ¶æ€
        if user_id in self.allowed_user_ids:
            status = "ğŸ‘‘ ç®¡ç†å‘˜"
            status_desc = "æ‹¥æœ‰æ‰€æœ‰æƒé™"
            export_limit = "æ— é™åˆ¶"
            remaining = "æ— é™åˆ¶"
        elif user_info and user_info.get("privilege_level") == "svip":
            status = "ğŸŒŸ SVIPç”¨æˆ·"
            status_desc = "é«˜çº§ç‰¹æƒç”¨æˆ·"
            export_limit = "æ— é™åˆ¶"
            remaining = "æ— é™åˆ¶"
        else:
            status = "ğŸ‘¤ æ™®é€šç”¨æˆ·"
            status_desc = "åŸºç¡€æƒé™ç”¨æˆ·"
            remaining = max(0, DAILY_EXPORT_LIMIT - today_export)
            export_limit = f"{DAILY_EXPORT_LIMIT} ä¸ª/å¤© (å‰©ä½™: {remaining})"

        # æ„å»ºç”¨æˆ·ä¿¡æ¯æ¶ˆæ¯
        message_parts = [
            f"<b>ğŸ‘¤ ç”¨æˆ·ä¿¡æ¯</b>",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•",
            f"<b>â”œ ç”¨æˆ·ID:</b> <code>{user_id}</code>",
            f"<b>â”œ ç”¨æˆ·å:</b> {username}",
        ]

        if full_name:
            message_parts.append(f"<b>â”œ æ˜¾ç¤ºåç§°:</b> {full_name}")

        message_parts.extend([
            f"<b>â”œ çŠ¶æ€:</b> {status}",
            f"<b>â”œ çŠ¶æ€æè¿°:</b> {status_desc}",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•",
            f"<b>â”œ å¯¼å‡ºæƒé™:</b>",
            f"   â”œ ä»Šæ—¥å¯¼å‡º: <b>{today_export}</b> ä¸ªJSONæ–‡ä»¶",
            f"   â”œ å‰©ä½™æ¬¡æ•°: <b>{remaining}</b>",
            f"   â”œ æ€»å¯¼å‡ºæ¬¡æ•°: <b>{total_export}</b>",
            f"   â”œ æƒé™é™åˆ¶: {export_limit}",
            f"   â”œ æœ€åå¯¼å‡ºæ—¶é—´: {format_time(last_export)}",
            f"   â”” ä¸‹æ¬¡é‡ç½®: {reset_time.strftime('%Y-%m-%d %H:%M:%S UTC')}",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•",
        ])
        if join_date:
            message_parts.append(f"<b>â”” åŠ å…¥æ—¶é—´:</b> {format_time(join_date)}")
        else:
            message_parts.append(f"<b>â”” åŠ å…¥æ—¶é—´:</b> æœªçŸ¥")

        # æ·»åŠ æç¤ºä¿¡æ¯
        if status == "ğŸ‘¤ æ™®é€šç”¨æˆ·":
            if today_export >= DAILY_EXPORT_LIMIT:
                message_parts.append(f"\nâš ï¸ <i>æ‚¨çš„ä»Šæ—¥å¯¼å‡ºæ¬¡æ•°å·²è¾¾ä¸Šé™({DAILY_EXPORT_LIMIT}æ¬¡)ï¼Œè¯·æ˜å¤©å†è¯•</i>")
            else:
                message_parts.append(f"\nâ„¹ï¸ <i>ä½œä¸ºæ™®é€šç”¨æˆ·ï¼Œæ‚¨æ¯å¤©å¯å¯¼å‡ºæœ€å¤š {DAILY_EXPORT_LIMIT} ä¸ªJSONæ–‡ä»¶</i>")
            message_parts.append("\nğŸ’ <i>è”ç³»ç®¡ç†å‘˜å‡çº§SVIPå¯äº«å—æ— é™åˆ¶å¯¼å‡ºæƒé™</i>")

        # ç»„åˆæ‰€æœ‰æ¶ˆæ¯éƒ¨åˆ†
        message = "\n".join(message_parts)
        self.send_auto_delete_message(update, context, message, delay=10, parse_mode="HTML")

    @admin_required
    def refresh_token_command(self, update: Update, context: CallbackContext):
        """å¤„ç†/refresh_tokenå‘½ä»¤ - å¼ºåˆ¶åˆ·æ–°Token"""
        try:
            # å¼ºåˆ¶è·å–æ–°Token
            if self.pan_client.token_manager.get_new_token():
                # è·å–æ–°çš„Tokenä¿¡æ¯
                new_token = self.pan_client.token_manager.access_token
                new_expiry = self.pan_client.token_manager.token_expiry
                
                # æ„å»ºå“åº”æ¶ˆæ¯
                message = (
                    "âœ… Token å¼ºåˆ¶åˆ·æ–°æˆåŠŸï¼\n"
                    f"â”œ æ–°Token: `{new_token[:12]}...{new_token[-12:]}`\n"
                    f"â”” æœ‰æ•ˆæœŸè‡³: {new_expiry.strftime('%Y-%m-%d %H:%M:%S UTC')}"
                )
            else:
                message = "âŒ Token åˆ·æ–°å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—"
                
            update.message.reply_text(message, parse_mode="Markdown")
            
            # åˆ é™¤ç”¨æˆ·æ¶ˆæ¯ï¼ˆå¦‚æœæ˜¯ç¾¤èŠï¼‰
            if update.message.chat.type in ['group', 'supergroup']:
                try:
                    context.bot.delete_message(
                        chat_id=update.message.chat_id,
                        message_id=update.message.message_id
                    )
                except Exception:
                    pass
                    
        except Exception as e:
            logger.error(f"åˆ·æ–°Tokenå¤±è´¥: {e}")
            self.send_auto_delete_message(update, context, f"âŒ åˆ·æ–°Tokenå¤±è´¥: {e}")

def main():
    # æ·»åŠ æˆæƒä¿¡æ¯æç¤º
    logger.info("=============================================")
    logger.info("123äº‘ç›˜æœºå™¨äºº - ä¸“ä¸šç‰ˆ")
    logger.info(f"ç‰ˆæœ¬: {VERSION}")
    logger.info("æˆæƒéªŒè¯é€šè¿‡ï¼Œæ­£åœ¨å¯åŠ¨æœåŠ¡...")
    logger.info("=============================================")
    # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
    BOT_TOKEN = os.getenv("TG_BOT_TOKEN","")
    CLIENT_ID = os.getenv("PAN_CLIENT_ID","")
    CLIENT_SECRET = os.getenv("PAN_CLIENT_SECRET","")
    ADMIN_USER_IDS = [int(id.strip()) for id in os.getenv("TG_ADMIN_USER_IDS", "").split(",") if id.strip()]
    
    if not BOT_TOKEN:
        logger.error("âŒ ç¯å¢ƒå˜é‡ TG_BOT_TOKEN æœªè®¾ç½®")
        return
    
    if not CLIENT_ID:
        logger.error("âŒ ç¯å¢ƒå˜é‡ PAN_CLIENT_ID æœªè®¾ç½®")
        return
    
    if not CLIENT_SECRET:
        logger.error("âŒ ç¯å¢ƒå˜é‡ PAN_CLIENT_SECRET æœªè®¾ç½®")
        return

    # ========== æ·»åŠ æ–¹æ¡ˆå››ï¼šç¦ç”¨ SSL éªŒè¯ ==========
    try:
        import ssl
        # ç¦ç”¨ SSL éªŒè¯ï¼ˆè§£å†³ UNEXPECTED_EOF_WHILE_READING é”™è¯¯ï¼‰
        ssl._create_default_https_context = ssl._create_unverified_context
        #logger.warning("âš ï¸ å·²å…¨å±€ç¦ç”¨ SSL è¯ä¹¦éªŒè¯ï¼ˆæ³¨æ„å®‰å…¨é£é™©ï¼‰")
    except Exception as e:
        logger.error(f"ç¦ç”¨ SSL éªŒè¯å¤±è´¥: {e}")
    # ========== ç»“æŸæ·»åŠ  ==========
    
    logger.info("åˆå§‹åŒ–123äº‘ç›˜å®¢æˆ·ç«¯...")
    pan_client = Pan123Client(CLIENT_ID, CLIENT_SECRET)
    
    if not pan_client.token_manager.access_token:
        logger.error("âŒ æ— æ³•è·å–æœ‰æ•ˆçš„Token")
        return
    
    logger.info("åˆå§‹åŒ–Telegramæœºå™¨äºº...")
    bot_handler = TelegramBotHandler(BOT_TOKEN, pan_client, ADMIN_USER_IDS)
    bot_handler.start()

if __name__ == "__main__":
    main()
